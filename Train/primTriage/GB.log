Fitting 1 folds for each of 1 candidates, totalling 1 fits
      Iter       Train Loss   Remaining Time 
         1           1.2990           17.09s
         2           1.2336           11.07s
         3           1.1795            7.07s
         4           1.1336            3.45s
         5           1.0920            0.00s
      Iter       Train Loss   Remaining Time 
         1           1.3035           21.77s
         2           1.2371           14.22s
         3           1.1821            9.08s
         4           1.1355            4.42s
         5           1.0930            0.00s
### Start Time 2019/10/08-14-01-48  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=560   randForSplit=887   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.89      0.77      0.82     28178
Train discard       0.77      0.88      0.82     23813

    micro avg       0.82      0.82      0.82     51991
    macro avg       0.83      0.83      0.82     51991
 weighted avg       0.83      0.82      0.82     51991

Train F2: 0.79160 (keep)

['yes', 'no']
[[21729  6449]
 [ 2806 21007]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.83      0.78      0.80      5596
Valid discard       0.84      0.88      0.86      7463

    micro avg       0.84      0.84      0.84     13059
    macro avg       0.84      0.83      0.83     13059
 weighted avg       0.84      0.84      0.84     13059

Valid F2: 0.78998 (keep)

['yes', 'no']
[[4367 1229]
 [ 889 6574]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.78      0.80      4188
Test  discard       0.84      0.87      0.86      5506

    micro avg       0.84      0.84      0.84      9694
    macro avg       0.83      0.83      0.83      9694
 weighted avg       0.83      0.84      0.83      9694

Test  F2: 0.79156 (keep)

['yes', 'no']
[[3281  907]
 [ 692 4814]]

### Best Pipeline Parameters:
classifier__n_estimators: 5

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=5,
              n_iter_no_change=None, presort='auto', random_state=560,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__n_estimators:[5]

### Feature weights: highest 20
+0.5163	mice figur
+0.1694	wild_typ mice
+0.1388	cre
+0.0827	wild_typ
+0.0377	mut_mut
+0.0264	litterm
+0.0251	genotyp
+0.0009	rat figur
+0.0009	compar wild_typ
+0.0008	embryonic_day
+0.0007	delet
+0.0002	mice infect
+0.0000	aa
+0.0000	aaa
+0.0000	aav
+0.0000	ab
+0.0000	abbrevi
+0.0000	abcam
+0.0000	aberr
+0.0000	abil

### Feature weights: lowest 20
+0.0000	wrote manuscript
+0.0000	xenograft
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	year
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	zebrafish
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6715
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'invad', u'invas', u'invers', u'invers correl', u'invert', u'investig', u'investig effect', u'investig express', u'investig mechan', u'investig possibl']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 692
30274781
31039010
28719654
27057433
31104950

### False negatives for Test set: 907
29603384
25104925
29359518
28088781
26554816

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :        13059         5596         7463          43%
Training Set        :        51991        28178        23813          54%
Test Set            :         9694         4188         5506          43%
TestSplit: 0.20
### End Time 2019/10/08-14-46-44. Total   2695.42 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
      Iter       Train Loss   Remaining Time 
         1           1.2990            6.82m
         2           1.2336            5.87m
         3           1.1795            5.54m
         4           1.1336            5.36m
         5           1.0920            5.23m
         6           1.0566            5.13m
         7           1.0249            5.06m
         8           0.9976            4.99m
         9           0.9738            4.92m
        10           0.9515            4.84m
        20           0.8238            4.18m
        30           0.7666            3.63m
        40           0.7321            3.09m
        50           0.7077            2.55m
        60           0.6885            2.02m
        70           0.6728            1.51m
        80           0.6598            1.00m
        90           0.6475           30.16s
       100           0.6374            0.00s
      Iter       Train Loss   Remaining Time 
         1           1.3035            8.95m
         2           1.2371            7.53m
         3           1.1821            7.08m
         4           1.1355            6.79m
         5           1.0930            6.57m
         6           1.0571            6.46m
         7           1.0248            6.34m
         8           0.9971            6.22m
         9           0.9731            6.12m
        10           0.9507            6.05m
        20           0.8200            5.24m
        30           0.7625            4.54m
        40           0.7290            3.87m
        50           0.7055            3.21m
        60           0.6867            2.56m
        70           0.6714            1.91m
        80           0.6590            1.27m
        90           0.6474           38.09s
       100           0.6376            0.00s
### Start Time 2019/10/09-09-08-55  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=314   randForSplit=723   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.85      0.88     28178
Train discard       0.83      0.90      0.87     23813

    micro avg       0.87      0.87      0.87     51991
    macro avg       0.87      0.87      0.87     51991
 weighted avg       0.88      0.87      0.87     51991

Train F2: 0.86092 (keep)

['yes', 'no']
[[23938  4240]
 [ 2376 21437]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.86      0.86      5596
Valid discard       0.89      0.90      0.90      7463

    micro avg       0.88      0.88      0.88     13059
    macro avg       0.88      0.88      0.88     13059
 weighted avg       0.88      0.88      0.88     13059

Valid F2: 0.85861 (keep)

['yes', 'no']
[[4796  800]
 [ 749 6714]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.86      0.86      0.86      4188
Test  discard       0.89      0.89      0.89      5506

    micro avg       0.88      0.88      0.88      9694
    macro avg       0.88      0.88      0.88      9694
 weighted avg       0.88      0.88      0.88      9694

Test  F2: 0.85948 (keep)

['yes', 'no']
[[3599  589]
 [ 586 4920]]

### Best Pipeline Parameters:
classifier__n_estimators: 100

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=314,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__n_estimators:[100]

### Feature weights: highest 20
+0.3416	mice figur
+0.1313	wild_typ mice
+0.0994	cre
+0.0788	wild_typ
+0.0417	litterm
+0.0351	mut_mut
+0.0327	genotyp
+0.0237	transgen mice
+0.0206	knock_out mice
+0.0191	transgen
+0.0158	knock_out
+0.0110	embryonic_day
+0.0093	mice compar
+0.0084	mice strain
+0.0077	relat figur
+0.0069	mice express
+0.0067	mut_mut mice
+0.0051	defici
+0.0049	embryon
+0.0040	mice model

### Feature weights: lowest 20
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6715
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'invad', u'invas', u'invers', u'invers correl', u'invert', u'investig', u'investig effect', u'investig express', u'investig mechan', u'investig possibl']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 586
30274781
28855256
28158270
28973855
28694481

### False negatives for Test set: 589
29359518
28088781
26554816
28182007
24251878

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :        13059         5596         7463          43%
Training Set        :        51991        28178        23813          54%
Test Set            :         9694         4188         5506          43%
TestSplit: 0.20
### End Time 2019/10/09-10-03-18. Total   3263.28 seconds

Recall for papers selected by each curation group. 9694 papers analyzed
ap             selected papers:  3631 predicted keep:  3266 recall: 0.899
gxd            selected papers:   328 predicted keep:   300 recall: 0.915
go             selected papers:  3094 predicted keep:  2687 recall: 0.868
tumor          selected papers:   222 predicted keep:   199 recall: 0.896
qtl            selected papers:    18 predicted keep:     9 recall: 0.500
Totals         keep     papers:  4188 predicted keep:  3599 recall: 0.859
Predictions from GB_test_pred.txt - Wed Oct  9 10:08:18 2019
Fitting 1 folds for each of 1 candidates, totalling 1 fits
      Iter       Train Loss   Remaining Time 
         1           1.2990           10.74m
         2           1.2336            9.19m
         3           1.1795            8.59m
         4           1.1336            8.31m
         5           1.0920            8.09m
         6           1.0566            7.93m
         7           1.0249            7.81m
         8           0.9976            7.68m
         9           0.9738            7.58m
        10           0.9515            7.47m
        20           0.8238            6.75m
        30           0.7666            6.15m
        40           0.7321            5.58m
        50           0.7077            5.03m
        60           0.6885            4.51m
        70           0.6728            3.99m
        80           0.6598            3.49m
        90           0.6475            2.99m
       100           0.6374            2.49m
      Iter       Train Loss   Remaining Time 
         1           1.3035           12.98m
         2           1.2371           11.22m
         3           1.1821           10.69m
         4           1.1355           10.35m
         5           1.0930           10.12m
         6           1.0571            9.96m
         7           1.0248            9.79m
         8           0.9971            9.73m
         9           0.9731            9.61m
        10           0.9507            9.48m
        20           0.8200            8.60m
        30           0.7625            7.88m
        40           0.7290            7.16m
        50           0.7055            6.45m
        60           0.6867            5.77m
        70           0.6714            5.11m
        80           0.6590            4.46m
        90           0.6474            3.82m
       100           0.6376            3.17m
### Start Time 2019/10/09-13-06-54  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=542   randForSplit=815   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.86      0.89     28178
Train discard       0.84      0.90      0.87     23813

    micro avg       0.88      0.88      0.88     51991
    macro avg       0.88      0.88      0.88     51991
 weighted avg       0.88      0.88      0.88     51991

Train F2: 0.86941 (keep)

['yes', 'no']
[[24205  3973]
 [ 2287 21526]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.87      0.87      5596
Valid discard       0.90      0.91      0.90      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid F2: 0.86805 (keep)

['yes', 'no']
[[4851  745]
 [ 707 6756]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.86      0.87      0.87      4188
Test  discard       0.90      0.90      0.90      5506

    micro avg       0.88      0.88      0.88      9694
    macro avg       0.88      0.88      0.88      9694
 weighted avg       0.88      0.88      0.88      9694

Test  F2: 0.86611 (keep)

['yes', 'no']
[[3629  559]
 [ 569 4937]]

### Best Pipeline Parameters:
classifier__n_estimators: 150

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=150,
              n_iter_no_change=None, presort='auto', random_state=542,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__n_estimators:[150]

### Feature weights: highest 20
+0.3334	mice figur
+0.1281	wild_typ mice
+0.0967	cre
+0.0770	wild_typ
+0.0406	litterm
+0.0343	mut_mut
+0.0318	genotyp
+0.0230	transgen mice
+0.0200	knock_out mice
+0.0188	transgen
+0.0155	knock_out
+0.0108	embryonic_day
+0.0090	mice compar
+0.0083	mice strain
+0.0077	relat figur
+0.0068	mice express
+0.0065	mut_mut mice
+0.0050	defici
+0.0048	embryon
+0.0040	mice model

### Feature weights: lowest 20
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6715
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'invad', u'invas', u'invers', u'invers correl', u'invert', u'investig', u'investig effect', u'investig express', u'investig mechan', u'investig possibl']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 569
30274781
28855256
28158270
28973855
28694481

### False negatives for Test set: 559
29359518
26554816
28182007
30154243
25473946

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :        13059         5596         7463          43%
Training Set        :        51991        28178        23813          54%
Test Set            :         9694         4188         5506          43%
TestSplit: 0.20
### End Time 2019/10/09-14-05-10. Total   3496.47 seconds

Recall for papers selected by each curation group. 9694 papers analyzed
ap             selected papers:  3631 predicted keep:  3288 recall: 0.906
gxd            selected papers:   328 predicted keep:   303 recall: 0.924
go             selected papers:  3094 predicted keep:  2709 recall: 0.876
tumor          selected papers:   222 predicted keep:   201 recall: 0.905
qtl            selected papers:    18 predicted keep:    11 recall: 0.611
Totals         keep     papers:  4188 predicted keep:  3629 recall: 0.867
Predictions from GB_test_pred.txt - Wed Oct  9 14:38:53 2019
Recall for papers selected by each curation group. 9694 papers analyzed
ap             selected papers:  3631 predicted keep:  3288 recall: 0.906
gxd            selected papers:   328 predicted keep:   303 recall: 0.924
go             selected papers:  3094 predicted keep:  2709 recall: 0.876
tumor          selected papers:   222 predicted keep:   201 recall: 0.905
qtl            selected papers:    18 predicted keep:    11 recall: 0.611
Totals         keep     papers:  4188 predicted keep:  3629 recall: 0.867
Predictions from GB_test_pred.txt - Thu Oct 10 09:07:31 2019
Fitting 1 folds for each of 3 candidates, totalling 3 fits
      Iter       Train Loss   Remaining Time 
         1           0.9252           14.49m
         2           0.8263           12.52m
         3           0.7826           11.82m
         4           0.7540           11.30m
         5           0.7346           11.03m
         6           0.7214           10.71m
         7           0.7118           10.40m
         8           0.7012           10.31m
         9           0.6882           10.21m
        10           0.6787           10.09m
        20           0.6127            9.55m
        30           0.5769            8.88m
        40           0.5492            8.42m
        50           0.5258            7.83m
        60           0.5045            7.21m
        70           0.4860            6.64m
        80           0.4659            6.11m
        90           0.4485            5.56m
       100           0.4330            5.03m
       200           0.3110            0.00s
      Iter       Train Loss   Remaining Time 
         1           1.2990           14.25m
         2           1.2336           12.27m
         3           1.1795           11.62m
         4           1.1336           11.23m
         5           1.0920           10.99m
         6           1.0566           10.80m
         7           1.0249           10.62m
         8           0.9976           10.49m
         9           0.9738           10.38m
        10           0.9515           10.27m
        20           0.8238            9.48m
        30           0.7666            8.86m
        40           0.7321            8.26m
        50           0.7077            7.69m
        60           0.6885            7.13m
        70           0.6728            6.59m
        80           0.6598            6.06m
        90           0.6475            5.55m
       100           0.6374            5.03m
       200           0.5683            0.00s
      Iter       Train Loss   Remaining Time 
         1           1.3381           14.15m
         2           1.3008           12.11m
         3           1.2671           11.32m
         4           1.2363           11.06m
         5           1.2085           10.81m
         6           1.1827           10.66m
         7           1.1587           10.56m
         8           1.1368           10.48m
         9           1.1151           10.35m
        10           1.0960           10.26m
        20           0.9562            9.54m
        30           0.8770            8.93m
        40           0.8262            8.42m
        50           0.7918            7.87m
        60           0.7675            7.34m
        70           0.7481            6.80m
        80           0.7330            6.25m
        90           0.7201            5.71m
       100           0.7080            5.18m
       200           0.6389            0.00s
      Iter       Train Loss   Remaining Time 
         1           1.3035           18.40m
         2           1.2371           16.02m
         3           1.1821           15.08m
         4           1.1355           14.48m
         5           1.0930           14.13m
         6           1.0571           13.84m
         7           1.0248           13.64m
         8           0.9971           13.51m
         9           0.9731           13.33m
        10           0.9507           13.20m
        20           0.8200           12.19m
        30           0.7625           11.45m
        40           0.7290           10.64m
        50           0.7055            9.91m
        60           0.6867            9.17m
        70           0.6714            8.50m
        80           0.6590            7.84m
        90           0.6474            7.21m
       100           0.6376            6.54m
       200           0.5728            0.00s
### Start Time 2019/10/10-09-47-49  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=209   randForSplit=552   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.87      0.89     28178
Train discard       0.85      0.91      0.88     23813

    micro avg       0.88      0.88      0.88     51991
    macro avg       0.88      0.89      0.88     51991
 weighted avg       0.89      0.88      0.88     51991

Train F2: 0.87529 (keep)

['yes', 'no']
[[24386  3792]
 [ 2205 21608]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.88      0.87      0.88      5596
Valid discard       0.91      0.91      0.91      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid F2: 0.87450 (keep)

['yes', 'no']
[[4889  707]
 [ 680 6783]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.87      0.87      0.87      4188
Test  discard       0.90      0.90      0.90      5506

    micro avg       0.89      0.89      0.89      9694
    macro avg       0.88      0.88      0.88      9694
 weighted avg       0.89      0.89      0.89      9694

Test  F2: 0.86979 (keep)

['yes', 'no']
[[3646  542]
 [ 561 4945]]

### Best Pipeline Parameters:
classifier__learning_rate: 0.1
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=209,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__learning_rate:[1, 0.1, 0.05]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.3281	mice figur
+0.1260	wild_typ mice
+0.0950	cre
+0.0757	wild_typ
+0.0399	litterm
+0.0336	mut_mut
+0.0313	genotyp
+0.0226	transgen mice
+0.0197	knock_out mice
+0.0184	transgen
+0.0152	knock_out
+0.0106	embryonic_day
+0.0089	mice compar
+0.0082	mice strain
+0.0078	relat figur
+0.0066	mice express
+0.0065	mut_mut mice
+0.0050	defici
+0.0047	embryon
+0.0041	mice model

### Feature weights: lowest 20
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6715
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'invad', u'invas', u'invers', u'invers correl', u'invert', u'investig', u'investig effect', u'investig express', u'investig mechan', u'investig possibl']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 561
30274781
28855256
28158270
28973855
28694481

### False negatives for Test set: 542
29359518
26554816
28182007
30154243
25473946

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :        13059         5596         7463          43%
Training Set        :        51991        28178        23813          54%
Test Set            :         9694         4188         5506          43%
TestSplit: 0.20
### End Time 2019/10/10-11-49-02. Total   7273.91 seconds

Recall for papers selected by each curation group. 9694 papers analyzed
ap             selected papers:  3631 predicted keep:  3296 recall: 0.908
gxd            selected papers:   328 predicted keep:   304 recall: 0.927
go             selected papers:  3094 predicted keep:  2721 recall: 0.879
tumor          selected papers:   222 predicted keep:   203 recall: 0.914
qtl            selected papers:    18 predicted keep:    11 recall: 0.611
Totals         keep     papers:  4188 predicted keep:  3646 recall: 0.871
Predictions from GB_test_pred.txt - Thu Oct 10 12:02:09 2019
      Iter       Train Loss   Remaining Time 
         1           1.2990           13.40m
         2           1.2336           11.53m
         3           1.1795           10.88m
         4           1.1336           10.61m
         5           1.0920           10.38m
         6           1.0566           10.20m
         7           1.0249           10.17m
         8           0.9976           10.10m
         9           0.9738           10.03m
        10           0.9515            9.92m
        20           0.8238            9.18m
        30           0.7666            8.59m
        40           0.7321            7.99m
        50           0.7077            7.43m
        60           0.6885            6.92m
        70           0.6728            6.47m
        80           0.6598            5.96m
        90           0.6475            5.45m
       100           0.6374            4.95m
       200           0.5683            0.00s
### Start Time 2019/10/29-09-53-44  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=843   randForSplit=869   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     28178
Train discard       0.86      0.90      0.88     23813

    micro avg       0.89      0.89      0.89     51991
    macro avg       0.89      0.89      0.89     51991
 weighted avg       0.89      0.89      0.89     51991

Train (keep) F2: 0.8820    P: 0.9148    R: 0.8742    NPV: 0.8586

['yes', 'no']
[[24633  3545]
 [ 2294 21519]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.87      0.87      5596
Valid discard       0.91      0.90      0.90      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid (keep) F2: 0.8730    P: 0.8664    R: 0.8747    NPV: 0.9054

['yes', 'no']
[[4895  701]
 [ 755 6708]]

### Best Pipeline Parameters:
classifier__learning_rate: 0.1
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=843,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__learning_rate:[0.1]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.3270	mice figur
+0.1224	wild_typ mice
+0.0964	cre
+0.0796	wild_typ
+0.0377	litterm
+0.0292	mut_mut
+0.0274	genotyp
+0.0261	transgen mice
+0.0238	knock_out mice
+0.0179	transgen
+0.0101	knock_out
+0.0097	mice compar
+0.0095	mice strain
+0.0079	mut_mut mice
+0.0077	embryonic_day
+0.0069	relat figur
+0.0059	embryon
+0.0050	mice express
+0.0048	defici
+0.0043	pdf file

### Feature weights: lowest 20
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 755
29406270
27617678
29228333
29955044
28993663

### False negatives for Validation set: 701
29953499
28062700
26673701
28775166
28837808

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/10/29-10-26-44. Total   1979.94 seconds
Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4479 recall: 0.916
gxd            selected papers:   475 predicted keep:   443 recall: 0.933
go             selected papers:  4180 predicted keep:  3711 recall: 0.888
tumor          selected papers:   316 predicted keep:   275 recall: 0.870
qtl            selected papers:    18 predicted keep:    13 recall: 0.722
Totals         keep     papers:  5596 predicted keep:  4895 recall: 0.875
Predictions from GB_val_pred.txt - Tue Oct 29 12:16:55 2019


Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4479 recall: 0.916
gxd            selected papers:   475 predicted keep:   443 recall: 0.933
go             selected papers:  4180 predicted keep:  3711 recall: 0.888
tumor          selected papers:   316 predicted keep:   275 recall: 0.870
qtl            selected papers:    18 predicted keep:    13 recall: 0.722
Totals         keep     papers:  5596 predicted keep:  4895 recall: 0.875
Predictions from GB_val_pred.txt - Tue Oct 29 12:49:06 2019
      Iter       Train Loss   Remaining Time 
         1           1.0975           13.19m
         2           1.0476           11.63m
         3           1.0066           11.00m
         4           0.9720           10.68m
         5           0.9423           10.46m
         6           0.9144           10.30m
         7           0.8910           10.20m
         8           0.8712           10.11m
         9           0.8520           10.03m
        10           0.8359            9.96m
        20           0.7424            9.27m
        30           0.6987            8.65m
        40           0.6715            8.06m
        50           0.6522            7.47m
        60           0.6370            6.91m
        70           0.6241            6.41m
        80           0.6124            5.88m
        90           0.6022            5.39m
       100           0.5934            4.88m
       200           0.5320            0.00s
### Start Time 2019/10/29-15-50-21  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=479   randForSplit=623   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.88      0.90     28178
Train discard       0.87      0.91      0.89     23813

    micro avg       0.90      0.90      0.90     51991
    macro avg       0.89      0.90      0.90     51991
 weighted avg       0.90      0.90      0.90     51991

Train (keep) F2: 0.8907    P: 0.9206    R: 0.8835    NPV: 0.8684

['yes', 'no']
[[24895  3283]
 [ 2148 21665]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.87      5596
Valid discard       0.91      0.90      0.90      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid (keep) F2: 0.8740    P: 0.8668    R: 0.8758    NPV: 0.9061

['yes', 'no']
[[4901  695]
 [ 753 6710]]

### Best Pipeline Parameters:
classifier__learning_rate: 0.1
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Clf instance at 0x1a1975d8c0>,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=479,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__learning_rate:[0.1]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.3163	mice figur
+0.1045	wild_typ mice
+0.0920	cre
+0.0761	wild_typ
+0.0379	litterm
+0.0310	genotyp
+0.0305	mut_mut
+0.0265	transgen mice
+0.0207	knock_out mice
+0.0192	transgen
+0.0110	knock_out
+0.0104	mice strain
+0.0099	relat figur
+0.0097	embryonic_day
+0.0073	mice model
+0.0067	mice compar
+0.0058	xenograft
+0.0055	mut_mut mice
+0.0052	pdf file
+0.0047	embryon

### Feature weights: lowest 20
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 753
29406270
27617678
29228333
29955044
28993663

### False negatives for Validation set: 695
29953499
28062700
26673701
28775166
28837808

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/10/29-16-22-33. Total   1932.10 seconds

Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4477 recall: 0.916
gxd            selected papers:   475 predicted keep:   446 recall: 0.939
go             selected papers:  4180 predicted keep:  3715 recall: 0.889
tumor          selected papers:   316 predicted keep:   274 recall: 0.867
qtl            selected papers:    18 predicted keep:    14 recall: 0.778
Totals         keep     papers:  5596 predicted keep:  4901 recall: 0.876
Predictions from GB_val_pred.txt - Tue Oct 29 16:23:52 2019
      Iter       Train Loss   Remaining Time 
         1           1.1573           13.27m
         2           1.1510           11.72m
         3           1.1447           11.09m
         4           1.1386           10.85m
         5           1.1326           10.60m
         6           1.1267           10.43m
         7           1.1210           10.29m
         8           1.1153           10.16m
         9           1.1098           10.04m
        10           1.1044           10.00m
        20           1.0554            9.47m
        30           1.0144            8.80m
        40           0.9793            8.23m
        50           0.9483            7.71m
        60           0.9213            7.19m
        70           0.8977            6.67m
        80           0.8768            6.15m
        90           0.8584            5.65m
       100           0.8419            5.14m
       200           0.7453            0.00s
### Start Time 2019/10/29-17-01-25  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=860   randForSplit=15   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.89      0.85      0.87     28178
Train discard       0.83      0.88      0.85     23813

    micro avg       0.86      0.86      0.86     51991
    macro avg       0.86      0.86      0.86     51991
 weighted avg       0.86      0.86      0.86     51991

Train (keep) F2: 0.8561    P: 0.8897    R: 0.8481    NPV: 0.8297

['yes', 'no']
[[23899  4279]
 [ 2964 20849]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.83      0.85      0.84      5596
Valid discard       0.88      0.87      0.87      7463

    micro avg       0.86      0.86      0.86     13059
    macro avg       0.85      0.86      0.86     13059
 weighted avg       0.86      0.86      0.86     13059

Valid (keep) F2: 0.8423    P: 0.8267    R: 0.8463    NPV: 0.8827

['yes', 'no']
[[4736  860]
 [ 993 6470]]

### Best Pipeline Parameters:
classifier__learning_rate: 0.01
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Clf instance at 0x1a2341d8c0>,
              learning_rate=0.01, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=860,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__learning_rate:[0.01]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.3875	mice figur
+0.1585	wild_typ mice
+0.1211	cre
+0.0901	wild_typ
+0.0485	litterm
+0.0329	mut_mut
+0.0327	transgen mice
+0.0322	genotyp
+0.0244	knock_out mice
+0.0152	transgen
+0.0091	knock_out
+0.0072	embryonic_day
+0.0071	mut_mut mice
+0.0068	mice strain
+0.0054	embryon
+0.0021	mice express
+0.0020	xenograft
+0.0019	rat figur
+0.0012	mice compar
+0.0011	crispr

### Feature weights: lowest 20
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	year
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 993
24550541
30282797
27617678
29228333
28883554

### False negatives for Validation set: 860
26909801
26253614
19417088
29953499
26673701

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/10/29-17-27-37. Total   1572.13 seconds

Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4381 recall: 0.896
gxd            selected papers:   475 predicted keep:   404 recall: 0.851
go             selected papers:  4180 predicted keep:  3599 recall: 0.861
tumor          selected papers:   316 predicted keep:   266 recall: 0.842
qtl            selected papers:    18 predicted keep:     9 recall: 0.500
Totals         keep     papers:  5596 predicted keep:  4736 recall: 0.846
Predictions from GB_val_pred.txt - Tue Oct 29 21:54:01 2019

      Iter       Train Loss   Remaining Time 
         1           0.9210           13.75m
         2           0.8235           12.06m
         3           0.7745           11.21m
         4           0.7445           10.75m
         5           0.7187           10.47m
         6           0.7008           10.21m
         7           0.6872            9.96m
         8           0.6759            9.82m
         9           0.6673            9.66m
        10           0.6585            9.56m
        20           0.5979            8.87m
        30           0.5635            8.40m
        40           0.5388            7.87m
        50           0.5183            7.35m
        60           0.5016            6.83m
        70           0.4861            6.34m
        80           0.4726            5.86m
        90           0.4607            5.37m
       100           0.4497            4.88m
       200           0.3640            0.00s
### Start Time 2019/11/04-09-55-11  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=133   randForSplit=31   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.95      0.93      0.94     28178
Train discard       0.92      0.94      0.93     23813

    micro avg       0.93      0.93      0.93     51991
    macro avg       0.93      0.93      0.93     51991
 weighted avg       0.93      0.93      0.93     51991

Train (keep) F2: 0.9322    P: 0.9458    R: 0.9288    NPV: 0.9175

['yes', 'no']
[[26172  2006]
 [ 1499 22314]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.89      0.87      5596
Valid discard       0.92      0.89      0.90      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid (keep) F2: 0.8842    P: 0.8599    R: 0.8905    NPV: 0.9156

['yes', 'no']
[[4983  613]
 [ 812 6651]]

### Best Pipeline Parameters:
classifier__learning_rate: 0.5
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x1a16d708c0>,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=133,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__learning_rate:[0.5]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.2627	mice figur
+0.1356	wild_typ mice
+0.0722	wild_typ
+0.0714	cre
+0.0442	litterm
+0.0299	transgen mice
+0.0248	genotyp
+0.0132	transgen
+0.0127	knock_out mice
+0.0114	mut_mut
+0.0113	mut_mut mice
+0.0098	embryonic_day
+0.0086	relat figur
+0.0075	mice strain
+0.0071	mice compar
+0.0052	pdf file
+0.0049	mutant mice
+0.0046	mice model
+0.0045	xenograft
+0.0041	inocul

### Feature weights: lowest 20
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 812
29406270
27617678
29228333
29955044
28993663

### False negatives for Validation set: 613
29953499
28062700
26673701
28837808
27911798

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/04-10-21-00. Total   1548.56 seconds

Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4494 recall: 0.919
gxd            selected papers:   475 predicted keep:   452 recall: 0.952
go             selected papers:  4180 predicted keep:  3776 recall: 0.904
tumor          selected papers:   316 predicted keep:   278 recall: 0.880
qtl            selected papers:    18 predicted keep:    16 recall: 0.889
Totals         keep     papers:  5596 predicted keep:  4983 recall: 0.890
Predictions from GB_val_pred.txt - Mon Nov  4 10:22:37 2019
      Iter       Train Loss   Remaining Time 
         1           0.8195           13.59m
         2           0.7493           11.61m
         3           0.7151           11.05m
         4           0.6922           10.62m
         5           0.6772           10.42m
         6           0.6630           10.22m
         7           0.6534           10.06m
         8           0.6409            9.87m
         9           0.6317            9.74m
        10           0.6233            9.60m
        20           0.5672            9.13m
        30           0.5322            8.66m
        40           0.5079            8.06m
        50           0.4875            7.52m
        60           0.4695            7.02m
        70           0.4525            6.47m
        80           0.4364            5.98m
        90           0.4203            5.49m
       100           0.4055            4.99m
       200           0.2934            0.00s
### Start Time 2019/11/04-10-26-15  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=455   randForSplit=261   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.96      0.94      0.95     28178
Train discard       0.94      0.95      0.94     23813

    micro avg       0.95      0.95      0.95     51991
    macro avg       0.95      0.95      0.95     51991
 weighted avg       0.95      0.95      0.95     51991

Train (keep) F2: 0.9468    P: 0.9551    R: 0.9447    NPV: 0.9354

['yes', 'no']
[[26620  1558]
 [ 1250 22563]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.87      0.85      5596
Valid discard       0.90      0.87      0.89      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.87      0.87      0.87     13059

Valid (keep) F2: 0.8652    P: 0.8355    R: 0.8729    NPV: 0.9014

['yes', 'no']
[[4885  711]
 [ 962 6501]]

### Best Pipeline Parameters:
classifier__init: <__main__.Working_Init_Classifier instance at 0x1a15b368c0>
classifier__learning_rate: 1.0
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x1a15b368c0>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=455,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__init:[<__main__.Working_Init_Classifier instance at 0x1a15b368c0>]
classifier__learning_rate:[1.0]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.3537	mice figur
+0.1032	cre
+0.0737	wild_typ mice
+0.0576	wild_typ
+0.0288	knock_out
+0.0235	transgen mice
+0.0234	mut_mut
+0.0131	litterm
+0.0114	genotyp
+0.0087	relat figur
+0.0078	inocul
+0.0069	mice strain
+0.0053	embryonic_day
+0.0047	crispr
+0.0046	pdf file
+0.0045	mice compar
+0.0043	clinic
+0.0034	po0
+0.0034	knock_out mice
+0.0033	xenograft

### Feature weights: lowest 20
+0.0000	work
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 962
24550541
30595162
29406270
30098187
29228333

### False negatives for Validation set: 711
29953499
28062700
26673701
28775166
27911798

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/04-10-52-17. Total   1561.55 seconds

Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4385 recall: 0.897
gxd            selected papers:   475 predicted keep:   450 recall: 0.947
go             selected papers:  4180 predicted keep:  3718 recall: 0.890
tumor          selected papers:   316 predicted keep:   274 recall: 0.867
qtl            selected papers:    18 predicted keep:    16 recall: 0.889
Totals         keep     papers:  5596 predicted keep:  4885 recall: 0.873
Predictions from GB_val_pred.txt - Mon Nov  4 10:54:49 2019
      Iter       Train Loss   Remaining Time 
         1           0.9386           14.88m
         2           0.8417           12.76m
         3           0.7868           11.92m
         4           0.7562           11.39m
         5           0.7295           10.98m
         6           0.7117           10.68m
         7           0.6998           10.51m
         8           0.6887           10.36m
         9           0.6791           10.25m
        10           0.6709           10.08m
        20           0.6128            9.13m
        30           0.5758            8.50m
        40           0.5504            7.90m
        50           0.5305            7.36m
        60           0.5116            6.87m
        70           0.4979            6.33m
        80           0.4836            5.85m
        90           0.4716            5.36m
       100           0.4598            4.87m
       200           0.3708            0.00s
### Start Time 2019/11/04-11-38-38  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=289   randForSplit=955   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.95      0.93      0.94     28178
Train discard       0.92      0.94      0.93     23813

    micro avg       0.93      0.93      0.93     51991
    macro avg       0.93      0.93      0.93     51991
 weighted avg       0.93      0.93      0.93     51991

Train (keep) F2: 0.9313    P: 0.9453    R: 0.9278    NPV: 0.9164

['yes', 'no']
[[26144  2034]
 [ 1512 22301]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.89      0.88      5596
Valid discard       0.92      0.89      0.90      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid (keep) F2: 0.8849    P: 0.8633    R: 0.8905    NPV: 0.9159

['yes', 'no']
[[4983  613]
 [ 789 6674]]

### Note: init param: RF w/ n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__init: <__main__.Working_Init_Classifier instance at 0x1a215948c0>
classifier__learning_rate: 0.5
classifier__n_estimators: 200

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x1a215948c0>,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=200,
              n_iter_no_change=None, presort='auto', random_state=289,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__init:[<__main__.Working_Init_Classifier instance at 0x1a215948c0>]
classifier__learning_rate:[0.5]
classifier__n_estimators:[200]

### Feature weights: highest 20
+0.2631	mice figur
+0.1270	wild_typ mice
+0.0827	cre
+0.0428	wild_typ
+0.0424	litterm
+0.0299	knock_out
+0.0286	transgen mice
+0.0236	genotyp
+0.0228	mut_mut
+0.0173	transgen
+0.0089	embryonic_day
+0.0084	relat figur
+0.0074	mice strain
+0.0071	mut_mut mice
+0.0057	mice compar
+0.0056	knock_out mice
+0.0053	mice model
+0.0049	pdf file
+0.0044	xenograft
+0.0043	crispr

### Feature weights: lowest 20
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 789
24550541
29406270
27617678
30098187
29228333

### False negatives for Validation set: 613
28973854
29953499
28062700
26673701
28775166

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/04-12-06-07. Total   1649.20 seconds

Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4488 recall: 0.918
gxd            selected papers:   475 predicted keep:   452 recall: 0.952
go             selected papers:  4180 predicted keep:  3782 recall: 0.905
tumor          selected papers:   316 predicted keep:   279 recall: 0.883
qtl            selected papers:    18 predicted keep:    17 recall: 0.944
Totals         keep     papers:  5596 predicted keep:  4983 recall: 0.890
Predictions from GB_val_pred.txt - Mon Nov  4 12:07:59 2019
Fitting 1 folds for each of 5 candidates, totalling 5 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1617           0.0235           39.80s
         2           1.1388           0.0206           27.67s
         3           1.1029           0.0368           23.58s
         4           1.0774           0.0251           20.96s
         5           1.0450           0.0314           18.78s
         6           1.0299           0.0146           17.01s
         7           1.0100           0.0211           15.45s
         8           0.9997           0.0108           13.95s
         9           0.9718           0.0266           12.77s
        10           0.9528           0.0202           11.48s
        20           0.8385           0.0085            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1617           0.0235            1.23m
         2           1.1388           0.0206           53.00s
         3           1.1029           0.0368           45.73s
         4           1.0774           0.0251           41.52s
         5           1.0450           0.0314           38.76s
         6           1.0299           0.0146           36.51s
         7           1.0100           0.0211           34.52s
         8           0.9997           0.0108           32.75s
         9           0.9718           0.0266           31.07s
        10           0.9528           0.0202           29.54s
        20           0.8385           0.0085           16.92s
        30           0.7701           0.0066            5.53s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1617           0.0235            1.69m
         2           1.1388           0.0206            1.22m
         3           1.1029           0.0368            1.07m
         4           1.0774           0.0251           58.69s
         5           1.0450           0.0314           54.94s
         6           1.0299           0.0146           52.67s
         7           1.0100           0.0211           50.45s
         8           0.9997           0.0108           48.80s
         9           0.9718           0.0266           47.36s
        10           0.9528           0.0202           45.89s
        20           0.8385           0.0085           33.07s
        30           0.7701           0.0066           21.50s
        40           0.7188           0.0016           10.71s
        50           0.6869           0.0022            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1617           0.0235            2.11m
         2           1.1388           0.0206            1.63m
         3           1.1029           0.0368            1.43m
         4           1.0774           0.0251            1.34m
         5           1.0450           0.0314            1.26m
         6           1.0299           0.0146            1.21m
         7           1.0100           0.0211            1.16m
         8           0.9997           0.0108            1.12m
         9           0.9718           0.0266            1.09m
        10           0.9528           0.0202            1.06m
        20           0.8385           0.0085           49.37s
        30           0.7701           0.0066           37.96s
        40           0.7188           0.0016           26.98s
        50           0.6869           0.0022           16.02s
        60           0.6629           0.0018            5.30s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1617           0.0235            2.65m
         2           1.1388           0.0206            1.99m
         3           1.1029           0.0368            1.75m
         4           1.0774           0.0251            1.61m
         5           1.0450           0.0314            1.54m
         6           1.0299           0.0146            1.47m
         7           1.0100           0.0211            1.44m
         8           0.9997           0.0108            1.39m
         9           0.9718           0.0266            1.35m
        10           0.9528           0.0202            1.32m
        20           0.8385           0.0085            1.09m
        30           0.7701           0.0066           53.54s
        40           0.7188           0.0016           42.55s
        50           0.6869           0.0022           31.79s
        60           0.6629           0.0018           21.10s
        70           0.6461           0.0013           10.54s
        80           0.6316           0.0012            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1701           0.0292            3.49m
         2           1.1387           0.0297            2.57m
         3           1.0975           0.0432            2.23m
         4           1.0628           0.0328            2.11m
         5           1.0419           0.0220            2.02m
         6           1.0204           0.0212            1.93m
         7           1.0009           0.0168            1.87m
         8           0.9892           0.0128            1.82m
         9           0.9686           0.0215            1.77m
        10           0.9559           0.0108            1.72m
        20           0.8392           0.0088            1.40m
        30           0.7721           0.0055            1.15m
        40           0.7280           0.0052           54.55s
        50           0.6922           0.0019           40.71s
        60           0.6716           0.0018           26.99s
        70           0.6480           0.0014           13.51s
        80           0.6331           0.0016            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1617           0.0235            2.65m
         2           1.1388           0.0206            1.99m
         3           1.1029           0.0368            1.77m
         4           1.0774           0.0251            1.65m
         5           1.0450           0.0314            1.56m
         6           1.0299           0.0146            1.51m
         7           1.0100           0.0211            1.46m
         8           0.9997           0.0108            1.42m
         9           0.9718           0.0266            1.37m
        10           0.9528           0.0202            1.34m
        20           0.8385           0.0085            1.11m
        30           0.7701           0.0066           54.86s
        40           0.7188           0.0016           43.88s
        50           0.6869           0.0022           33.10s
        60           0.6629           0.0018           22.11s
        70           0.6461           0.0013           10.97s
        80           0.6316           0.0012            0.00s
### Start Time 2019/11/04-12-54-50  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=41   randForSplit=320   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.86      0.89     28178
Train discard       0.85      0.90      0.87     23813

    micro avg       0.88      0.88      0.88     51991
    macro avg       0.88      0.88      0.88     51991
 weighted avg       0.88      0.88      0.88     51991

Train (keep) F2: 0.8711    P: 0.9111    R: 0.8616    NPV: 0.8461

['yes', 'no']
[[24278  3900]
 [ 2370 21443]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.87      0.86      5596
Valid discard       0.90      0.89      0.90      7463

    micro avg       0.88      0.88      0.88     13059
    macro avg       0.88      0.88      0.88     13059
 weighted avg       0.88      0.88      0.88     13059

Valid (keep) F2: 0.8658    P: 0.8580    R: 0.8678    NPV: 0.9000

['yes', 'no']
[[4856  740]
 [ 804 6659]]

### Note: searching for initial high learning rate.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__init: <__main__.Working_Init_Classifier instance at 0x1a1611a950>
classifier__learning_rate: 0.1
classifier__max_depth: 5
classifier__max_features: 'sqrt'
classifier__min_samples_leaf: 50
classifier__min_samples_split: 500
classifier__n_estimators: 80
classifier__subsample: 0.8

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=41,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__init:[<__main__.Working_Init_Classifier instance at 0x1a1611a950>]
classifier__learning_rate:[0.1]
classifier__max_depth:[5]
classifier__max_features:['sqrt']
classifier__min_samples_leaf:[50]
classifier__min_samples_split:[500]
classifier__n_estimators:[20, 35, 50, 65, 80]
classifier__subsample:[0.8]

### Feature weights: highest 20
+0.0768	mice figur
+0.0591	wild_typ mice
+0.0321	transgen
+0.0313	defici
+0.0308	knock_out mice
+0.0308	wild_typ
+0.0290	litterm
+0.0286	mice compar
+0.0253	mice express
+0.0221	mut_mut
+0.0212	wild_typ wild_typ
+0.0154	knock_out
+0.0145	mice signific
+0.0131	old
+0.0125	cre mice
+0.0122	mice strain
+0.0121	mice cell_lin
+0.0112	mice result
+0.0101	genotyp
+0.0101	mut_mut mice

### Feature weights: lowest 20
+0.0000	work
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 804
29406270
27617678
29228333
29955044
28993663

### False negatives for Validation set: 740
29953499
28062700
26673701
28775166
28837808

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/04-15-06-46. Total   7916.11 seconds

Fitting 1 folds for each of 8 candidates, totalling 8 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0396           0.1391            2.11m
         2           0.9766           0.0574            1.57m
         3           0.9241           0.0518            1.41m
         4           0.8753           0.0484            1.31m
         5           0.8411           0.0307            1.24m
         6           0.8145           0.0304            1.19m
         7           0.7920           0.0208            1.14m
         8           0.7780           0.0170            1.11m
         9           0.7598           0.0124            1.08m
        10           0.7498           0.0113            1.09m
        20           0.6535           0.0067           51.23s
        30           0.6022           0.0052           39.04s
        40           0.5688          -0.0002           27.57s
        50           0.5461           0.0010           16.45s
        60           0.5207          -0.0002            5.45s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0396           0.1391            2.72m
         2           0.9766           0.0574            2.06m
         3           0.9241           0.0518            1.79m
         4           0.8753           0.0484            1.66m
         5           0.8411           0.0307            1.58m
         6           0.8145           0.0304            1.53m
         7           0.7920           0.0208            1.48m
         8           0.7780           0.0170            1.44m
         9           0.7598           0.0124            1.41m
        10           0.7498           0.0113            1.37m
        20           0.6535           0.0067            1.12m
        30           0.6022           0.0052           54.99s
        40           0.5688          -0.0002           43.69s
        50           0.5461           0.0010           32.45s
        60           0.5207          -0.0002           21.53s
        70           0.5000          -0.0005           10.73s
        80           0.4914          -0.0005            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0396           0.1391            3.21m
         2           0.9766           0.0574            2.39m
         3           0.9241           0.0518            2.11m
         4           0.8753           0.0484            1.95m
         5           0.8411           0.0307            1.86m
         6           0.8145           0.0304            1.78m
         7           0.7920           0.0208            1.73m
         8           0.7780           0.0170            1.68m
         9           0.7598           0.0124            1.64m
        10           0.7498           0.0113            1.60m
        20           0.6535           0.0067            1.35m
        30           0.6022           0.0052            1.16m
        40           0.5688          -0.0002           58.67s
        50           0.5461           0.0010           47.99s
        60           0.5207          -0.0002           37.19s
        70           0.5000          -0.0005           26.49s
        80           0.4914          -0.0005           15.91s
        90           0.4732           0.0003            5.32s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0396           0.1391            3.82m
         2           0.9766           0.0574            2.76m
         3           0.9241           0.0518            2.39m
         4           0.8753           0.0484            2.25m
         5           0.8411           0.0307            2.19m
         6           0.8145           0.0304            2.09m
         7           0.7920           0.0208            2.03m
         8           0.7780           0.0170            2.00m
         9           0.7598           0.0124            1.95m
        10           0.7498           0.0113            1.92m
        20           0.6535           0.0067            1.64m
        30           0.6022           0.0052            1.44m
        40           0.5688          -0.0002            1.25m
        50           0.5461           0.0010            1.07m
        60           0.5207          -0.0002           52.91s
        70           0.5000          -0.0005           42.10s
        80           0.4914          -0.0005           31.67s
        90           0.4732           0.0003           21.07s
       100           0.4570          -0.0001           10.53s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1477           0.0353            2.17m
         2           1.1215           0.0230            1.65m
         3           1.0983           0.0240            1.47m
         4           1.0714           0.0285            1.33m
         5           1.0488           0.0213            1.25m
         6           1.0284           0.0225            1.19m
         7           1.0082           0.0188            1.17m
         8           0.9942           0.0156            1.13m
         9           0.9760           0.0154            1.10m
        10           0.9632           0.0136            1.07m
        20           0.8343           0.0117           50.46s
        30           0.7669           0.0093           37.86s
        40           0.7282           0.0020           26.69s
        50           0.6987           0.0022           15.98s
        60           0.6728           0.0030            5.30s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1477           0.0353            2.74m
         2           1.1215           0.0230            1.98m
         3           1.0983           0.0240            1.78m
         4           1.0714           0.0285            1.68m
         5           1.0488           0.0213            1.60m
         6           1.0284           0.0225            1.52m
         7           1.0082           0.0188            1.46m
         8           0.9942           0.0156            1.42m
         9           0.9760           0.0154            1.38m
        10           0.9632           0.0136            1.34m
        20           0.8343           0.0117            1.09m
        30           0.7669           0.0093           53.96s
        40           0.7282           0.0020           42.74s
        50           0.6987           0.0022           31.93s
        60           0.6728           0.0030           21.23s
        70           0.6506           0.0013           10.60s
        80           0.6408           0.0010            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1477           0.0353            2.32m
         2           1.1215           0.0230            1.96m
         3           1.0983           0.0240            1.79m
         4           1.0714           0.0285            1.70m
         5           1.0488           0.0213            1.63m
         6           1.0284           0.0225            1.59m
         7           1.0082           0.0188            1.59m
         8           0.9942           0.0156            1.56m
         9           0.9760           0.0154            1.53m
        10           0.9632           0.0136            1.50m
        20           0.8343           0.0117            1.31m
        30           0.7669           0.0093            1.12m
        40           0.7282           0.0020           56.73s
        50           0.6987           0.0022           46.62s
        60           0.6728           0.0030           36.35s
        70           0.6506           0.0013           26.02s
        80           0.6408           0.0010           15.56s
        90           0.6213           0.0009            5.17s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1477           0.0353            3.58m
         2           1.1215           0.0230            2.66m
         3           1.0983           0.0240            2.33m
         4           1.0714           0.0285            2.17m
         5           1.0488           0.0213            2.06m
         6           1.0284           0.0225            2.01m
         7           1.0082           0.0188            1.95m
         8           0.9942           0.0156            1.90m
         9           0.9760           0.0154            1.90m
        10           0.9632           0.0136            1.88m
        20           0.8343           0.0117            1.61m
        30           0.7669           0.0093            1.42m
        40           0.7282           0.0020            1.23m
        50           0.6987           0.0022            1.05m
        60           0.6728           0.0030           52.27s
        70           0.6506           0.0013           41.91s
        80           0.6408           0.0010           31.34s
        90           0.6213           0.0009           20.80s
       100           0.6104           0.0008           10.37s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0111           0.1791            4.76m
         2           0.9446           0.0651            3.54m
         3           0.8953           0.0511            3.10m
         4           0.8635           0.0288            2.94m
         5           0.8389           0.0235            2.79m
         6           0.8086           0.0311            2.69m
         7           0.7690           0.0359            2.61m
         8           0.7569           0.0101            2.55m
         9           0.7488           0.0094            2.49m
        10           0.7254           0.0214            2.44m
        20           0.6434           0.0033            2.11m
        30           0.5979           0.0008            1.85m
        40           0.5679           0.0018            1.60m
        50           0.5494           0.0001            1.38m
        60           0.5267          -0.0001            1.15m
        70           0.5120           0.0002           54.93s
        80           0.5016           0.0005           41.03s
        90           0.4820          -0.0006           27.37s
       100           0.4682          -0.0006           13.65s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0396           0.1391            3.89m
         2           0.9766           0.0574            2.89m
         3           0.9241           0.0518            2.55m
         4           0.8753           0.0484            2.36m
         5           0.8411           0.0307            2.24m
         6           0.8145           0.0304            2.14m
         7           0.7920           0.0208            2.06m
         8           0.7780           0.0170            2.01m
         9           0.7598           0.0124            1.97m
        10           0.7498           0.0113            1.93m
        20           0.6535           0.0067            1.63m
        30           0.6022           0.0052            1.42m
        40           0.5688          -0.0002            1.23m
        50           0.5461           0.0010            1.04m
        60           0.5207          -0.0002           52.01s
        70           0.5000          -0.0005           41.57s
        80           0.4914          -0.0005           31.31s
        90           0.4732           0.0003           20.76s
       100           0.4570          -0.0001           10.38s
### Start Time 2019/11/05-20-08-36  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=966   randForSplit=707   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.93      0.91      0.92     28178
Train discard       0.89      0.92      0.91     23813

    micro avg       0.91      0.91      0.91     51991
    macro avg       0.91      0.91      0.91     51991
 weighted avg       0.91      0.91      0.91     51991

Train (keep) F2: 0.9118    P: 0.9289    R: 0.9076    NPV: 0.8936

['yes', 'no']
[[25575  2603]
 [ 1959 21854]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.88      0.87      5596
Valid discard       0.91      0.89      0.90      7463

    micro avg       0.88      0.88      0.88     13059
    macro avg       0.88      0.88      0.88     13059
 weighted avg       0.88      0.88      0.88     13059

Valid (keep) F2: 0.8730    P: 0.8533    R: 0.8781    NPV: 0.9066

['yes', 'no']
[[4914  682]
 [ 845 6618]]

### Note: searching for initial high learning rate.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__init: <__main__.Working_Init_Classifier instance at 0x1a1ac14cf8>
classifier__learning_rate: 0.5
classifier__max_depth: 5
classifier__max_features: 'sqrt'
classifier__min_samples_leaf: 50
classifier__min_samples_split: 500
classifier__n_estimators: 110
classifier__subsample: 0.8

### GridSearch Pipeline:
classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=966,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__init:[<__main__.Working_Init_Classifier instance at 0x1a1ac14cf8>]
classifier__learning_rate:[0.5, 0.1]
classifier__max_depth:[5]
classifier__max_features:['sqrt']
classifier__min_samples_leaf:[50]
classifier__min_samples_split:[500]
classifier__n_estimators:[65, 80, 95, 110]
classifier__subsample:[0.8]

### End Time 2019/11/05-23-17-45. Total  11349.30 seconds

Fitting 1 folds for each of 8 candidates, totalling 8 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0492           0.1314           39.32s
         2           0.8806           0.1799           27.95s
         3           0.8285           0.0444           23.75s
         4           0.7970           0.0286           20.95s
         5           0.7734           0.0216           18.91s
         6           0.7537           0.0130           17.22s
         7           0.7463           0.0107           15.74s
         8           0.7307           0.0069           14.29s
         9           0.7266           0.0091           12.94s
        10           0.7241           0.0026           11.65s
        20           0.6534           0.0010            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0492           0.1314            1.38m
         2           0.8806           0.1799            1.02m
         3           0.8285           0.0444           53.16s
         4           0.7970           0.0286           48.41s
         5           0.7734           0.0216           45.30s
         6           0.7537           0.0130           42.83s
         7           0.7463           0.0107           40.79s
         8           0.7307           0.0069           38.86s
         9           0.7266           0.0091           37.19s
        10           0.7241           0.0026           35.53s
        20           0.6534           0.0010           22.64s
        30           0.6068          -0.0019           11.12s
        40           0.5779           0.0020            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0492           0.1314            1.95m
         2           0.8806           0.1799            1.50m
         3           0.8285           0.0444            1.30m
         4           0.7970           0.0286            1.19m
         5           0.7734           0.0216            1.12m
         6           0.7537           0.0130            1.08m
         7           0.7463           0.0107            1.04m
         8           0.7307           0.0069            1.02m
         9           0.7266           0.0091           59.85s
        10           0.7241           0.0026           58.14s
        20           0.6534           0.0010           45.38s
        30           0.6068          -0.0019           32.88s
        40           0.5779           0.0020           21.57s
        50           0.5483           0.0003           10.68s
        60           0.5352          -0.0012            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0492           0.1314            2.79m
         2           0.8806           0.1799            2.08m
         3           0.8285           0.0444            1.84m
         4           0.7970           0.0286            1.70m
         5           0.7734           0.0216            1.61m
         6           0.7537           0.0130            1.54m
         7           0.7463           0.0107            1.49m
         8           0.7307           0.0069            1.44m
         9           0.7266           0.0091            1.41m
        10           0.7241           0.0026            1.37m
        20           0.6534           0.0010            1.13m
        30           0.6068          -0.0019           55.27s
        40           0.5779           0.0020           43.94s
        50           0.5483           0.0003           32.78s
        60           0.5352          -0.0012           21.79s
        70           0.5192          -0.0021           10.81s
        80           0.5088          -0.0021            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0680           0.1109           36.27s
         2           0.8920           0.1941           25.86s
         3           0.8587           0.0177           22.19s
         4           0.8383           0.0213           19.55s
         5           0.8225           0.0140           18.20s
         6           0.8082          -0.0002           16.40s
         7           0.8071           0.0026           14.95s
         8           0.7906          -0.0010           13.52s
         9           0.7870           0.0070           12.21s
        10           0.7844          -0.0074           11.03s
        20           0.7357          -0.0044            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0680           0.1109            1.27m
         2           0.8920           0.1941           58.72s
         3           0.8587           0.0177           50.06s
         4           0.8383           0.0213           47.11s
         5           0.8225           0.0140           43.93s
         6           0.8082          -0.0002           42.30s
         7           0.8071           0.0026           39.69s
         8           0.7906          -0.0010           38.48s
         9           0.7870           0.0070           36.42s
        10           0.7844          -0.0074           34.67s
        20           0.7357          -0.0044           21.76s
        30           0.6997          -0.0047           10.63s
        40           0.6872          -0.0004            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0680           0.1109            2.02m
         2           0.8920           0.1941            1.49m
         3           0.8587           0.0177            1.29m
         4           0.8383           0.0213            1.18m
         5           0.8225           0.0140            1.12m
         6           0.8082          -0.0002            1.08m
         7           0.8071           0.0026            1.05m
         8           0.7906          -0.0010            1.01m
         9           0.7870           0.0070           58.30s
        10           0.7844          -0.0074           56.66s
        20           0.7357          -0.0044           43.16s
        30           0.6997          -0.0047           32.02s
        40           0.6872          -0.0004           21.14s
        50           0.6691          -0.0071           10.49s
        60           0.6611          -0.0029            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0680           0.1109            2.78m
         2           0.8920           0.1941            2.01m
         3           0.8587           0.0177            1.75m
         4           0.8383           0.0213            1.64m
         5           0.8225           0.0140            1.54m
         6           0.8082          -0.0002            1.51m
         7           0.8071           0.0026            1.45m
         8           0.7906          -0.0010            1.41m
         9           0.7870           0.0070            1.37m
        10           0.7844          -0.0074            1.33m
        20           0.7357          -0.0044            1.08m
        30           0.6997          -0.0047           53.91s
        40           0.6872          -0.0004           42.84s
        50           0.6691          -0.0071           31.99s
        60           0.6611          -0.0029           21.23s
        70           0.6533          -0.0034           10.56s
        80           0.6399          -0.0063            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0731           0.1291            3.31m
         2           0.8625           0.2157            2.48m
         3           0.8293           0.0260            2.17m
         4           0.8057           0.0202            2.03m
         5           0.7762           0.0244            1.92m
         6           0.7569           0.0133            1.84m
         7           0.7527           0.0107            1.77m
         8           0.7336           0.0108            1.72m
         9           0.7266           0.0048            1.68m
        10           0.7178           0.0087            1.65m
        20           0.6480           0.0029            1.37m
        30           0.6135           0.0022            1.13m
        40           0.5871           0.0006           53.78s
        50           0.5682          -0.0001           40.32s
        60           0.5493          -0.0019           26.79s
        70           0.5357          -0.0023           13.37s
        80           0.5233          -0.0023            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0492           0.1314            2.66m
         2           0.8806           0.1799            2.00m
         3           0.8285           0.0444            1.77m
         4           0.7970           0.0286            1.62m
         5           0.7734           0.0216            1.54m
         6           0.7537           0.0130            1.47m
         7           0.7463           0.0107            1.44m
         8           0.7307           0.0069            1.40m
         9           0.7266           0.0091            1.36m
        10           0.7241           0.0026            1.33m
        20           0.6534           0.0010            1.09m
        30           0.6068          -0.0019           53.37s
        40           0.5779           0.0020           42.08s
        50           0.5483           0.0003           31.62s
        60           0.5352          -0.0012           21.10s
        70           0.5192          -0.0021           10.48s
        80           0.5088          -0.0021            0.00s
### Start Time 2019/11/06-16-35-56  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=549   randForSplit=863   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.90      0.91     28178
Train discard       0.88      0.90      0.89     23813

    micro avg       0.90      0.90      0.90     51991
    macro avg       0.90      0.90      0.90     51991
 weighted avg       0.90      0.90      0.90     51991

Train (keep) F2: 0.9018    P: 0.9151    R: 0.8985    NPV: 0.8825

['yes', 'no']
[[25319  2859]
 [ 2349 21464]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.87      0.85      5596
Valid discard       0.90      0.87      0.89      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.87      0.87      0.87     13059

Valid (keep) F2: 0.8642    P: 0.8389    R: 0.8708    NPV: 0.9003

['yes', 'no']
[[4873  723]
 [ 936 6527]]

### Note: Searching for initial high learning rate.
Looking for: smaller n_estimators for bigger learning rate.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 1.0
classifier__max_depth: 5
classifier__max_features: 'sqrt'
classifier__min_samples_leaf: 200
classifier__min_samples_split: 1000
classifier__n_estimators: 80
classifier__subsample: 0.8

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x1a6b907320>,
              learning_rate=1.0, loss='deviance', max_depth=5,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=200, min_samples_split=1000,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=549,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__learning_rate:[1.0, 1.5]
classifier__max_depth:[5]
classifier__max_features:['sqrt']
classifier__min_samples_leaf:[200]
classifier__min_samples_split:[1000]
classifier__n_estimators:[20, 40, 60, 80]
classifier__subsample:[0.8]

### Grid Search Scores:
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 20, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.844565
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 40, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.860839
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 60, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.861268
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.864222
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.5, 'classifier__n_estimators': 20, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.843709
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.5, 'classifier__n_estimators': 40, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.846885
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.5, 'classifier__n_estimators': 60, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.842037
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.5, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 5}
mean_test_score:  0.844517

### Grid Search Best Score: 0.864222

### End Time 2019/11/06-19-41-44. Total  11148.05 seconds

Fitting 1 folds for each of 9 candidates, totalling 9 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0697           0.1222            2.70m
         2           0.9953           0.0743            2.02m
         3           0.9539           0.0456            1.77m
         4           0.9221           0.0301            1.64m
         5           0.8494           0.0785            1.56m
         6           0.8313           0.0194            1.49m
         7           0.7972           0.0340            1.44m
         8           0.7836           0.0100            1.40m
         9           0.7670           0.0199            1.37m
        10           0.7577           0.0082            1.34m
        20           0.6979           0.0021            1.11m
        30           0.6495           0.0044           54.32s
        40           0.6188           0.0001           43.06s
        50           0.6048          -0.0008           32.07s
        60           0.5821          -0.0002           21.24s
        70           0.5775          -0.0011           10.60s
        80           0.5678          -0.0013            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0697           0.1222            2.69m
         2           0.9953           0.0743            1.99m
         3           0.9539           0.0456            1.72m
         4           0.9221           0.0301            1.60m
         5           0.8494           0.0785            1.51m
         6           0.8314           0.0196            1.47m
         7           0.7973           0.0340            1.42m
         8           0.7836           0.0099            1.38m
         9           0.7670           0.0199            1.35m
        10           0.7577           0.0082            1.32m
        20           0.6980           0.0023            1.08m
        30           0.6498           0.0053           52.89s
        40           0.6197          -0.0001           41.85s
        50           0.6042          -0.0011           31.19s
        60           0.5821           0.0017           20.73s
        70           0.5754          -0.0001           10.38s
        80           0.5658          -0.0011            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0697           0.1222            2.73m
         2           0.9953           0.0743            2.04m
         3           0.9539           0.0457            1.79m
         4           0.9221           0.0301            1.66m
         5           0.8494           0.0785            1.57m
         6           0.8317           0.0193            1.51m
         7           0.7976           0.0341            1.46m
         8           0.7837           0.0100            1.41m
         9           0.7673           0.0199            1.38m
        10           0.7580           0.0082            1.35m
        20           0.6973           0.0014            1.11m
        30           0.6456           0.0042           54.94s
        40           0.6244           0.0007           43.44s
        50           0.6081          -0.0019           32.30s
        60           0.5892          -0.0005           21.44s
        70           0.5844          -0.0003           10.72s
        80           0.5665          -0.0000            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9388           0.2560            2.80m
         2           0.8699           0.0655            2.03m
         3           0.8335           0.0406            1.83m
         4           0.8004           0.0272            1.72m
         5           0.7618           0.0448            1.66m
         6           0.7400           0.0149            1.56m
         7           0.7137           0.0256            1.49m
         8           0.7018           0.0077            1.44m
         9           0.6882           0.0051            1.39m
        10           0.6812           0.0014            1.36m
        20           0.6189          -0.0010            1.10m
        30           0.5759           0.0003           54.26s
        40           0.5428          -0.0044           42.69s
        50           0.5217          -0.0052           31.64s
        60           0.4958          -0.0033           20.92s
        70           0.4789          -0.0028           10.43s
        80           0.4632          -0.0021            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9397           0.2550            2.66m
         2           0.8705           0.0675            1.96m
         3           0.8334           0.0420            1.72m
         4           0.8013           0.0278            1.60m
         5           0.7620           0.0445            1.51m
         6           0.7386           0.0134            1.47m
         7           0.7136           0.0267            1.42m
         8           0.7039           0.0112            1.38m
         9           0.6901           0.0079            1.34m
        10           0.6841           0.0059            1.30m
        20           0.6213          -0.0012            1.08m
        30           0.5776          -0.0006           53.21s
        40           0.5458          -0.0020           42.10s
        50           0.5279           0.0000           31.52s
        60           0.5003           0.0004           20.91s
        70           0.4821          -0.0045           10.39s
        80           0.4671          -0.0025            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9489           0.2460            2.52m
         2           0.8764           0.0693            1.88m
         3           0.8383           0.0445            1.65m
         4           0.8073           0.0296            1.54m
         5           0.7661           0.0464            1.46m
         6           0.7415           0.0194            1.40m
         7           0.7167           0.0253            1.37m
         8           0.7074           0.0041            1.33m
         9           0.6949           0.0061            1.30m
        10           0.6881           0.0026            1.27m
        20           0.6173          -0.0012            1.05m
        30           0.5805          -0.0009           52.11s
        40           0.5489          -0.0027           41.16s
        50           0.5340          -0.0014           30.82s
        60           0.5074          -0.0024           20.57s
        70           0.4936          -0.0009           10.28s
        80           0.4787          -0.0024            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9289           0.2650            2.69m
         2           0.8451           0.0773            2.02m
         3           0.8038           0.0485            1.80m
         4           0.7679           0.0239            1.67m
         5           0.7224           0.0511            1.61m
         6           0.6933           0.0176            1.54m
         7           0.6730           0.0152            1.49m
         8           0.6617           0.0060            1.44m
         9           0.6498           0.0060            1.40m
        10           0.6445           0.0035            1.37m
        20           0.5671          -0.0014            1.13m
        30           0.5190          -0.0099           55.09s
        40           0.4761          -0.0034           43.58s
        50           0.4495          -0.0017           32.71s
        60           0.4095          -0.0013           21.69s
        70           0.3848          -0.0064           10.81s
        80           0.3567          -0.0041            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9116           0.2776            2.55m
         2           0.8286           0.0737            1.93m
         3           0.7921           0.0448            1.70m
         4           0.7605           0.0226            1.58m
         5           0.7216           0.0395            1.52m
         6           0.6949           0.0201            1.46m
         7           0.6770           0.0125            1.42m
         8           0.6673           0.0033            1.38m
         9           0.6562           0.0058            1.36m
        10           0.6493           0.0050            1.33m
        20           0.5734          -0.0004            1.12m
        30           0.5295          -0.0041           55.06s
        40           0.4880          -0.0065           43.95s
        50           0.4626          -0.0049           32.90s
        60           0.4338          -0.0033           21.83s
        70           0.4121          -0.0028           10.88s
        80           0.3867          -0.0022            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9167           0.2711            2.53m
         2           0.8355           0.0734            1.94m
         3           0.7975           0.0452            1.70m
         4           0.7638           0.0264            1.58m
         5           0.7259           0.0366            1.51m
         6           0.6991           0.0240            1.49m
         7           0.6782           0.0161            1.43m
         8           0.6683           0.0044            1.42m
         9           0.6538           0.0016            1.38m
        10           0.6497          -0.0012            1.35m
        20           0.5816           0.0008            1.11m
        30           0.5326          -0.0027           55.35s
        40           0.4986          -0.0026           43.67s
        50           0.4764          -0.0049           32.46s
        60           0.4399          -0.0067           21.56s
        70           0.4238          -0.0047           10.71s
        80           0.4045          -0.0038            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0853           0.1123            3.45m
         2           1.0299           0.0565            2.48m
         3           0.9797           0.0573            2.18m
         4           0.9184           0.0562            2.03m
         5           0.8509           0.0631            1.91m
         6           0.8378           0.0152            1.81m
         7           0.8232           0.0197            1.74m
         8           0.8000           0.0177            1.68m
         9           0.7876           0.0155            1.63m
        10           0.7615           0.0166            1.60m
        20           0.6993           0.0035            1.32m
        30           0.6679           0.0006            1.10m
        40           0.6436           0.0011           52.04s
        50           0.6226           0.0009           39.07s
        60           0.5993          -0.0006           26.04s
        70           0.5884          -0.0001           13.00s
        80           0.5805          -0.0002            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0697           0.1222            2.46m
         2           0.9953           0.0743            1.87m
         3           0.9539           0.0456            1.70m
         4           0.9221           0.0301            1.56m
         5           0.8494           0.0785            1.49m
         6           0.8314           0.0196            1.43m
         7           0.7973           0.0340            1.39m
         8           0.7836           0.0099            1.35m
         9           0.7670           0.0199            1.32m
        10           0.7577           0.0082            1.29m
        20           0.6980           0.0023            1.06m
        30           0.6498           0.0053           52.41s
        40           0.6197          -0.0001           41.54s
        50           0.6042          -0.0011           30.83s
        60           0.5821           0.0017           20.40s
        70           0.5754          -0.0001           10.23s
        80           0.5658          -0.0011            0.00s
### Start Time 2019/11/06-21-57-28  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=89   randForSplit=280   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.88      0.89     28178
Train discard       0.86      0.89      0.88     23813

    micro avg       0.89      0.89      0.89     51991
    macro avg       0.89      0.89      0.89     51991
 weighted avg       0.89      0.89      0.89     51991

Train (keep) F2: 0.8866    P: 0.9079    R: 0.8814    NPV: 0.8643

['yes', 'no']
[[24836  3342]
 [ 2519 21294]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.87      0.85      5596
Valid discard       0.90      0.87      0.89      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.87      0.87      0.87     13059

Valid (keep) F2: 0.8611    P: 0.8374    R: 0.8672    NPV: 0.8977

['yes', 'no']
[[4853  743]
 [ 942 6521]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Looking for max_depth and min_samples_split.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 1.0
classifier__max_depth: 3
classifier__max_features: 'sqrt'
classifier__min_samples_leaf: 200
classifier__min_samples_split: 750
classifier__n_estimators: 80
classifier__subsample: 0.8

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x1a7481c200>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=200, min_samples_split=750,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=89,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__learning_rate:[1.0]
classifier__max_depth:[3, 6, 9]
classifier__max_features:['sqrt']
classifier__min_samples_leaf:[200]
classifier__min_samples_split:[500, 750, 1000]
classifier__n_estimators:[80]
classifier__subsample:[0.8]

### Grid Search Scores:
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 500, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 3}
mean_test_score:  0.858527
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 750, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 3}
mean_test_score:  0.861102
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 3}
mean_test_score:  0.858948
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 500, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 6}
mean_test_score:  0.852236
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 750, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 6}
mean_test_score:  0.853551
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 6}
mean_test_score:  0.852059
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 500, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 9}
mean_test_score:  0.844500
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 750, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 9}
mean_test_score:  0.850452
{'classifier__max_features': 'sqrt', 'classifier__subsample': 0.8, 'classifier__min_samples_split': 1000, 'classifier__learning_rate': 1.0, 'classifier__n_estimators': 80, 'classifier__min_samples_leaf': 200, 'classifier__max_depth': 9}
mean_test_score:  0.852619

### Grid Search Best Score: 0.861102

### End Time 2019/11/07-01-22-48. Total  12319.68 seconds

Fitting 1 folds for each of 9 candidates, totalling 9 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.80m
         2           1.0427           0.0380            2.05m
         3           0.9984           0.0457            1.76m
         4           0.9624           0.0364            1.63m
         5           0.9355           0.0184            1.59m
         6           0.9135           0.0196            1.55m
         7           0.8881           0.0186            1.49m
         8           0.8850           0.0072            1.43m
         9           0.8568           0.0349            1.39m
        10           0.8282           0.0229            1.35m
        20           0.7054           0.0032            1.10m
        30           0.6657           0.0009           53.91s
        40           0.6369           0.0045           42.81s
        50           0.6135           0.0012           31.76s
        60           0.6018          -0.0001           21.11s
        70           0.5805           0.0000           10.54s
        80           0.5692          -0.0030            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.68m
         2           1.0427           0.0380            1.99m
         3           0.9984           0.0457            1.72m
         4           0.9624           0.0364            1.62m
         5           0.9355           0.0184            1.59m
         6           0.9138           0.0196            1.54m
         7           0.8885           0.0187            1.48m
         8           0.8854           0.0073            1.42m
         9           0.8570           0.0349            1.39m
        10           0.8283           0.0231            1.35m
        20           0.7055           0.0031            1.09m
        30           0.6640           0.0053           53.51s
        40           0.6292           0.0068           42.43s
        50           0.6101          -0.0012           31.68s
        60           0.6001           0.0008           21.01s
        70           0.5793           0.0009           10.46s
        80           0.5687          -0.0011            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.78m
         2           1.0427           0.0380            2.01m
         3           0.9984           0.0457            1.74m
         4           0.9624           0.0364            1.63m
         5           0.9355           0.0184            1.60m
         6           0.9138           0.0196            1.56m
         7           0.8885           0.0187            1.51m
         8           0.8854           0.0073            1.45m
         9           0.8570           0.0349            1.40m
        10           0.8283           0.0231            1.37m
        20           0.7055           0.0032            1.11m
        30           0.6660           0.0009           54.09s
        40           0.6378           0.0046           42.81s
        50           0.6151           0.0014           31.78s
        60           0.6017          -0.0017           21.01s
        70           0.5820           0.0018           10.45s
        80           0.5724          -0.0005            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.48m
         2           1.0427           0.0380            1.85m
         3           0.9986           0.0457            1.63m
         4           0.9625           0.0363            1.58m
         5           0.9357           0.0185            1.53m
         6           0.9140           0.0188            1.49m
         7           0.8888           0.0187            1.43m
         8           0.8855           0.0070            1.39m
         9           0.8573           0.0351            1.36m
        10           0.8289           0.0231            1.32m
        20           0.7068           0.0032            1.06m
        30           0.6681           0.0018           52.14s
        40           0.6364           0.0056           42.74s
        50           0.6153          -0.0004           32.04s
        60           0.6010           0.0003           21.23s
        70           0.5820          -0.0014           10.62s
        80           0.5719          -0.0023            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.66m
         2           1.0427           0.0380            1.98m
         3           0.9986           0.0457            1.77m
         4           0.9625           0.0363            1.65m
         5           0.9357           0.0186            1.61m
         6           0.9141           0.0194            1.56m
         7           0.8888           0.0187            1.51m
         8           0.8857           0.0070            1.46m
         9           0.8573           0.0351            1.42m
        10           0.8288           0.0230            1.39m
        20           0.7068           0.0032            1.13m
        30           0.6672           0.0021           55.00s
        40           0.6389           0.0057           43.30s
        50           0.6163           0.0001           32.16s
        60           0.6033          -0.0015           21.32s
        70           0.5837           0.0006           10.60s
        80           0.5723          -0.0009            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.71m
         2           1.0427           0.0380            1.98m
         3           0.9986           0.0457            1.74m
         4           0.9625           0.0363            1.63m
         5           0.9357           0.0186            1.58m
         6           0.9141           0.0194            1.54m
         7           0.8888           0.0187            1.49m
         8           0.8857           0.0070            1.45m
         9           0.8573           0.0351            1.41m
        10           0.8288           0.0230            1.36m
        20           0.7067           0.0032            1.11m
        30           0.6672           0.0021           54.50s
        40           0.6387           0.0059           43.39s
        50           0.6172           0.0003           32.62s
        60           0.6062          -0.0015           21.81s
        70           0.5868           0.0011           10.91s
        80           0.5751          -0.0020            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0805           0.0947            2.64m
         2           1.0426           0.0382            1.95m
         3           0.9988           0.0456            1.73m
         4           0.9627           0.0363            1.60m
         5           0.9361           0.0183            1.56m
         6           0.9143           0.0191            1.53m
         7           0.8902           0.0170            1.47m
         8           0.8871           0.0069            1.42m
         9           0.8587           0.0348            1.38m
        10           0.8289           0.0248            1.34m
        20           0.7068           0.0034            1.10m
        30           0.6665           0.0034           53.62s
        40           0.6346           0.0059           42.43s
        50           0.6153          -0.0006           31.63s
        60           0.6025          -0.0000           20.93s
        70           0.5832           0.0011           10.48s
        80           0.5746          -0.0009            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0805           0.0947            2.67m
         2           1.0426           0.0382            1.98m
         3           0.9988           0.0456            1.74m
         4           0.9627           0.0363            1.64m
         5           0.9361           0.0183            1.59m
         6           0.9143           0.0194            1.54m
         7           0.8903           0.0170            1.47m
         8           0.8872           0.0069            1.42m
         9           0.8587           0.0348            1.38m
        10           0.8289           0.0248            1.35m
        20           0.7068           0.0033            1.11m
        30           0.6674           0.0035           55.27s
        40           0.6354           0.0063           43.81s
        50           0.6141           0.0004           32.52s
        60           0.6021          -0.0010           21.52s
        70           0.5818           0.0024           10.73s
        80           0.5694          -0.0000            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0805           0.0947            2.68m
         2           1.0426           0.0382            1.98m
         3           0.9988           0.0456            1.73m
         4           0.9627           0.0363            1.60m
         5           0.9361           0.0183            1.57m
         6           0.9143           0.0194            1.52m
         7           0.8903           0.0170            1.46m
         8           0.8872           0.0069            1.41m
         9           0.8587           0.0348            1.36m
        10           0.8289           0.0248            1.33m
        20           0.7068           0.0033            1.09m
        30           0.6674           0.0036           53.81s
        40           0.6358           0.0064           42.83s
        50           0.6148          -0.0004           31.95s
        60           0.6031           0.0005           21.22s
        70           0.5831          -0.0007           10.59s
        80           0.5728          -0.0007            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0133           0.1875            3.51m
         2           0.9581           0.0575            2.54m
         3           0.9109           0.0483            2.29m
         4           0.8763           0.0331            2.14m
         5           0.8404           0.0297            2.02m
         6           0.8198           0.0286            1.95m
         7           0.7772           0.0352            1.89m
         8           0.7764           0.0087            1.84m
         9           0.7630           0.0057            1.84m
        10           0.7587           0.0122            1.78m
        20           0.6953           0.0038            1.42m
        30           0.6617           0.0045            1.17m
        40           0.6339           0.0013           55.23s
        50           0.6199           0.0015           40.91s
        60           0.6006          -0.0009           27.22s
        70           0.5851          -0.0007           13.60s
        80           0.5748          -0.0007            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0804           0.0942            2.61m
         2           1.0427           0.0380            1.96m
         3           0.9986           0.0457            1.71m
         4           0.9625           0.0363            1.61m
         5           0.9357           0.0185            1.58m
         6           0.9140           0.0188            1.54m
         7           0.8888           0.0187            1.47m
         8           0.8855           0.0070            1.43m
         9           0.8573           0.0351            1.39m
        10           0.8289           0.0231            1.35m
        20           0.7068           0.0032            1.11m
        30           0.6681           0.0018           54.13s
        40           0.6364           0.0056           42.64s
        50           0.6153          -0.0004           31.72s
        60           0.6010           0.0003           20.94s
        70           0.5820          -0.0014           10.47s
        80           0.5719          -0.0023            0.00s
### Start Time 2019/11/07-10-12-30  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=291   randForSplit=679   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.88      0.89     28178
Train discard       0.86      0.89      0.88     23813

    micro avg       0.89      0.89      0.89     51991
    macro avg       0.88      0.89      0.89     51991
 weighted avg       0.89      0.89      0.89     51991

Train (keep) F2: 0.8843    P: 0.9075    R: 0.8787    NPV: 0.8617

['yes', 'no']
[[24760  3418]
 [ 2523 21290]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.87      0.85      5596
Valid discard       0.90      0.88      0.89      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.87      0.87      0.87     13059

Valid (keep) F2: 0.8605    P: 0.8412    R: 0.8654    NPV: 0.8969

['yes', 'no']
[[4843  753]
 [ 914 6549]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking min_samples_split & min_samples_leaf.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__min_samples_leaf: 200
classifier__min_samples_split: 700

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x1af95bad40>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=200, min_samples_split=700,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=291,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__min_samples_leaf:[100, 200, 300]
classifier__min_samples_split:[700, 750, 800]

### Grid Search Scores:
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 700}
mean_test_score:  0.857371
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 750}
mean_test_score:  0.853225
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 800}
mean_test_score:  0.858037
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 700}
mean_test_score:  0.860488
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 750}
mean_test_score:  0.859178
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 800}
mean_test_score:  0.858821
{'classifier__min_samples_leaf': 300, 'classifier__min_samples_split': 700}
mean_test_score:  0.858056
{'classifier__min_samples_leaf': 300, 'classifier__min_samples_split': 750}
mean_test_score:  0.854657
{'classifier__min_samples_leaf': 300, 'classifier__min_samples_split': 800}
mean_test_score:  0.853142

### Grid Search Best Score: 0.860488

### End Time 2019/11/07-13-48-29. Total  12959.44 seconds

Fitting 1 folds for each of 12 candidates, totalling 12 fits
Fitting 1 folds for each of 12 candidates, totalling 12 fits
Fitting 1 folds for each of 12 candidates, totalling 12 fits
Fitting 1 folds for each of 12 candidates, totalling 12 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            1.91m
         2           0.9108           0.1337            1.48m
         3           0.8733           0.0344            1.33m
         4           0.8418           0.0284            1.25m
         5           0.8114           0.0316            1.21m
         6           0.8006           0.0098            1.16m
         7           0.7874           0.0131            1.13m
         8           0.7818           0.0062            1.10m
         9           0.7739           0.0020            1.08m
        10           0.7609           0.0101            1.06m
        20           0.6905           0.0001           52.62s
        30           0.6405           0.0018           43.46s
        40           0.6204          -0.0003           34.55s
        50           0.6006          -0.0006           25.79s
        60           0.5835          -0.0003           17.16s
        70           0.5704          -0.0002            8.56s
        80           0.5574           0.0006            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.15m
         2           0.9108           0.1337            1.64m
         3           0.8733           0.0344            1.45m
         4           0.8418           0.0284            1.35m
         5           0.8114           0.0316            1.29m
         6           0.8006           0.0098            1.24m
         7           0.7874           0.0131            1.20m
         8           0.7818           0.0062            1.17m
         9           0.7739           0.0020            1.14m
        10           0.7609           0.0101            1.12m
        20           0.6905           0.0001           55.27s
        30           0.6415           0.0027           45.37s
        40           0.6198          -0.0018           35.93s
        50           0.6023          -0.0016           26.80s
        60           0.5853          -0.0002           17.82s
        70           0.5706          -0.0013            8.89s
        80           0.5582          -0.0008            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.17m
         2           0.9108           0.1337            1.64m
         3           0.8733           0.0344            1.46m
         4           0.8418           0.0284            1.36m
         5           0.8114           0.0316            1.29m
         6           0.8006           0.0098            1.24m
         7           0.7874           0.0131            1.20m
         8           0.7818           0.0062            1.17m
         9           0.7739           0.0020            1.14m
        10           0.7609           0.0101            1.12m
        20           0.6905           0.0001           54.97s
        30           0.6415           0.0027           45.26s
        40           0.6199          -0.0018           35.96s
        50           0.6026          -0.0016           26.79s
        60           0.5858           0.0007           17.80s
        70           0.5713          -0.0001            8.90s
        80           0.5575          -0.0005            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.20m
         2           0.9108           0.1337            1.66m
         3           0.8733           0.0344            1.47m
         4           0.8418           0.0284            1.37m
         5           0.8114           0.0316            1.30m
         6           0.8006           0.0098            1.25m
         7           0.7874           0.0131            1.22m
         8           0.7818           0.0062            1.19m
         9           0.7739           0.0020            1.16m
        10           0.7609           0.0101            1.14m
        20           0.6905           0.0001           55.98s
        30           0.6414           0.0024           45.82s
        40           0.6204          -0.0016           36.37s
        50           0.6030           0.0002           27.12s
        60           0.5874          -0.0005           18.00s
        70           0.5723           0.0009            8.98s
        80           0.5604          -0.0003            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.19m
         2           0.9108           0.1337            1.67m
         3           0.8733           0.0344            1.48m
         4           0.8418           0.0284            1.37m
         5           0.8114           0.0316            1.31m
         6           0.8006           0.0098            1.26m
         7           0.7874           0.0131            1.22m
         8           0.7818           0.0063            1.19m
         9           0.7738           0.0020            1.15m
        10           0.7608           0.0099            1.13m
        20           0.6913          -0.0001           55.58s
        30           0.6427           0.0033           45.61s
        40           0.6197          -0.0010           36.08s
        50           0.5981          -0.0003           26.85s
        60           0.5845          -0.0000           17.83s
        70           0.5702           0.0004            8.88s
        80           0.5576          -0.0004            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.22m
         2           0.9108           0.1337            1.67m
         3           0.8733           0.0344            1.48m
         4           0.8418           0.0284            1.37m
         5           0.8114           0.0316            1.30m
         6           0.8006           0.0098            1.25m
         7           0.7874           0.0131            1.21m
         8           0.7818           0.0063            1.18m
         9           0.7738           0.0020            1.15m
        10           0.7608           0.0099            1.12m
        20           0.6906           0.0001           55.45s
        30           0.6414           0.0028           45.64s
        40           0.6201          -0.0011           36.22s
        50           0.6015          -0.0017           27.04s
        60           0.5868           0.0004           17.96s
        70           0.5722           0.0007            8.96s
        80           0.5576          -0.0005            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.19m
         2           0.9108           0.1337            1.65m
         3           0.8733           0.0344            1.46m
         4           0.8418           0.0284            1.36m
         5           0.8114           0.0316            1.30m
         6           0.8006           0.0098            1.25m
         7           0.7874           0.0131            1.21m
         8           0.7818           0.0063            1.17m
         9           0.7738           0.0020            1.14m
        10           0.7608           0.0099            1.12m
        20           0.6906           0.0001           55.40s
        30           0.6414           0.0028           45.60s
        40           0.6204          -0.0014           36.20s
        50           0.6027          -0.0004           27.02s
        60           0.5875           0.0004           17.97s
        70           0.5741          -0.0007            8.99s
        80           0.5612          -0.0002            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.24m
         2           0.9108           0.1337            1.69m
         3           0.8733           0.0344            1.58m
         4           0.8418           0.0284            1.45m
         5           0.8114           0.0316            1.38m
         6           0.8006           0.0098            1.32m
         7           0.7874           0.0131            1.27m
         8           0.7818           0.0063            1.23m
         9           0.7738           0.0020            1.20m
        10           0.7608           0.0099            1.17m
        20           0.6906           0.0001           56.90s
        30           0.6415           0.0028           46.39s
        40           0.6205          -0.0013           36.73s
        50           0.6032          -0.0020           27.40s
        60           0.5878           0.0007           18.16s
        70           0.5737           0.0004            9.07s
        80           0.5586          -0.0004            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.22m
         2           0.9106           0.1328            1.66m
         3           0.8732           0.0343            1.47m
         4           0.8429           0.0262            1.37m
         5           0.8125           0.0320            1.30m
         6           0.8018           0.0098            1.25m
         7           0.7884           0.0130            1.21m
         8           0.7827           0.0063            1.18m
         9           0.7755           0.0031            1.15m
        10           0.7621           0.0098            1.12m
        20           0.6917          -0.0001           55.12s
        30           0.6424           0.0028           45.18s
        40           0.6220          -0.0006           36.15s
        50           0.6038          -0.0006           27.03s
        60           0.5878           0.0004           17.96s
        70           0.5722          -0.0011            8.96s
        80           0.5590          -0.0003            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.23m
         2           0.9106           0.1328            1.67m
         3           0.8732           0.0343            1.48m
         4           0.8429           0.0262            1.38m
         5           0.8125           0.0320            1.31m
         6           0.8018           0.0098            1.26m
         7           0.7884           0.0130            1.22m
         8           0.7827           0.0063            1.18m
         9           0.7755           0.0031            1.15m
        10           0.7621           0.0098            1.13m
        20           0.6919          -0.0002           55.71s
        30           0.6426           0.0035           45.75s
        40           0.6214          -0.0009           36.29s
        50           0.6029          -0.0001           27.11s
        60           0.5887           0.0003           18.01s
        70           0.5749          -0.0001            8.97s
        80           0.5634          -0.0003            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.20m
         2           0.9106           0.1328            1.65m
         3           0.8732           0.0343            1.47m
         4           0.8429           0.0262            1.37m
         5           0.8125           0.0320            1.30m
         6           0.8018           0.0098            1.25m
         7           0.7884           0.0130            1.21m
         8           0.7827           0.0063            1.19m
         9           0.7755           0.0031            1.16m
        10           0.7621           0.0098            1.13m
        20           0.6919          -0.0002           56.16s
        30           0.6426           0.0035           46.14s
        40           0.6215          -0.0009           36.64s
        50           0.6039           0.0001           27.41s
        60           0.5892           0.0002           18.20s
        70           0.5747           0.0009            9.07s
        80           0.5629          -0.0002            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.18m
         2           0.9106           0.1328            1.65m
         3           0.8732           0.0343            1.46m
         4           0.8429           0.0262            1.36m
         5           0.8125           0.0320            1.30m
         6           0.8018           0.0098            1.25m
         7           0.7884           0.0130            1.21m
         8           0.7827           0.0063            1.18m
         9           0.7755           0.0031            1.15m
        10           0.7621           0.0098            1.12m
        20           0.6916          -0.0002           55.24s
        30           0.6417           0.0035           45.37s
        40           0.6206          -0.0007           36.00s
        50           0.6027           0.0004           26.89s
        60           0.5882           0.0026           17.84s
        70           0.5728          -0.0002            8.88s
        80           0.5589          -0.0010            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0417           0.1586            2.82m
         2           0.9962           0.0386            2.13m
         3           0.9429           0.0646            1.88m
         4           0.9148           0.0246            1.75m
         5           0.8769           0.0378            1.66m
         6           0.8572           0.0166            1.60m
         7           0.8180           0.0369            1.55m
         8           0.7966           0.0218            1.50m
         9           0.7829           0.0103            1.46m
        10           0.7778           0.0056            1.43m
        20           0.7043           0.0024            1.18m
        30           0.6596           0.0004           57.92s
        40           0.6360           0.0019           46.09s
        50           0.6161          -0.0001           34.48s
        60           0.6061          -0.0005           22.92s
        70           0.5887           0.0014           11.43s
        80           0.5818          -0.0002            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0488           0.1344            2.23m
         2           0.9108           0.1337            1.68m
         3           0.8733           0.0344            1.49m
         4           0.8418           0.0284            1.38m
         5           0.8114           0.0316            1.32m
         6           0.8006           0.0098            1.27m
         7           0.7874           0.0131            1.23m
         8           0.7818           0.0062            1.20m
         9           0.7739           0.0020            1.17m
        10           0.7609           0.0101            1.15m
        20           0.6905           0.0001           56.72s
        30           0.6405           0.0018           46.77s
        40           0.6204          -0.0003           37.11s
        50           0.6006          -0.0006           27.67s
        60           0.5835          -0.0003           18.38s
        70           0.5704          -0.0002            9.17s
        80           0.5574           0.0006            0.00s
### Start Time 2019/11/08-09-08-15  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=268   randForSplit=206   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.88      0.90     28178
Train discard       0.87      0.90      0.88     23813

    micro avg       0.89      0.89      0.89     51991
    macro avg       0.89      0.89      0.89     51991
 weighted avg       0.89      0.89      0.89     51991

Train (keep) F2: 0.8880    P: 0.9095    R: 0.8828    NPV: 0.8660

['yes', 'no']
[[24876  3302]
 [ 2475 21338]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.87      0.86      5596
Valid discard       0.90      0.88      0.89      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.88      0.87      0.88     13059

Valid (keep) F2: 0.8663    P: 0.8409    R: 0.8729    NPV: 0.9019

['yes', 'no']
[[4885  711]
 [ 924 6539]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking min_samples_split & min_samples_leaf.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__min_samples_leaf: 150
classifier__min_samples_split: 600

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7f79cac27200>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=268,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__min_samples_leaf:[150, 200, 250]
classifier__min_samples_split:[600, 650, 700, 725]

### Grid Search Scores:
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 600}
mean_test_score:  0.866350
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 650}
mean_test_score:  0.864309
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 700}
mean_test_score:  0.864408
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 725}
mean_test_score:  0.866224
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 600}
mean_test_score:  0.862987
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 650}
mean_test_score:  0.863564
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 700}
mean_test_score:  0.863244
{'classifier__min_samples_leaf': 200, 'classifier__min_samples_split': 725}
mean_test_score:  0.863985
{'classifier__min_samples_leaf': 250, 'classifier__min_samples_split': 600}
mean_test_score:  0.863851
{'classifier__min_samples_leaf': 250, 'classifier__min_samples_split': 650}
mean_test_score:  0.864248
{'classifier__min_samples_leaf': 250, 'classifier__min_samples_split': 700}
mean_test_score:  0.864149
{'classifier__min_samples_leaf': 250, 'classifier__min_samples_split': 725}
mean_test_score:  0.864992

### Grid Search Best Score: 0.866350

### End Time 2019/11/08-12-59-11. Total  13856.05 seconds

Fitting 1 folds for each of 20 candidates, totalling 20 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.21m
         2           0.9984           0.0308            1.66m
         3           0.9713           0.0303            1.46m
         4           0.8842           0.0818            1.37m
         5           0.8710           0.0139            1.31m
         6           0.8475           0.0264            1.26m
         7           0.8354           0.0093            1.24m
         8           0.8202           0.0070            1.20m
         9           0.8153           0.0075            1.17m
        10           0.8058           0.0070            1.14m
        20           0.7157           0.0020           55.96s
        30           0.6808           0.0017           45.82s
        40           0.6522           0.0009           36.39s
        50           0.6235          -0.0004           27.30s
        60           0.6068           0.0008           18.16s
        70           0.5931           0.0008            9.06s
        80           0.5763           0.0001            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.18m
         2           0.9984           0.0308            1.67m
         3           0.9713           0.0303            1.48m
         4           0.8842           0.0818            1.38m
         5           0.8710           0.0139            1.31m
         6           0.8475           0.0264            1.29m
         7           0.8354           0.0093            1.25m
         8           0.8202           0.0070            1.22m
         9           0.8153           0.0075            1.18m
        10           0.8058           0.0070            1.15m
        20           0.7157           0.0020           56.75s
        30           0.6808           0.0017           46.34s
        40           0.6522           0.0009           36.77s
        50           0.6237          -0.0004           27.42s
        60           0.6069           0.0008           18.21s
        70           0.5933           0.0006            9.09s
        80           0.5761          -0.0004            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.19m
         2           0.9984           0.0308            1.67m
         3           0.9713           0.0303            1.47m
         4           0.8842           0.0818            1.37m
         5           0.8710           0.0139            1.30m
         6           0.8475           0.0264            1.25m
         7           0.8354           0.0093            1.21m
         8           0.8202           0.0070            1.17m
         9           0.8153           0.0075            1.14m
        10           0.8058           0.0070            1.12m
        20           0.7157           0.0020           55.05s
        30           0.6808           0.0017           45.21s
        40           0.6522           0.0009           35.92s
        50           0.6241          -0.0021           26.82s
        60           0.6082          -0.0020           17.83s
        70           0.5971          -0.0005            8.89s
        80           0.5800           0.0002            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.32m
         2           0.9984           0.0308            1.73m
         3           0.9713           0.0303            1.53m
         4           0.8842           0.0818            1.41m
         5           0.8710           0.0139            1.34m
         6           0.8475           0.0264            1.29m
         7           0.8354           0.0093            1.25m
         8           0.8202           0.0070            1.22m
         9           0.8153           0.0075            1.19m
        10           0.8058           0.0070            1.17m
        20           0.7159           0.0020           57.09s
        30           0.6810           0.0017           46.61s
        40           0.6522           0.0009           36.95s
        50           0.6241          -0.0021           27.50s
        60           0.6082          -0.0020           18.28s
        70           0.5973          -0.0005            9.11s
        80           0.5801          -0.0003            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.19m
         2           0.9984           0.0308            1.66m
         3           0.9713           0.0303            1.47m
         4           0.8842           0.0818            1.37m
         5           0.8710           0.0139            1.30m
         6           0.8475           0.0264            1.25m
         7           0.8354           0.0093            1.21m
         8           0.8202           0.0070            1.17m
         9           0.8153           0.0075            1.14m
        10           0.8058           0.0070            1.12m
        20           0.7159           0.0020           55.50s
        30           0.6811           0.0017           45.71s
        40           0.6523           0.0009           36.27s
        50           0.6242          -0.0021           27.10s
        60           0.6083          -0.0020           18.01s
        70           0.5976          -0.0006            9.00s
        80           0.5786          -0.0016            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.21m
         2           0.9984           0.0308            1.68m
         3           0.9713           0.0303            1.49m
         4           0.8842           0.0818            1.38m
         5           0.8710           0.0139            1.32m
         6           0.8475           0.0264            1.27m
         7           0.8354           0.0095            1.23m
         8           0.8204           0.0073            1.19m
         9           0.8153           0.0075            1.16m
        10           0.8058           0.0070            1.13m
        20           0.7158           0.0018           55.99s
        30           0.6798           0.0020           46.00s
        40           0.6548           0.0001           36.46s
        50           0.6239          -0.0019           27.32s
        60           0.6048           0.0012           18.16s
        70           0.5953           0.0015            9.06s
        80           0.5795          -0.0012            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.20m
         2           0.9984           0.0308            1.67m
         3           0.9713           0.0303            1.47m
         4           0.8842           0.0818            1.37m
         5           0.8710           0.0139            1.30m
         6           0.8475           0.0264            1.25m
         7           0.8354           0.0095            1.21m
         8           0.8204           0.0073            1.18m
         9           0.8153           0.0075            1.15m
        10           0.8058           0.0070            1.12m
        20           0.7158           0.0018           55.47s
        30           0.6798           0.0020           45.74s
        40           0.6548           0.0001           36.27s
        50           0.6241          -0.0018           27.08s
        60           0.6049           0.0016           17.99s
        70           0.5951           0.0016            8.97s
        80           0.5784          -0.0010            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.26m
         2           0.9984           0.0308            1.72m
         3           0.9713           0.0303            1.52m
         4           0.8842           0.0818            1.41m
         5           0.8710           0.0139            1.33m
         6           0.8475           0.0264            1.28m
         7           0.8354           0.0095            1.24m
         8           0.8204           0.0073            1.20m
         9           0.8153           0.0075            1.17m
        10           0.8058           0.0070            1.14m
        20           0.7158           0.0018           56.18s
        30           0.6801           0.0021           46.04s
        40           0.6531          -0.0010           36.47s
        50           0.6232          -0.0005           27.19s
        60           0.6054           0.0039           18.06s
        70           0.5936           0.0012            9.01s
        80           0.5767          -0.0014            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.22m
         2           0.9984           0.0308            1.68m
         3           0.9713           0.0303            1.50m
         4           0.8842           0.0818            1.39m
         5           0.8710           0.0139            1.32m
         6           0.8475           0.0264            1.27m
         7           0.8354           0.0095            1.23m
         8           0.8204           0.0073            1.20m
         9           0.8153           0.0075            1.16m
        10           0.8058           0.0070            1.14m
        20           0.7160           0.0018           56.33s
        30           0.6799           0.0021           46.30s
        40           0.6549           0.0001           36.74s
        50           0.6244          -0.0018           27.48s
        60           0.6049           0.0014           18.26s
        70           0.5941           0.0013            9.11s
        80           0.5770          -0.0012            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.15m
         2           0.9984           0.0308            1.63m
         3           0.9713           0.0303            1.45m
         4           0.8842           0.0818            1.35m
         5           0.8710           0.0139            1.29m
         6           0.8475           0.0264            1.24m
         7           0.8354           0.0095            1.20m
         8           0.8204           0.0073            1.17m
         9           0.8153           0.0075            1.14m
        10           0.8058           0.0070            1.11m
        20           0.7160           0.0018           55.16s
        30           0.6804           0.0021           45.41s
        40           0.6539          -0.0011           36.12s
        50           0.6238          -0.0022           26.99s
        60           0.6066          -0.0006           17.99s
        70           0.5971           0.0013            8.97s
        80           0.5787          -0.0014            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.28m
         2           0.9984           0.0308            1.71m
         3           0.9714           0.0305            1.52m
         4           0.8843           0.0817            1.42m
         5           0.8710           0.0136            1.35m
         6           0.8475           0.0264            1.29m
         7           0.8355           0.0094            1.25m
         8           0.8205           0.0073            1.22m
         9           0.8154           0.0075            1.19m
        10           0.8060           0.0074            1.16m
        20           0.7171           0.0024           57.40s
        30           0.6806           0.0015           46.93s
        40           0.6526          -0.0001           37.10s
        50           0.6224          -0.0022           27.56s
        60           0.6063           0.0033           18.28s
        70           0.5931          -0.0001            9.09s
        80           0.5802          -0.0009            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.23m
         2           0.9984           0.0308            1.68m
         3           0.9714           0.0305            1.48m
         4           0.8843           0.0817            1.38m
         5           0.8710           0.0136            1.31m
         6           0.8475           0.0264            1.26m
         7           0.8355           0.0094            1.22m
         8           0.8205           0.0073            1.19m
         9           0.8154           0.0075            1.16m
        10           0.8060           0.0074            1.13m
        20           0.7171           0.0024           56.22s
        30           0.6806           0.0015           46.10s
        40           0.6526          -0.0001           36.58s
        50           0.6222          -0.0022           27.28s
        60           0.6060           0.0028           18.13s
        70           0.5921          -0.0000            9.05s
        80           0.5798          -0.0012            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.17m
         2           0.9984           0.0308            1.65m
         3           0.9714           0.0305            1.47m
         4           0.8843           0.0817            1.36m
         5           0.8710           0.0136            1.30m
         6           0.8475           0.0264            1.25m
         7           0.8355           0.0094            1.21m
         8           0.8205           0.0073            1.18m
         9           0.8154           0.0075            1.15m
        10           0.8060           0.0074            1.12m
        20           0.7172           0.0020           55.53s
        30           0.6813           0.0014           45.76s
        40           0.6533          -0.0021           36.34s
        50           0.6263           0.0010           27.16s
        60           0.6070          -0.0017           18.07s
        70           0.5938           0.0005            9.03s
        80           0.5783          -0.0013            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.20m
         2           0.9984           0.0308            1.67m
         3           0.9714           0.0305            1.47m
         4           0.8843           0.0817            1.37m
         5           0.8710           0.0136            1.30m
         6           0.8475           0.0264            1.25m
         7           0.8355           0.0094            1.21m
         8           0.8205           0.0073            1.18m
         9           0.8154           0.0075            1.15m
        10           0.8060           0.0074            1.12m
        20           0.7174           0.0020           55.43s
        30           0.6815           0.0014           45.48s
        40           0.6533          -0.0021           36.08s
        50           0.6276          -0.0006           26.95s
        60           0.6083           0.0005           17.93s
        70           0.5947           0.0006            8.94s
        80           0.5824          -0.0009            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.18m
         2           0.9984           0.0308            1.66m
         3           0.9714           0.0305            1.48m
         4           0.8843           0.0817            1.37m
         5           0.8710           0.0136            1.30m
         6           0.8475           0.0264            1.25m
         7           0.8355           0.0094            1.21m
         8           0.8205           0.0073            1.18m
         9           0.8154           0.0075            1.16m
        10           0.8060           0.0074            1.13m
        20           0.7165           0.0004           55.89s
        30           0.6814           0.0020           45.88s
        40           0.6527           0.0007           36.41s
        50           0.6221          -0.0021           27.16s
        60           0.6067          -0.0017           18.06s
        70           0.5955           0.0004            9.03s
        80           0.5798          -0.0019            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.30m
         2           0.9984           0.0308            1.72m
         3           0.9714           0.0303            1.50m
         4           0.8844           0.0817            1.39m
         5           0.8710           0.0136            1.31m
         6           0.8476           0.0263            1.26m
         7           0.8356           0.0094            1.22m
         8           0.8205           0.0073            1.19m
         9           0.8152           0.0072            1.16m
        10           0.8061           0.0079            1.13m
        20           0.7172           0.0024           55.52s
        30           0.6825           0.0003           45.71s
        40           0.6581          -0.0001           36.35s
        50           0.6257          -0.0023           27.17s
        60           0.6104          -0.0002           18.10s
        70           0.5978           0.0009            9.03s
        80           0.5857          -0.0019            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.19m
         2           0.9984           0.0308            1.67m
         3           0.9714           0.0303            1.47m
         4           0.8844           0.0817            1.37m
         5           0.8710           0.0136            1.30m
         6           0.8476           0.0263            1.25m
         7           0.8356           0.0094            1.21m
         8           0.8205           0.0073            1.18m
         9           0.8152           0.0072            1.15m
        10           0.8061           0.0079            1.12m
        20           0.7172           0.0024           55.48s
        30           0.6825           0.0003           45.70s
        40           0.6581          -0.0001           36.28s
        50           0.6259          -0.0023           27.08s
        60           0.6097           0.0004           18.01s
        70           0.5969           0.0009            8.98s
        80           0.5851          -0.0027            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.16m
         2           0.9984           0.0308            1.64m
         3           0.9714           0.0303            1.45m
         4           0.8844           0.0817            1.35m
         5           0.8710           0.0136            1.29m
         6           0.8476           0.0263            1.24m
         7           0.8356           0.0094            1.20m
         8           0.8205           0.0073            1.17m
         9           0.8152           0.0072            1.14m
        10           0.8061           0.0079            1.11m
        20           0.7173           0.0024           54.94s
        30           0.6820           0.0002           45.16s
        40           0.6532          -0.0004           35.79s
        50           0.6242          -0.0017           26.76s
        60           0.6079          -0.0003           17.84s
        70           0.5943           0.0001            8.91s
        80           0.5825          -0.0016            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.16m
         2           0.9984           0.0308            1.65m
         3           0.9714           0.0303            1.46m
         4           0.8844           0.0817            1.36m
         5           0.8710           0.0136            1.29m
         6           0.8476           0.0263            1.24m
         7           0.8356           0.0094            1.20m
         8           0.8205           0.0073            1.17m
         9           0.8152           0.0072            1.14m
        10           0.8061           0.0079            1.12m
        20           0.7165           0.0004           55.03s
        30           0.6830           0.0021           45.20s
        40           0.6517           0.0007           35.86s
        50           0.6227          -0.0012           26.88s
        60           0.6087           0.0009           17.87s
        70           0.5986           0.0004            8.93s
        80           0.5827          -0.0029            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.15m
         2           0.9984           0.0308            1.63m
         3           0.9714           0.0303            1.45m
         4           0.8844           0.0817            1.34m
         5           0.8710           0.0136            1.28m
         6           0.8476           0.0263            1.23m
         7           0.8356           0.0094            1.19m
         8           0.8205           0.0073            1.16m
         9           0.8152           0.0072            1.13m
        10           0.8061           0.0079            1.11m
        20           0.7165           0.0004           54.55s
        30           0.6830           0.0021           44.77s
        40           0.6517           0.0007           35.71s
        50           0.6227          -0.0012           26.72s
        60           0.6086           0.0009           17.78s
        70           0.5986           0.0004            8.88s
        80           0.5827          -0.0029            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9937           0.2026            2.86m
         2           0.9415           0.0525            2.15m
         3           0.9218           0.0194            1.91m
         4           0.8907           0.0358            1.78m
         5           0.8738           0.0122            1.70m
         6           0.8437           0.0232            1.63m
         7           0.8215           0.0265            1.58m
         8           0.7938           0.0273            1.53m
         9           0.7820           0.0163            1.49m
        10           0.7826           0.0037            1.46m
        20           0.7168           0.0019            1.20m
        30           0.6776           0.0013           59.32s
        40           0.6531           0.0002           47.08s
        50           0.6346           0.0003           35.17s
        60           0.6147           0.0003           23.38s
        70           0.5984          -0.0000           11.67s
        80           0.5861          -0.0003            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0283           0.1515            2.26m
         2           0.9984           0.0308            1.72m
         3           0.9714           0.0305            1.52m
         4           0.8843           0.0817            1.41m
         5           0.8710           0.0136            1.34m
         6           0.8475           0.0264            1.29m
         7           0.8355           0.0094            1.25m
         8           0.8205           0.0073            1.22m
         9           0.8154           0.0075            1.18m
        10           0.8060           0.0074            1.16m
        20           0.7165           0.0004           56.91s
        30           0.6814           0.0020           47.12s
        40           0.6527           0.0007           37.36s
        50           0.6221          -0.0021           27.90s
        60           0.6067          -0.0017           18.54s
        70           0.5955           0.0004            9.24s
        80           0.5798          -0.0019            0.00s
### Start Time 2019/11/09-17-02-14  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=48   randForSplit=708   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.90      0.88      0.89     28178
Train discard       0.86      0.89      0.87     23813

    micro avg       0.88      0.88      0.88     51991
    macro avg       0.88      0.88      0.88     51991
 weighted avg       0.88      0.88      0.88     51991

Train (keep) F2: 0.8830    P: 0.9023    R: 0.8783    NPV: 0.8604

['yes', 'no']
[[24748  3430]
 [ 2680 21133]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.83      0.87      0.85      5596
Valid discard       0.90      0.87      0.88      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.87      0.87      0.87     13059

Valid (keep) F2: 0.8610    P: 0.8337    R: 0.8681    NPV: 0.8980

['yes', 'no']
[[4858  738]
 [ 969 6494]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking min_samples_split & min_samples_leaf.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__min_samples_leaf: 150
classifier__min_samples_split: 625

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7fc3d81c1dd0>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features='sqrt', max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=625,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=48,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__min_samples_leaf:[100, 125, 150, 175]
classifier__min_samples_split:[525, 550, 575, 600, 625]

### Grid Search Scores:
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 525}
mean_test_score:  0.857092
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 550}
mean_test_score:  0.857488
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 575}
mean_test_score:  0.855576
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 600}
mean_test_score:  0.855581
{'classifier__min_samples_leaf': 100, 'classifier__min_samples_split': 625}
mean_test_score:  0.854828
{'classifier__min_samples_leaf': 125, 'classifier__min_samples_split': 525}
mean_test_score:  0.856550
{'classifier__min_samples_leaf': 125, 'classifier__min_samples_split': 550}
mean_test_score:  0.858588
{'classifier__min_samples_leaf': 125, 'classifier__min_samples_split': 575}
mean_test_score:  0.854481
{'classifier__min_samples_leaf': 125, 'classifier__min_samples_split': 600}
mean_test_score:  0.857052
{'classifier__min_samples_leaf': 125, 'classifier__min_samples_split': 625}
mean_test_score:  0.856945
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 525}
mean_test_score:  0.858212
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 550}
mean_test_score:  0.857817
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 575}
mean_test_score:  0.855006
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 600}
mean_test_score:  0.859544
{'classifier__min_samples_leaf': 150, 'classifier__min_samples_split': 625}
mean_test_score:  0.861012
{'classifier__min_samples_leaf': 175, 'classifier__min_samples_split': 525}
mean_test_score:  0.856874
{'classifier__min_samples_leaf': 175, 'classifier__min_samples_split': 550}
mean_test_score:  0.857057
{'classifier__min_samples_leaf': 175, 'classifier__min_samples_split': 575}
mean_test_score:  0.857772
{'classifier__min_samples_leaf': 175, 'classifier__min_samples_split': 600}
mean_test_score:  0.856198
{'classifier__min_samples_leaf': 175, 'classifier__min_samples_split': 625}
mean_test_score:  0.856198

### Grid Search Best Score: 0.861012

### End Time 2019/11/09-23-11-47. Total  22172.83 seconds

Fitting 1 folds for each of 6 candidates, totalling 6 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0750           0.1072            2.25m
         2           0.9854           0.0925            1.73m
         3           0.9539           0.0283            1.52m
         4           0.9123           0.0437            1.41m
         5           0.8922           0.0161            1.33m
         6           0.8488           0.0450            1.29m
         7           0.8342           0.0207            1.24m
         8           0.8229           0.0107            1.21m
         9           0.8103           0.0083            1.18m
        10           0.7939           0.0115            1.15m
        20           0.7170           0.0025           56.62s
        30           0.6605           0.0011           46.62s
        40           0.6300          -0.0005           36.93s
        50           0.6125          -0.0009           27.56s
        60           0.5902          -0.0008           18.37s
        70           0.5788          -0.0004            9.15s
        80           0.5653          -0.0005            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9615           0.2237            2.27m
         2           0.8660           0.0952            1.74m
         3           0.8350           0.0303            1.59m
         4           0.8119           0.0239            1.50m
         5           0.7856           0.0225            1.43m
         6           0.7556           0.0241            1.38m
         7           0.7399           0.0197            1.33m
         8           0.7336           0.0064            1.29m
         9           0.7210           0.0061            1.26m
        10           0.7074           0.0207            1.23m
        20           0.6467          -0.0026           59.78s
        30           0.6087           0.0015           48.88s
        40           0.5878          -0.0000           38.79s
        50           0.5718          -0.0024           28.99s
        60           0.5571          -0.0032           19.26s
        70           0.5447          -0.0024            9.60s
        80           0.5306          -0.0018            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9065           0.2870            2.43m
         2           0.8084           0.1005            1.86m
         3           0.7804           0.0227            1.67m
         4           0.7538           0.0222            1.55m
         5           0.7367           0.0191            1.49m
         6           0.7218           0.0142            1.43m
         7           0.7104           0.0085            1.39m
         8           0.7026           0.0113            1.35m
         9           0.6854           0.0116            1.31m
        10           0.6766           0.0076            1.29m
        20           0.6182           0.0002            1.06m
        30           0.5885          -0.0002           51.98s
        40           0.5641           0.0027           41.40s
        50           0.5444          -0.0011           30.92s
        60           0.5351          -0.0003           20.57s
        70           0.5197          -0.0013           10.26s
        80           0.5082          -0.0026            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8924           0.2889            2.67m
         2           0.8193           0.0758            2.08m
         3           0.7732           0.0467            1.87m
         4           0.7401           0.0366            1.76m
         5           0.7195           0.0148            1.70m
         6           0.7069           0.0130            1.63m
         7           0.6968           0.0071            1.57m
         8           0.6894           0.0109            1.53m
         9           0.6764           0.0104            1.49m
        10           0.6669           0.0093            1.45m
        20           0.6100           0.0003            1.19m
        30           0.5778          -0.0021           58.82s
        40           0.5554          -0.0005           46.65s
        50           0.5394          -0.0018           34.86s
        60           0.5270          -0.0016           23.16s
        70           0.5162          -0.0027           11.55s
        80           0.5018          -0.0021            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8922           0.2938            2.76m
         2           0.8035           0.0898            2.22m
         3           0.7678           0.0313            2.05m
         4           0.7379           0.0286            1.94m
         5           0.7190           0.0160            1.87m
         6           0.7060           0.0110            1.80m
         7           0.6951           0.0088            1.77m
         8           0.6855           0.0133            1.73m
         9           0.6736           0.0072            1.69m
        10           0.6676           0.0045            1.65m
        20           0.6144           0.0019            1.34m
        30           0.5806          -0.0013            1.11m
        40           0.5538          -0.0029           52.99s
        50           0.5406          -0.0033           39.38s
        60           0.5228          -0.0027           26.13s
        70           0.5109           0.0001           13.03s
        80           0.4979          -0.0018            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8659           0.3117            3.18m
         2           0.7827           0.0885            2.59m
         3           0.7469           0.0334            2.35m
         4           0.7297           0.0108            2.18m
         5           0.7140           0.0144            2.09m
         6           0.6993           0.0165            2.01m
         7           0.6914           0.0054            1.94m
         8           0.6841           0.0066            1.88m
         9           0.6708           0.0081            1.84m
        10           0.6657           0.0073            1.80m
        20           0.6062           0.0006            1.51m
        30           0.5703          -0.0015            1.25m
        40           0.5478           0.0002           59.65s
        50           0.5319          -0.0028           44.84s
        60           0.5149           0.0005           29.81s
        70           0.4979          -0.0009           14.88s
        80           0.4862          -0.0025            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8859           0.3176            4.00m
         2           0.7883           0.0893            3.27m
         3           0.7563           0.0389            2.98m
         4           0.7292           0.0193            2.82m
         5           0.7141           0.0158            2.69m
         6           0.7026           0.0106            2.60m
         7           0.6913           0.0114            2.54m
         8           0.6828           0.0084            2.48m
         9           0.6707           0.0068            2.41m
        10           0.6652           0.0071            2.35m
        20           0.6099          -0.0007            1.93m
        30           0.5798          -0.0017            1.59m
        40           0.5615          -0.0016            1.26m
        50           0.5463          -0.0015           56.51s
        60           0.5350          -0.0019           37.56s
        70           0.5131           0.0005           18.75s
        80           0.5044          -0.0018            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8659           0.3117            3.21m
         2           0.7827           0.0885            2.63m
         3           0.7469           0.0334            2.38m
         4           0.7297           0.0108            2.21m
         5           0.7140           0.0144            2.11m
         6           0.6993           0.0165            2.02m
         7           0.6914           0.0054            1.95m
         8           0.6841           0.0066            1.90m
         9           0.6708           0.0081            1.86m
        10           0.6657           0.0073            1.82m
        20           0.6062           0.0006            1.52m
        30           0.5703          -0.0015            1.26m
        40           0.5478           0.0002           59.94s
        50           0.5319          -0.0028           44.81s
        60           0.5149           0.0005           29.77s
        70           0.4979          -0.0009           14.84s
        80           0.4862          -0.0025            0.00s
### Start Time 2019/11/10-10-42-11  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=261   randForSplit=12   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.90      0.91     28178
Train discard       0.89      0.90      0.89     23813

    micro avg       0.90      0.90      0.90     51991
    macro avg       0.90      0.90      0.90     51991
 weighted avg       0.90      0.90      0.90     51991

Train (keep) F2: 0.9043    P: 0.9132    R: 0.9021    NPV: 0.8858

['yes', 'no']
[[25419  2759]
 [ 2417 21396]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      5596
Valid discard       0.91      0.87      0.89      7463

    micro avg       0.87      0.87      0.87     13059
    macro avg       0.87      0.87      0.87     13059
 weighted avg       0.88      0.87      0.87     13059

Valid (keep) F2: 0.8701    P: 0.8355    R: 0.8792    NPV: 0.9057

['yes', 'no']
[[4920  676]
 [ 969 6494]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking at max_features.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__max_features: 0.4

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7f9ea7a60ef0>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features=0.4, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=261,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__max_features:['sqrt', 0.05, 0.1, 0.2, 0.3, 0.4]

### Grid Search Scores:
{'classifier__max_features': 'sqrt'}
mean_test_score:  0.860666
{'classifier__max_features': 0.05}
mean_test_score:  0.862509
{'classifier__max_features': 0.1}
mean_test_score:  0.866844
{'classifier__max_features': 0.2}
mean_test_score:  0.863981
{'classifier__max_features': 0.3}
mean_test_score:  0.864530
{'classifier__max_features': 0.4}
mean_test_score:  0.870088

### Grid Search Best Score: 0.870088

### Feature weights: highest 20
+0.2956	wild_typ
+0.1430	wild_typ mice
+0.0904	cre
+0.0808	mice figur
+0.0394	transgen mice
+0.0364	litterm
+0.0345	mut_mut
+0.0163	genotyp
+0.0158	knock_out mice
+0.0097	relat figur
+0.0069	xenograft
+0.0066	inocul
+0.0061	embryonic_day embryonic_day
+0.0057	section
+0.0055	mice strain
+0.0049	pdf file
+0.0046	clinic
+0.0042	defici mice
+0.0030	mice model
+0.0029	replic

### Feature weights: lowest 20
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 969
24550541
29406270
27617678
30098187
28883554

### False negatives for Validation set: 676
28580947
25591872
29953499
27977701
28062700

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/10-12-59-21. Total   8230.63 seconds

Fitting 1 folds for each of 7 candidates, totalling 7 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8437           0.3279            3.05m
         2           0.7813           0.0664            2.51m
         3           0.7346           0.0410            2.29m
         4           0.7166           0.0168            2.19m
         5           0.7010           0.0132            2.07m
         6           0.6917           0.0086            2.00m
         7           0.6837           0.0074            1.95m
         8           0.6724           0.0126            1.89m
         9           0.6610           0.0076            1.85m
        10           0.6537           0.0078            1.82m
        20           0.5915           0.0019            1.51m
        30           0.5680           0.0021            1.24m
        40           0.5480          -0.0006           59.02s
        50           0.5271          -0.0006           44.27s
        60           0.5152          -0.0017           29.44s
        70           0.4956          -0.0046           14.71s
        80           0.4900          -0.0019            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8603           0.3120            3.27m
         2           0.7823           0.0836            2.74m
         3           0.7409           0.0363            2.50m
         4           0.7198           0.0193            2.34m
         5           0.7026           0.0149            2.22m
         6           0.6922           0.0167            2.18m
         7           0.6774           0.0140            2.14m
         8           0.6692           0.0079            2.10m
         9           0.6564           0.0074            2.03m
        10           0.6494           0.0078            1.98m
        20           0.5888          -0.0000            1.67m
        30           0.5649          -0.0004            1.36m
        40           0.5464          -0.0003            1.08m
        50           0.5214          -0.0001           48.57s
        60           0.5140           0.0000           32.23s
        70           0.5001          -0.0025           16.01s
        80           0.4911          -0.0025            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8493           0.3247            3.51m
         2           0.7728           0.0817            2.93m
         3           0.7312           0.0371            2.72m
         4           0.7082           0.0187            2.56m
         5           0.6909           0.0126            2.49m
         6           0.6863           0.0077            2.38m
         7           0.6714           0.0131            2.33m
         8           0.6634           0.0090            2.26m
         9           0.6555           0.0054            2.20m
        10           0.6457           0.0039            2.14m
        20           0.5882           0.0015            1.80m
        30           0.5620           0.0024            1.47m
        40           0.5375          -0.0013            1.18m
        50           0.5205          -0.0014           52.81s
        60           0.5071          -0.0011           34.91s
        70           0.4944          -0.0010           17.34s
        80           0.4830          -0.0012            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8553           0.3086            3.78m
         2           0.7754           0.0874            3.14m
         3           0.7414           0.0320            2.94m
         4           0.7244           0.0160            2.73m
         5           0.7044           0.0155            2.60m
         6           0.6949           0.0151            2.52m
         7           0.6827           0.0055            2.48m
         8           0.6774           0.0066            2.41m
         9           0.6695           0.0040            2.34m
        10           0.6582           0.0050            2.28m
        20           0.5962           0.0024            1.90m
        30           0.5679           0.0005            1.56m
        40           0.5462          -0.0025            1.24m
        50           0.5281          -0.0010           55.46s
        60           0.5155           0.0005           36.93s
        70           0.5009          -0.0018           18.48s
        80           0.4921          -0.0020            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8367           0.3355            4.00m
         2           0.7694           0.0660            3.38m
         3           0.7341           0.0364            3.12m
         4           0.7138           0.0200            2.91m
         5           0.6967           0.0124            2.77m
         6           0.6882           0.0103            2.75m
         7           0.6777           0.0063            2.67m
         8           0.6725           0.0063            2.59m
         9           0.6611           0.0069            2.56m
        10           0.6472           0.0112            2.50m
        20           0.5908           0.0013            2.09m
        30           0.5653           0.0020            1.72m
        40           0.5418          -0.0006            1.37m
        50           0.5182          -0.0026            1.02m
        60           0.5101          -0.0027           40.38s
        70           0.4907          -0.0018           20.20s
        80           0.4824          -0.0016            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8368           0.3343            4.23m
         2           0.7625           0.0691            3.63m
         3           0.7320           0.0318            3.40m
         4           0.7111           0.0212            3.19m
         5           0.6925           0.0161            3.02m
         6           0.6850           0.0111            2.96m
         7           0.6764           0.0070            2.91m
         8           0.6697           0.0031            2.82m
         9           0.6607           0.0039            2.73m
        10           0.6515           0.0029            2.66m
        20           0.5888           0.0013            2.25m
        30           0.5636          -0.0018            1.85m
        40           0.5408          -0.0004            1.46m
        50           0.5216          -0.0027            1.10m
        60           0.5080          -0.0014           43.78s
        70           0.4943          -0.0021           21.79s
        80           0.4841          -0.0009            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8368           0.3343            4.49m
         2           0.7625           0.0691            3.86m
         3           0.7294           0.0370            3.57m
         4           0.7067           0.0200            3.36m
         5           0.6912           0.0135            3.21m
         6           0.6825           0.0114            3.15m
         7           0.6743           0.0045            3.10m
         8           0.6662           0.0047            3.00m
         9           0.6556           0.0126            2.91m
        10           0.6425           0.0090            2.84m
        20           0.5841           0.0020            2.41m
        30           0.5536          -0.0015            1.98m
        40           0.5357           0.0006            1.58m
        50           0.5174          -0.0024            1.18m
        60           0.5071          -0.0001           46.92s
        70           0.4911          -0.0002           23.30s
        80           0.4809          -0.0005            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8408           0.3479            4.85m
         2           0.7774           0.0649            4.09m
         3           0.7424           0.0331            3.76m
         4           0.7223           0.0175            3.54m
         5           0.7085           0.0108            3.40m
         6           0.6973           0.0090            3.33m
         7           0.6897           0.0079            3.22m
         8           0.6791           0.0067            3.18m
         9           0.6637           0.0069            3.09m
        10           0.6608           0.0097            3.02m
        20           0.6081           0.0013            2.48m
        30           0.5701          -0.0001            2.08m
        40           0.5586          -0.0005            1.65m
        50           0.5332           0.0014            1.23m
        60           0.5205          -0.0003           49.41s
        70           0.5084          -0.0014           24.61s
        80           0.4968          -0.0019            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8553           0.3086            3.91m
         2           0.7754           0.0874            3.25m
         3           0.7414           0.0320            3.03m
         4           0.7244           0.0160            2.81m
         5           0.7044           0.0155            2.66m
         6           0.6949           0.0151            2.58m
         7           0.6827           0.0055            2.53m
         8           0.6774           0.0066            2.45m
         9           0.6695           0.0040            2.39m
        10           0.6582           0.0050            2.32m
        20           0.5962           0.0024            1.93m
        30           0.5679           0.0005            1.59m
        40           0.5462          -0.0025            1.26m
        50           0.5281          -0.0010           56.50s
        60           0.5155           0.0005           37.58s
        70           0.5009          -0.0018           18.74s
        80           0.4921          -0.0020            0.00s
### Start Time 2019/11/10-13-17-16  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=594   randForSplit=894   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.90      0.91     28178
Train discard       0.89      0.90      0.89     23813

    micro avg       0.90      0.90      0.90     51991
    macro avg       0.90      0.90      0.90     51991
 weighted avg       0.90      0.90      0.90     51991

Train (keep) F2: 0.9044    P: 0.9154    R: 0.9017    NPV: 0.8857

['yes', 'no']
[[25409  2769]
 [ 2348 21465]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      5596
Valid discard       0.91      0.88      0.89      7463

    micro avg       0.88      0.88      0.88     13059
    macro avg       0.87      0.88      0.88     13059
 weighted avg       0.88      0.88      0.88     13059

Valid (keep) F2: 0.8727    P: 0.8425    R: 0.8806    NPV: 0.9074

['yes', 'no']
[[4928  668]
 [ 921 6542]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking at max_features.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__max_features: 0.7

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7f0d2a9e2c68>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=594,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__max_features:[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, None]

### Grid Search Scores:
{'classifier__max_features': 0.4}
mean_test_score:  0.862899
{'classifier__max_features': 0.5}
mean_test_score:  0.863577
{'classifier__max_features': 0.6}
mean_test_score:  0.864233
{'classifier__max_features': 0.7}
mean_test_score:  0.872738
{'classifier__max_features': 0.8}
mean_test_score:  0.869950
{'classifier__max_features': 0.9}
mean_test_score:  0.869380
{'classifier__max_features': None}
mean_test_score:  0.871305

### Grid Search Best Score: 0.872738

### Feature weights: highest 20
+0.4005	mice figur
+0.0780	cre
+0.0725	wild_typ
+0.0597	mut_mut
+0.0464	wild_typ mice
+0.0301	transgen mice
+0.0250	knock_out mice
+0.0227	genotyp
+0.0195	litterm
+0.0100	embryonic_day
+0.0088	relat figur
+0.0068	inocul
+0.0055	pdf file
+0.0051	mice compar
+0.0047	xenograft
+0.0043	clinic
+0.0042	crispr
+0.0040	mice model
+0.0038	immunostain
+0.0037	mice strain

### Feature weights: lowest 20
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 921
29695611
31075260
27617678
29228333
28963450

### False negatives for Validation set: 668
30366907
29953499
26673701
28916300
24732378

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/10-15-55-43. Total   9507.02 seconds

Fitting 1 folds for each of 7 candidates, totalling 7 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8450           0.3444            3.57m
         2           0.7681           0.0697            3.04m
         3           0.7327           0.0336            2.78m
         4           0.7133           0.0175            2.61m
         5           0.7021           0.0086            2.48m
         6           0.6830           0.0091            2.42m
         7           0.6802           0.0087            2.38m
         8           0.6683           0.0045            2.31m
         9           0.6570           0.0086            2.27m
        10           0.6478           0.0096            2.20m
        20           0.5937          -0.0013            1.84m
        30           0.5655           0.0011            1.51m
        40           0.5491          -0.0024            1.20m
        50           0.5228          -0.0020           53.36s
        60           0.5120          -0.0026           35.25s
        70           0.5057          -0.0034           17.51s
        80           0.4917          -0.0045            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3491            3.84m
         2           0.7749           0.0562            3.15m
         3           0.7374           0.0345            2.91m
         4           0.7198           0.0167            2.71m
         5           0.7080           0.0122            2.59m
         6           0.6891           0.0107            2.51m
         7           0.6886           0.0087            2.41m
         8           0.6721           0.0062            2.36m
         9           0.6583           0.0094            2.30m
        10           0.6491           0.0087            2.24m
        20           0.5951           0.0044            1.88m
        30           0.5675          -0.0002            1.54m
        40           0.5488          -0.0007            1.22m
        50           0.5225          -0.0011           54.63s
        60           0.5074          -0.0021           36.33s
        70           0.4993          -0.0015           18.05s
        80           0.4841          -0.0002            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3491            3.75m
         2           0.7694           0.0674            3.14m
         3           0.7299           0.0330            2.94m
         4           0.7142           0.0182            2.79m
         5           0.7020           0.0143            2.68m
         6           0.6774           0.0111            2.63m
         7           0.6782           0.0063            2.54m
         8           0.6630           0.0076            2.47m
         9           0.6516           0.0072            2.40m
        10           0.6434           0.0121            2.34m
        20           0.5895           0.0001            1.95m
        30           0.5581          -0.0009            1.60m
        40           0.5434          -0.0019            1.26m
        50           0.5169          -0.0016           56.08s
        60           0.5025          -0.0012           37.46s
        70           0.4975          -0.0010           18.63s
        80           0.4850          -0.0007            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8404           0.3496            3.94m
         2           0.7680           0.0654            3.31m
         3           0.7340           0.0290            3.06m
         4           0.7121           0.0186            2.88m
         5           0.7040           0.0110            2.73m
         6           0.6820           0.0139            2.64m
         7           0.6779           0.0071            2.63m
         8           0.6620           0.0092            2.60m
         9           0.6518           0.0071            2.54m
        10           0.6455           0.0054            2.48m
        20           0.5913           0.0011            2.04m
        30           0.5670          -0.0004            1.67m
        40           0.5471          -0.0009            1.33m
        50           0.5208           0.0015           59.20s
        60           0.5040          -0.0045           39.19s
        70           0.4984          -0.0011           19.58s
        80           0.4828          -0.0035            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8514           0.3450            4.02m
         2           0.7689           0.0746            3.35m
         3           0.7285           0.0388            3.13m
         4           0.7053           0.0204            2.98m
         5           0.6953           0.0153            2.84m
         6           0.6765           0.0103            2.75m
         7           0.6726           0.0115            2.71m
         8           0.6588           0.0057            2.65m
         9           0.6441           0.0092            2.58m
        10           0.6393           0.0090            2.51m
        20           0.5902           0.0002            2.08m
        30           0.5634           0.0006            1.70m
        40           0.5436          -0.0006            1.37m
        50           0.5173          -0.0021            1.03m
        60           0.5081          -0.0028           40.86s
        70           0.5006          -0.0019           20.49s
        80           0.4846          -0.0024            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3491            4.27m
         2           0.7685           0.0679            3.63m
         3           0.7314           0.0319            3.38m
         4           0.7113           0.0200            3.18m
         5           0.7012           0.0113            3.00m
         6           0.6831           0.0110            2.93m
         7           0.6794           0.0109            2.84m
         8           0.6646           0.0061            2.80m
         9           0.6484           0.0107            2.74m
        10           0.6423           0.0071            2.67m
        20           0.5848           0.0037            2.28m
        30           0.5573          -0.0024            1.87m
        40           0.5408          -0.0010            1.48m
        50           0.5092          -0.0021            1.11m
        60           0.4988          -0.0020           44.28s
        70           0.4926          -0.0018           22.03s
        80           0.4765          -0.0004            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3491            4.52m
         2           0.7685           0.0679            3.87m
         3           0.7314           0.0319            3.59m
         4           0.7120           0.0229            3.37m
         5           0.6986           0.0125            3.21m
         6           0.6796           0.0127            3.15m
         7           0.6781           0.0063            3.05m
         8           0.6628           0.0132            2.98m
         9           0.6522           0.0064            2.90m
        10           0.6446           0.0068            2.83m
        20           0.5900           0.0036            2.39m
        30           0.5607           0.0014            2.01m
        40           0.5440          -0.0022            1.59m
        50           0.5135          -0.0017            1.18m
        60           0.5028          -0.0025           46.96s
        70           0.4937          -0.0016           23.34s
        80           0.4806          -0.0032            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8369           0.3704            4.97m
         2           0.7615           0.0758            4.23m
         3           0.7262           0.0319            3.89m
         4           0.7106           0.0172            3.61m
         5           0.6957           0.0132            3.46m
         6           0.6833           0.0110            3.36m
         7           0.6738           0.0074            3.31m
         8           0.6670           0.0083            3.21m
         9           0.6583           0.0053            3.11m
        10           0.6475           0.0040            3.06m
        20           0.5990           0.0010            2.54m
        30           0.5644           0.0025            2.10m
        40           0.5490           0.0008            1.68m
        50           0.5318          -0.0005            1.25m
        60           0.5170          -0.0012           50.20s
        70           0.5009          -0.0020           24.91s
        80           0.4876          -0.0020            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3491            3.99m
         2           0.7694           0.0674            3.26m
         3           0.7299           0.0330            3.04m
         4           0.7142           0.0182            2.88m
         5           0.7020           0.0143            2.74m
         6           0.6774           0.0111            2.68m
         7           0.6782           0.0063            2.58m
         8           0.6630           0.0076            2.51m
         9           0.6516           0.0072            2.44m
        10           0.6434           0.0121            2.38m
        20           0.5895           0.0001            1.99m
        30           0.5581          -0.0009            1.62m
        40           0.5434          -0.0019            1.28m
        50           0.5169          -0.0016           57.28s
        60           0.5025          -0.0012           38.27s
        70           0.4975          -0.0010           19.06s
        80           0.4850          -0.0007            0.00s
### Start Time 2019/11/10-18-06-50  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=125   randForSplit=916   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.90      0.91     28178
Train discard       0.89      0.90      0.90     23813

    micro avg       0.90      0.90      0.90     51991
    macro avg       0.90      0.90      0.90     51991
 weighted avg       0.90      0.90      0.90     51991

Train (keep) F2: 0.9057    P: 0.9177    R: 0.9027    NPV: 0.8871

['yes', 'no']
[[25437  2741]
 [ 2280 21533]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      5596
Valid discard       0.91      0.88      0.89      7463

    micro avg       0.88      0.88      0.88     13059
    macro avg       0.87      0.88      0.88     13059
 weighted avg       0.88      0.88      0.88     13059

Valid (keep) F2: 0.8725    P: 0.8414    R: 0.8806    NPV: 0.9072

['yes', 'no']
[[4928  668]
 [ 929 6534]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking at max_features.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__max_features: 0.7

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7fb18c4e1c68>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=125,
              subsample=0.8, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__max_features:[0.6, 0.65, 0.7, 0.75, 0.8, 0.9, None]

### Grid Search Scores:
{'classifier__max_features': 0.6}
mean_test_score:  0.868695
{'classifier__max_features': 0.65}
mean_test_score:  0.871448
{'classifier__max_features': 0.7}
mean_test_score:  0.872490
{'classifier__max_features': 0.75}
mean_test_score:  0.865330
{'classifier__max_features': 0.8}
mean_test_score:  0.867068
{'classifier__max_features': 0.9}
mean_test_score:  0.869542
{'classifier__max_features': None}
mean_test_score:  0.869981

### Grid Search Best Score: 0.872490

### Feature weights: highest 20
+0.3792	mice figur
+0.1121	cre
+0.0802	wild_typ mice
+0.0720	wild_typ
+0.0303	litterm
+0.0258	mut_mut
+0.0240	knock_out mice
+0.0210	genotyp
+0.0133	transgen
+0.0073	xenograft
+0.0070	embryonic_day
+0.0064	relat figur
+0.0047	host
+0.0042	pdf file
+0.0041	mice compar
+0.0039	po0
+0.0038	mice strain
+0.0036	improv
+0.0035	journal__plos_one
+0.0035	patient

### Feature weights: lowest 20
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 929
29927948
29406270
27617678
29228333
29955044

### False negatives for Validation set: 668
29953499
28062700
26673701
28837808
28916300

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/10-20-47-52. Total   9661.62 seconds

Fitting 1 folds for each of 8 candidates, totalling 8 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8425           0.3462            3.77m
         2           0.7717           0.0696            3.07m
         3           0.7326           0.0338            2.83m
         4           0.7062           0.0166            2.69m
         5           0.6944           0.0138            2.54m
         6           0.6875           0.0067            2.47m
         7           0.6691           0.0073            2.39m
         8           0.6682           0.0042            2.34m
         9           0.6654           0.0100            2.30m
        10           0.6602           0.0055            2.24m
        20           0.6081           0.0011            1.88m
        30           0.5773          -0.0004            1.56m
        40           0.5605          -0.0010            1.23m
        50           0.5506          -0.0024           55.08s
        60           0.5331          -0.0026           36.46s
        70           0.5200          -0.0023           18.25s
        80           0.5103          -0.0022            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8415           0.3435            3.74m
         2           0.7713           0.0694            3.12m
         3           0.7328           0.0340            2.88m
         4           0.7091           0.0162            2.73m
         5           0.6954           0.0154            2.59m
         6           0.6882           0.0078            2.54m
         7           0.6697           0.0067            2.45m
         8           0.6696           0.0047            2.41m
         9           0.6587           0.0123            2.38m
        10           0.6589           0.0059            2.31m
        20           0.6037           0.0048            1.91m
        30           0.5670           0.0007            1.58m
        40           0.5493          -0.0020            1.25m
        50           0.5406          -0.0021           56.17s
        60           0.5190          -0.0017           37.44s
        70           0.5051          -0.0014           18.67s
        80           0.4907          -0.0020            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8404           0.3410            3.75m
         2           0.7707           0.0690            3.12m
         3           0.7341           0.0339            2.90m
         4           0.7089           0.0188            2.77m
         5           0.6956           0.0156            2.64m
         6           0.6867           0.0076            2.57m
         7           0.6712           0.0070            2.49m
         8           0.6661           0.0079            2.43m
         9           0.6558           0.0137            2.39m
        10           0.6505           0.0098            2.32m
        20           0.5960          -0.0013            1.94m
        30           0.5606          -0.0021            1.59m
        40           0.5393          -0.0019            1.26m
        50           0.5251          -0.0028           56.49s
        60           0.5103          -0.0019           37.36s
        70           0.4925          -0.0029           18.57s
        80           0.4759          -0.0039            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8402           0.3413            3.79m
         2           0.7708           0.0699            3.15m
         3           0.7325           0.0312            2.91m
         4           0.7148           0.0190            2.72m
         5           0.7011           0.0097            2.62m
         6           0.6924           0.0070            2.53m
         7           0.6783           0.0064            2.46m
         8           0.6734           0.0067            2.40m
         9           0.6637           0.0122            2.35m
        10           0.6608           0.0079            2.29m
        20           0.6024           0.0033            1.93m
        30           0.5662           0.0010            1.59m
        40           0.5469          -0.0002            1.28m
        50           0.5260          -0.0024           57.13s
        60           0.5057          -0.0004           37.98s
        70           0.4915          -0.0021           18.88s
        80           0.4755          -0.0021            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3439            3.84m
         2           0.7716           0.0722            3.19m
         3           0.7325           0.0295            2.94m
         4           0.7092           0.0209            2.79m
         5           0.6964           0.0110            2.66m
         6           0.6828           0.0140            2.60m
         7           0.6699           0.0067            2.53m
         8           0.6633           0.0098            2.49m
         9           0.6525           0.0049            2.42m
        10           0.6486           0.0093            2.36m
        20           0.5990           0.0014            1.97m
        30           0.5648           0.0001            1.61m
        40           0.5440          -0.0038            1.28m
        50           0.5233          -0.0001           57.94s
        60           0.5035          -0.0027           38.37s
        70           0.4906          -0.0020           19.15s
        80           0.4732          -0.0006            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8404           0.3410            3.82m
         2           0.7721           0.0737            3.21m
         3           0.7327           0.0267            2.98m
         4           0.7111           0.0134            2.84m
         5           0.6960           0.0109            2.70m
         6           0.6829           0.0130            2.63m
         7           0.6704           0.0062            2.56m
         8           0.6598           0.0070            2.53m
         9           0.6521           0.0081            2.45m
        10           0.6465           0.0074            2.39m
        20           0.5929           0.0022            1.98m
        30           0.5584          -0.0009            1.64m
        40           0.5375          -0.0015            1.31m
        50           0.5200          -0.0020           58.58s
        60           0.5011          -0.0032           38.95s
        70           0.4810          -0.0018           19.50s
        80           0.4661          -0.0031            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8418           0.3547            3.83m
         2           0.7709           0.0708            3.25m
         3           0.7348           0.0290            3.02m
         4           0.7109           0.0101            2.89m
         5           0.6974           0.0128            2.75m
         6           0.6820           0.0097            2.69m
         7           0.6682           0.0069            2.64m
         8           0.6601           0.0078            2.54m
         9           0.6493           0.0047            2.48m
        10           0.6435           0.0077            2.44m
        20           0.5925          -0.0037            2.07m
        30           0.5582           0.0006            1.70m
        40           0.5338           0.0008            1.34m
        50           0.5125          -0.0008           59.68s
        60           0.4965          -0.0036           39.54s
        70           0.4816           0.0001           19.65s
        80           0.4640          -0.0004            0.00s
      Iter       Train Loss   Remaining Time 
         1           0.8401            3.88m
         2           0.7676            3.27m
         3           0.7380            3.07m
         4           0.7155            2.93m
         5           0.6986            2.82m
         6           0.6869            2.71m
         7           0.6770            2.62m
         8           0.6691            2.54m
         9           0.6572            2.46m
        10           0.6475            2.40m
        20           0.5917            2.04m
        30           0.5591            1.70m
        40           0.5341            1.35m
        50           0.5099            1.01m
        60           0.4909           40.15s
        70           0.4749           20.04s
        80           0.4599            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8480           0.3595            4.95m
         2           0.7686           0.0727            4.14m
         3           0.7303           0.0339            3.86m
         4           0.7155           0.0196            3.67m
         5           0.6967           0.0156            3.56m
         6           0.6885           0.0079            3.46m
         7           0.6788           0.0059            3.37m
         8           0.6731           0.0037            3.26m
         9           0.6669           0.0054            3.17m
        10           0.6573           0.0025            3.09m
        20           0.6094           0.0005            2.59m
        30           0.5722           0.0021            2.12m
        40           0.5511          -0.0007            1.69m
        50           0.5336          -0.0004            1.26m
        60           0.5190          -0.0025           50.18s
        70           0.5017          -0.0016           24.96s
        80           0.4915          -0.0004            0.00s
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.8405           0.3439            3.96m
         2           0.7716           0.0722            3.30m
         3           0.7325           0.0295            3.04m
         4           0.7092           0.0209            2.89m
         5           0.6964           0.0110            2.76m
         6           0.6828           0.0140            2.69m
         7           0.6699           0.0067            2.61m
         8           0.6633           0.0098            2.57m
         9           0.6525           0.0049            2.48m
        10           0.6486           0.0093            2.42m
        20           0.5990           0.0014            1.99m
        30           0.5648           0.0001            1.64m
        40           0.5440          -0.0038            1.30m
        50           0.5233          -0.0001           58.93s
        60           0.5035          -0.0027           39.06s
        70           0.4906          -0.0020           19.46s
        80           0.4732          -0.0006            0.00s
### Start Time 2019/11/10-21-26-55  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=478   randForSplit=821   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.90      0.91     28178
Train discard       0.89      0.91      0.90     23813

    micro avg       0.91      0.91      0.91     51991
    macro avg       0.90      0.91      0.90     51991
 weighted avg       0.91      0.91      0.91     51991

Train (keep) F2: 0.9075    P: 0.9197    R: 0.9045    NPV: 0.8892

['yes', 'no']
[[25487  2691]
 [ 2226 21587]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      5596
Valid discard       0.91      0.88      0.89      7463

    micro avg       0.88      0.88      0.88     13059
    macro avg       0.88      0.88      0.88     13059
 weighted avg       0.88      0.88      0.88     13059

Valid (keep) F2: 0.8756    P: 0.8429    R: 0.8842    NPV: 0.9099

['yes', 'no']
[[4948  648]
 [ 922 6541]]

### Note: Using initial learning_rate: 1.0, estimators: 80.
Using max_depth 3, Looking at subsample.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__subsample: 0.85

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7fa9e3d15248>,
              learning_rate=1.0, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=80,
              n_iter_no_change=None, presort='auto', random_state=478,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__subsample:[0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]

### Grid Search Scores:
{'classifier__subsample': 0.6}
mean_test_score:  0.862124
{'classifier__subsample': 0.7}
mean_test_score:  0.869442
{'classifier__subsample': 0.75}
mean_test_score:  0.872850
{'classifier__subsample': 0.8}
mean_test_score:  0.866584
{'classifier__subsample': 0.85}
mean_test_score:  0.875628
{'classifier__subsample': 0.9}
mean_test_score:  0.870028
{'classifier__subsample': 0.95}
mean_test_score:  0.874712
{'classifier__subsample': 1.0}
mean_test_score:  0.872647

### Grid Search Best Score: 0.875628

### Feature weights: highest 20
+0.3837	mice figur
+0.0927	wild_typ mice
+0.0729	wild_typ
+0.0721	cre
+0.0330	genotyp
+0.0316	litterm
+0.0296	mut_mut
+0.0257	transgen mice
+0.0153	knock_out mice
+0.0105	relat figur
+0.0079	xenograft
+0.0077	embryonic_day
+0.0060	inocul
+0.0057	pdf file
+0.0051	mice strain
+0.0051	clinic
+0.0038	journal__nat_commun
+0.0037	immunostain
+0.0036	mice model
+0.0033	defici mice

### Feature weights: lowest 20
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 922
30595162
27617678
29228333
29955044
29288169

### False negatives for Validation set: 648
26909801
29953499
28062700
26673701
28775166

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/11-00-25-18. Total  10703.20 seconds

      Iter       Train Loss      OOB Improve   Remaining Time 
         1           0.9466           0.2333            7.80m
         2           0.8387           0.1073            6.59m
         3           0.7879           0.0538            6.16m
         4           0.7572           0.0260            5.94m
         5           0.7367           0.0194            5.85m
         6           0.7203           0.0182            5.68m
         7           0.7087           0.0119            5.54m
         8           0.6985           0.0091            5.45m
         9           0.6883           0.0096            5.38m
        10           0.6787           0.0094            5.31m
        20           0.6213           0.0042            4.68m
        30           0.5909           0.0008            4.34m
        40           0.5589           0.0012            3.99m
        50           0.5403          -0.0005            3.61m
        60           0.5312          -0.0004            3.28m
        70           0.5136           0.0004            2.93m
        80           0.5008          -0.0009            2.59m
        90           0.4864          -0.0007            2.25m
       100           0.4782          -0.0014            1.93m
### Start Time 2019/11/11-11-16-20  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=33   randForSplit=156   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.93      0.91      0.92     28178
Train discard       0.90      0.92      0.91     23813

    micro avg       0.92      0.92      0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9167    P: 0.9323    R: 0.9128    NPV: 0.8993

['yes', 'no']
[[25722  2456]
 [ 1869 21944]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.89      0.88      5596
Valid discard       0.91      0.89      0.90      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid (keep) F2: 0.8837    P: 0.8637    R: 0.8888    NPV: 0.9148

['yes', 'no']
[[4974  622]
 [ 785 6678]]

### Note: .Optimizing learning_rate & n_estimators.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 0.5
classifier__n_estimators: 160

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7ff3cb0167e8>,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=160,
              n_iter_no_change=None, presort='auto', random_state=33,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Feature weights: highest 20
+0.2741	mice figur
+0.1038	wild_typ mice
+0.0799	cre
+0.0591	wild_typ
+0.0434	litterm
+0.0416	transgen mice
+0.0330	mut_mut
+0.0313	knock_out
+0.0237	genotyp
+0.0089	mice strain
+0.0086	relat figur
+0.0082	section
+0.0076	mice compar
+0.0063	xenograft
+0.0059	crispr
+0.0056	knock_out mice
+0.0055	embryonic_day
+0.0055	pdf file
+0.0054	defici mice
+0.0046	mice model

### Feature weights: lowest 20
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	young
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 785
29406270
30098187
29228333
29955044
29288169

### False negatives for Validation set: 622
29953499
28062700
26673701
28775166
28837808

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
ValidationSplit: 0.20
### End Time 2019/11/11-11-36-29. Total   1208.71 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0266           0.1657            7.74m
         2           0.9307           0.0975            6.63m
         3           0.8669           0.0599            6.25m
         4           0.8246           0.0427            6.06m
         5           0.7960           0.0261            5.92m
         6           0.7764           0.0224            5.80m
         7           0.7579           0.0168            5.67m
         8           0.7462           0.0115            5.57m
         9           0.7282           0.0120            5.47m
        10           0.7196           0.0096            5.40m
        20           0.6587           0.0037            4.75m
        30           0.6257           0.0022            4.34m
        40           0.6011           0.0009            3.95m
        50           0.5798           0.0011            3.61m
        60           0.5650           0.0000            3.28m
        70           0.5498           0.0000            2.93m
        80           0.5382           0.0003            2.60m
        90           0.5311          -0.0003            2.27m
       100           0.5215          -0.0000            1.94m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1254           0.0614            7.75m
         2           1.0754           0.0514            6.61m
         3           1.0309           0.0418            6.20m
         4           0.9944           0.0362            6.06m
         5           0.9643           0.0302            5.93m
         6           0.9369           0.0280            5.81m
         7           0.9122           0.0247            5.71m
         8           0.8925           0.0206            5.64m
         9           0.8707           0.0180            5.60m
        10           0.8560           0.0153            5.53m
        20           0.7628           0.0061            5.02m
        30           0.7201           0.0028            4.58m
        40           0.6933           0.0020            4.13m
        50           0.6737           0.0013            3.74m
        60           0.6606           0.0009            3.37m
        70           0.6434           0.0008            3.00m
        80           0.6325           0.0009            2.66m
        90           0.6245           0.0008            2.32m
       100           0.6151           0.0012            1.98m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0299           0.1713           10.09m
         2           0.9303           0.0955            8.63m
         3           0.8652           0.0658            8.02m
         4           0.8227           0.0428            7.70m
         5           0.7894           0.0332            7.49m
         6           0.7654           0.0229            7.29m
         7           0.7459           0.0179            7.12m
         8           0.7326           0.0145            7.01m
         9           0.7232           0.0103            6.87m
        10           0.7114           0.0079            6.77m
        20           0.6569           0.0030            6.03m
        30           0.6242           0.0013            5.52m
        40           0.5978           0.0022            5.10m
        50           0.5835           0.0021            4.63m
        60           0.5663           0.0006            4.18m
        70           0.5514           0.0004            3.76m
        80           0.5415           0.0003            3.33m
        90           0.5300           0.0004            2.91m
       100           0.5221           0.0001            2.48m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.0266           0.1657            7.74m
         2           0.9307           0.0975            6.67m
         3           0.8669           0.0599            6.30m
         4           0.8246           0.0427            6.12m
         5           0.7960           0.0261            5.97m
         6           0.7764           0.0224            5.87m
         7           0.7579           0.0168            5.74m
         8           0.7462           0.0115            5.66m
         9           0.7282           0.0120            5.54m
        10           0.7196           0.0096            5.47m
        20           0.6587           0.0037            4.83m
        30           0.6257           0.0022            4.39m
        40           0.6011           0.0009            3.99m
        50           0.5798           0.0011            3.63m
        60           0.5650           0.0000            3.30m
        70           0.5498           0.0000            2.95m
        80           0.5382           0.0003            2.62m
        90           0.5311          -0.0003            2.29m
       100           0.5215          -0.0000            1.95m
### Start Time 2019/11/11-14-10-44  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=316   randForSplit=489   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.93      0.90      0.91     28178
Train discard       0.89      0.91      0.90     23813

    micro avg       0.91      0.91      0.91     51991
    macro avg       0.91      0.91      0.91     51991
 weighted avg       0.91      0.91      0.91     51991

Train (keep) F2: 0.9050    P: 0.9258    R: 0.9000    NPV: 0.8854

['yes', 'no']
[[25360  2818]
 [ 2032 21781]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.88      5596
Valid discard       0.91      0.90      0.91      7463

    micro avg       0.89      0.89      0.89     13059
    macro avg       0.89      0.89      0.89     13059
 weighted avg       0.89      0.89      0.89     13059

Valid (keep) F2: 0.8811    P: 0.8702    R: 0.8838    NPV: 0.9119

['yes', 'no']
[[4946  650]
 [ 738 6725]]

### Note: .Optimizing learning_rate & n_estimators.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 0.3
classifier__n_estimators: 160

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7f9f13eb1998>,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=160,
              n_iter_no_change=None, presort='auto', random_state=316,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Grid Search Parameter Options Tried:
classifier__learning_rate:[0.3, 0.1]
classifier__n_estimators:[160]

### Grid Search Scores:
{'classifier__learning_rate': 0.3, 'classifier__n_estimators': 160}
mean_test_score:  0.881075
{'classifier__learning_rate': 0.1, 'classifier__n_estimators': 160}
mean_test_score:  0.869790

### Grid Search Best Score: 0.881075

### End Time 2019/11/11-15-32-22. Total   4898.36 seconds

      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1220           0.0624           39.13m
         2           1.0707           0.0511           33.70m
         3           1.0281           0.0420           31.97m
         4           0.9937           0.0323           31.04m
         5           0.9644           0.0320           30.57m
         6           0.9366           0.0271           30.18m
         7           0.9137           0.0257           29.86m
         8           0.8905           0.0205           29.70m
         9           0.8734           0.0180           29.52m
        10           0.8559           0.0171           29.31m
        20           0.7593           0.0061           28.28m
        30           0.7186           0.0033           27.27m
        40           0.6924           0.0018           26.26m
        50           0.6713           0.0014           25.52m
        60           0.6602           0.0009           24.93m
        70           0.6451           0.0005           24.46m
        80           0.6325           0.0009           23.97m
        90           0.6204           0.0007           23.45m
       100           0.6106           0.0007           23.08m
       200           0.5499           0.0000           19.57m
       300           0.5153           0.0000           16.06m
       400           0.4860          -0.0001           12.87m
       500           0.4657          -0.0002            9.59m
       600           0.4466          -0.0002            6.36m
       700           0.4293          -0.0001            3.16m
       800           0.4130          -0.0001            0.00s
### Start Time 2019/11/11-18-03-03  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=313   randForSplit=313   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.92      0.93     28178
Train discard       0.90      0.93      0.92     23813

    micro avg       0.92      0.92      0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9209    P: 0.9391    R: 0.9165    NPV: 0.9040

['yes', 'no']
[[25826  2352]
 [ 1676 22137]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.89      0.88      5596
Valid discard       0.92      0.90      0.91      7463

    micro avg       0.90      0.90      0.90     13059
    macro avg       0.89      0.90      0.90     13059
 weighted avg       0.90      0.90      0.90     13059

Valid (keep) F2: 0.8879    P: 0.8718    R: 0.8921    NPV: 0.9176

['yes', 'no']
[[4992  604]
 [ 734 6729]]

### Note: .Optimizing learning_rate & n_estimators.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 0.1
classifier__n_estimators: 800

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7f22aca0b7e8>,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=800,
              n_iter_no_change=None, presort='auto', random_state=313,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### End Time 2019/11/11-18-43-08. Total   2405.15 seconds

      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1550           0.0302           76.78m
         2           1.1277           0.0279           66.42m
         3           1.1033           0.0252           62.40m
         4           1.0772           0.0240           60.52m
         5           1.0577           0.0210           59.25m
         6           1.0363           0.0209           58.73m
         7           1.0157           0.0191           58.33m
         8           0.9992           0.0176           58.04m
         9           0.9822           0.0163           57.75m
        10           0.9671           0.0139           57.54m
        20           0.8610           0.0077           56.32m
        30           0.8016           0.0048           56.00m
        40           0.7656           0.0031           54.92m
        50           0.7376           0.0022           54.02m
        60           0.7168           0.0015           53.28m
        70           0.7046           0.0010           52.58m
        80           0.6923           0.0010           51.72m
        90           0.6814           0.0009           51.13m
       100           0.6737           0.0005           50.37m
       200           0.6136           0.0003           45.97m
       300           0.5756           0.0001           42.36m
       400           0.5534           0.0001           38.83m
       500           0.5317           0.0001           35.33m
       600           0.5119          -0.0000           31.99m
       700           0.4977          -0.0000           28.70m
       800           0.4832          -0.0001           25.41m
       900           0.4737          -0.0000           22.17m
      1000           0.4632          -0.0000           18.93m
### Start Time 2019/11/11-20-10-02  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=309   randForSplit=619   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.92      0.93     28178
Train discard       0.90      0.93      0.92     23813

    micro avg       0.92      0.92      0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9210    P: 0.9392    R: 0.9165    NPV: 0.9039

['yes', 'no']
[[25825  2353]
 [ 1671 22142]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.89      0.88      5596
Valid discard       0.92      0.90      0.91      7463

    micro avg       0.90      0.90      0.90     13059
    macro avg       0.90      0.90      0.90     13059
 weighted avg       0.90      0.90      0.90     13059

Valid (keep) F2: 0.8887    P: 0.8740    R: 0.8924    NPV: 0.9180

['yes', 'no']
[[4994  602]
 [ 720 6743]]

### Note: .Optimizing learning_rate & n_estimators.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 0.05
classifier__n_estimators: 1600

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7f15ca7d47e8>,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=309,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### End Time 2019/11/11-21-14-45. Total   3882.87 seconds

Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4488 recall: 0.918
gxd            selected papers:   475 predicted keep:   452 recall: 0.952
go             selected papers:  4180 predicted keep:  3782 recall: 0.905
tumor          selected papers:   316 predicted keep:   279 recall: 0.883
qtl            selected papers:    18 predicted keep:    17 recall: 0.944
Totals         keep     papers:  5596 predicted keep:  4983 recall: 0.890
Predictions from GB_val_pred.txt - Tue Nov 12 12:14:22 2019
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1703           0.0151          158.26m
         2           1.1545           0.0148          136.65m
         3           1.1396           0.0152          128.61m
         4           1.1258           0.0138          125.98m
         5           1.1135           0.0134          123.83m
         6           1.1005           0.0127          121.97m
         7           1.0889           0.0125          120.55m
         8           1.0758           0.0118          119.53m
         9           1.0637           0.0111          118.58m
        10           1.0548           0.0104          118.30m
        20           0.9670           0.0068          115.06m
        30           0.9070           0.0052          114.18m
        40           0.8613           0.0039          113.35m
        50           0.8267           0.0028          113.13m
        60           0.8012           0.0020          112.60m
        70           0.7814           0.0020          111.60m
        80           0.7645           0.0014          110.46m
        90           0.7522           0.0014          109.56m
       100           0.7364           0.0012          108.96m
       200           0.6732           0.0004          102.21m
       300           0.6364           0.0002           96.96m
       400           0.6117           0.0001           92.72m
       500           0.5921           0.0000           88.74m
       600           0.5738          -0.0000           85.01m
       700           0.5635           0.0001           81.42m
       800           0.5523           0.0001           77.84m
       900           0.5437           0.0000           74.45m
      1000           0.5290           0.0001           71.06m
      2000           0.4642          -0.0000           38.16m
      3000           0.4205          -0.0000            6.31m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1842           0.0162          203.77m
         2           1.1673           0.0160          175.14m
         3           1.1532           0.0154          165.72m
         4           1.1396           0.0139          160.37m
         5           1.1242           0.0137          157.22m
         6           1.1116           0.0134          154.72m
         7           1.0999           0.0127          153.14m
         8           1.0872           0.0123          151.58m
         9           1.0731           0.0120          150.69m
        10           1.0621           0.0117          149.91m
        20           0.9703           0.0074          145.78m
        30           0.9075           0.0056          144.86m
        40           0.8596           0.0037          143.69m
        50           0.8262           0.0031          143.22m
        60           0.7984           0.0024          143.03m
        70           0.7780           0.0020          141.97m
        80           0.7617           0.0015          141.20m
        90           0.7477           0.0012          140.31m
       100           0.7328           0.0009          139.59m
       200           0.6690           0.0003          132.53m
       300           0.6335           0.0001          126.19m
       400           0.6133           0.0001          120.72m
       500           0.5949           0.0001          115.53m
       600           0.5794           0.0000          110.72m
       700           0.5675           0.0000          105.91m
       800           0.5537           0.0000          101.26m
       900           0.5473           0.0000           96.76m
      1000           0.5373          -0.0000           92.34m
      2000           0.4760          -0.0000           49.85m
      3000           0.4351           0.0000            8.25m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.1687           0.0158          155.88m
         2           1.1525           0.0152          134.30m
         3           1.1390           0.0143          126.84m
         4           1.1259           0.0139          123.48m
         5           1.1129           0.0130          120.92m
         6           1.1001           0.0122          119.85m
         7           1.0878           0.0118          119.03m
         8           1.0754           0.0117          118.25m
         9           1.0650           0.0110          117.40m
        10           1.0543           0.0107          116.80m
        20           0.9683           0.0074          113.75m
        30           0.9053           0.0054          112.37m
        40           0.8592           0.0039          111.65m
        50           0.8280           0.0027          110.92m
        60           0.8011           0.0022          110.33m
        70           0.7827           0.0020          109.35m
        80           0.7640           0.0014          108.54m
        90           0.7480           0.0013          107.84m
       100           0.7392           0.0010          107.32m
       200           0.6704           0.0003          101.06m
       300           0.6379           0.0001           96.13m
       400           0.6135           0.0002           91.79m
       500           0.5945           0.0002           87.85m
       600           0.5754           0.0000           84.17m
       700           0.5625           0.0000           80.80m
       800           0.5490           0.0000           77.29m
       900           0.5415          -0.0000           73.99m
      1000           0.5300           0.0000           70.59m
      2000           0.4624          -0.0000           38.00m
      3000           0.4194          -0.0000            6.28m
### Start Time 2019/11/12-13-34-15  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=297   randForSplit=830   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.92      0.93     28178
Train discard       0.90      0.93      0.92     23813

    micro avg       0.92      0.92      0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9214    P: 0.9408    R: 0.9167    NPV: 0.9043

['yes', 'no']
[[25831  2347]
 [ 1626 22187]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.89      0.88      5596
Valid discard       0.92      0.90      0.91      7463

    micro avg       0.90      0.90      0.90     13059
    macro avg       0.90      0.90      0.90     13059
 weighted avg       0.90      0.90      0.90     13059

Valid (keep) F2: 0.8892    P: 0.8739    R: 0.8931    NPV: 0.9185

['yes', 'no']
[[4998  598]
 [ 721 6742]]

### Note: .Optimizing learning_rate & n_estimators.
init param: RF n_estimators=50, min_samples_leaf=15

### Best Pipeline Parameters:
classifier__learning_rate: 0.025
classifier__n_estimators: 3200

classifier:
GradientBoostingClassifier(criterion='friedman_mse',
              init=<__main__.Working_Init_Classifier instance at 0x7fe431d4c7e8>,
              learning_rate=0.025, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=3200,
              n_iter_no_change=None, presort='auto', random_state=297,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### End Time 2019/11/12-15-30-23. Total   6967.69 seconds

      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3401           0.0398           93.84m
         2           1.3025           0.0378           79.60m
         3           1.2690           0.0334           73.29m
         4           1.2378           0.0311           69.45m
         5           1.2081           0.0284           67.57m
         6           1.1823           0.0262           66.49m
         7           1.1593           0.0247           65.81m
         8           1.1367           0.0225           65.21m
         9           1.1154           0.0200           64.96m
        10           1.0967           0.0188           64.73m
        20           0.9549           0.0103           63.12m
        30           0.8772           0.0059           62.19m
        40           0.8257           0.0036           61.09m
        50           0.7955           0.0028           60.40m
        60           0.7697           0.0020           59.97m
        70           0.7492           0.0017           59.20m
        80           0.7336           0.0011           58.67m
        90           0.7206           0.0010           57.94m
       100           0.7077           0.0010           57.51m
       200           0.6421           0.0004           52.53m
       300           0.6018           0.0002           48.34m
       400           0.5764           0.0002           44.33m
       500           0.5530          -0.0000           40.50m
       600           0.5299           0.0000           36.81m
       700           0.5208          -0.0000           33.00m
       800           0.5036          -0.0000           29.21m
       900           0.4913          -0.0001           25.51m
      1000           0.4819           0.0000           21.81m
### Start Time 2019/11/13-10-21-30  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=2   randForSplit=994   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.92     28178
Train discard       0.90      0.93      0.91     23813

    micro avg       0.92      0.92      0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9165    P: 0.9367    R: 0.9116    NPV: 0.8986

['yes', 'no']
[[25686  2492]
 [ 1737 22076]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.89      0.88      5596
Valid discard       0.92      0.90      0.91      7463

    micro avg       0.90      0.90      0.90     13059
    macro avg       0.90      0.90      0.90     13059
 weighted avg       0.90      0.90      0.90     13059

Valid (keep) F2: 0.8895    P: 0.8737    R: 0.8935    NPV: 0.9188

['yes', 'no']
[[5000  596]
 [ 723 6740]]

### Note: Try w/o using RF init.

### Best Pipeline Parameters:

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=2,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### End Time 2019/11/13-11-34-50. Total   4400.44 seconds

      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3385           0.0421           95.91m
         2           1.3021           0.0355           79.16m
         3           1.2704           0.0319           74.57m
         4           1.2398           0.0307           72.43m
         5           1.2116           0.0277           71.18m
         6           1.1842           0.0262           69.86m
         7           1.1592           0.0243           69.33m
         8           1.1364           0.0218           68.98m
         9           1.1170           0.0206           68.93m
        10           1.0980           0.0182           68.92m
        20           0.9571           0.0099           68.07m
        30           0.8768           0.0063           65.95m
        40           0.8274           0.0036           64.27m
        50           0.7944           0.0026           63.60m
        60           0.7713           0.0020           63.27m
        70           0.7505           0.0015           62.70m
        80           0.7395           0.0012           62.11m
        90           0.7209           0.0010           61.55m
       100           0.7125           0.0012           60.80m
       200           0.6429           0.0003           54.57m
       300           0.6022           0.0001           49.17m
       400           0.5733           0.0000           44.71m
       500           0.5521           0.0000           40.53m
       600           0.5345           0.0000           36.60m
       700           0.5180           0.0000           32.80m
       800           0.5054          -0.0000           29.06m
       900           0.4923           0.0001           25.34m
      1000           0.4826          -0.0000           21.63m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3437           0.0424          115.38m
         2           1.3070           0.0377           96.79m
         3           1.2717           0.0348           91.24m
         4           1.2411           0.0300           88.62m
         5           1.2122           0.0283           86.06m
         6           1.1860           0.0258           85.05m
         7           1.1624           0.0243           83.54m
         8           1.1377           0.0231           82.36m
         9           1.1160           0.0204           82.19m
        10           1.0986           0.0197           81.69m
        20           0.9545           0.0109           79.26m
        30           0.8753           0.0055           77.77m
        40           0.8262           0.0042           76.47m
        50           0.7871           0.0030           75.31m
        60           0.7632           0.0018           74.20m
        70           0.7473           0.0015           73.43m
        80           0.7316           0.0009           72.63m
        90           0.7192           0.0009           71.93m
       100           0.7091           0.0006           71.12m
       200           0.6421           0.0003           65.48m
       300           0.6023           0.0002           60.46m
       400           0.5812           0.0001           55.60m
       500           0.5592           0.0000           51.02m
       600           0.5413           0.0000           46.33m
       700           0.5251          -0.0000           41.57m
       800           0.5132          -0.0000           36.80m
       900           0.5015           0.0000           32.14m
      1000           0.4892          -0.0000           27.47m
### Start Time 2019/11/13-15-32-17  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=517   randForSplit=833   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.93     28178
Train discard       0.90      0.93      0.91     23813

    micro avg       0.92      0.92      0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9178    P: 0.9374    R: 0.9131    NPV: 0.9002

['yes', 'no']
[[25728  2450]
 [ 1718 22095]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.89      0.88      5596
Valid discard       0.92      0.90      0.91      7463

    micro avg       0.90      0.90      0.90     13059
    macro avg       0.90      0.90      0.90     13059
 weighted avg       0.90      0.90      0.90     13059

Valid (keep) F2: 0.8888    P: 0.8731    R: 0.8928    NPV: 0.9182

['yes', 'no']
[[4996  600]
 [ 726 6737]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.87      0.88      0.88      4188
Test  discard       0.91      0.90      0.91      5506

    micro avg       0.89      0.89      0.89      9694
    macro avg       0.89      0.89      0.89      9694
 weighted avg       0.89      0.89      0.89      9694

Test  (keep) F2: 0.8809    P: 0.8746    R: 0.8825    NPV: 0.9100

['yes', 'no']
[[3696  492]
 [ 530 4976]]

### Note: Try w/o using RF init.

### Best Pipeline Parameters:

featureEvaluator:
FeatureDocCounter()

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=517,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Feature weights: highest 20
+0.2468	mice figur
+0.1288	wild_typ
+0.0980	wild_typ mice
+0.0849	cre
+0.0367	litterm
+0.0276	transgen mice
+0.0274	mut_mut
+0.0266	genotyp
+0.0193	knock_out mice
+0.0131	transgen
+0.0130	mice compar
+0.0119	knock_out
+0.0077	embryonic_day
+0.0075	mice strain
+0.0073	relat figur
+0.0050	mice model
+0.0050	embryon
+0.0048	mut_mut mice
+0.0047	mice express
+0.0043	defici

### Feature weights: lowest 20
+0.0000	withdraw
+0.0000	wk
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wors
+0.0000	wound heal
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell', u'involv regul', u'iodid', u'ion']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 726
29406270
27617678
29228333
29955044
28993663

### False negatives for Validation set: 600
29953499
28062700
26673701
28837808
27911798

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
Test Set            :         9694         4188         5506          43%
ValidationSplit: 0.20
### End Time 2019/11/13-18-22-33. Total  10216.82 seconds
Predictions from GB_train_pred.txt - Wed Nov 13 20:29:39 2019
Recall for papers selected by each curation group. 51991 papers analyzed
ap             selected papers: 24539 predicted keep: 23235 recall: 0.947
gxd            selected papers:  2345 predicted keep:  2273 recall: 0.969
go             selected papers: 19107 predicted keep: 17698 recall: 0.926
tumor          selected papers:  4364 predicted keep:  4000 recall: 0.917
qtl            selected papers:   169 predicted keep:   144 recall: 0.852
Totals         keep     papers: 28178 predicted keep: 25728 recall: 0.913

Predictions from GB_val_pred.txt - Wed Nov 13 20:29:21 2019
Recall for papers selected by each curation group. 13059 papers analyzed
ap             selected papers:  4888 predicted keep:  4518 recall: 0.924
gxd            selected papers:   475 predicted keep:   456 recall: 0.960
go             selected papers:  4180 predicted keep:  3780 recall: 0.905
tumor          selected papers:   316 predicted keep:   283 recall: 0.896
qtl            selected papers:    18 predicted keep:    15 recall: 0.833
Totals         keep     papers:  5596 predicted keep:  4996 recall: 0.893

Predictions from GB_test_pred.txt - Wed Nov 13 20:29:01 2019
Recall for papers selected by each curation group. 9694 papers analyzed
ap             selected papers:  3631 predicted keep:  3319 recall: 0.914
gxd            selected papers:   328 predicted keep:   304 recall: 0.927
go             selected papers:  3094 predicted keep:  2765 recall: 0.894
tumor          selected papers:   222 predicted keep:   206 recall: 0.928
qtl            selected papers:    18 predicted keep:    15 recall: 0.833
Totals         keep     papers:  4188 predicted keep:  3696 recall: 0.883
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3423           0.0374           93.93m
         2           1.3047           0.0382           79.19m
         3           1.2723           0.0311           74.69m
         4           1.2406           0.0310           71.72m
         5           1.2109           0.0297           70.03m
         6           1.1850           0.0258           68.92m
         7           1.1601           0.0257           68.18m
         8           1.1369           0.0237           67.54m
         9           1.1140           0.0211           67.33m
        10           1.0940           0.0204           67.05m
        20           0.9545           0.0111           64.39m
        30           0.8760           0.0063           63.37m
        40           0.8253           0.0038           62.12m
        50           0.7906           0.0028           61.38m
        60           0.7652           0.0017           60.74m
        70           0.7472           0.0014           60.09m
        80           0.7309           0.0012           59.35m
        90           0.7179           0.0010           58.64m
       100           0.7085           0.0010           57.96m
       200           0.6371           0.0004           54.22m
       300           0.5994           0.0001           50.34m
       400           0.5724           0.0001           46.21m
       500           0.5482          -0.0000           42.17m
       600           0.5310           0.0000           38.34m
       700           0.5134          -0.0000           34.45m
       800           0.5043          -0.0000           30.49m
       900           0.4904          -0.0000           26.61m
      1000           0.4794          -0.0000           22.80m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3434           0.0414          128.41m
         2           1.3058           0.0384          106.04m
         3           1.2718           0.0348           97.50m
         4           1.2421           0.0293           93.11m
         5           1.2139           0.0288           91.15m
         6           1.1870           0.0266           90.43m
         7           1.1615           0.0256           90.99m
         8           1.1376           0.0226           90.79m
         9           1.1171           0.0210           90.50m
        10           1.0978           0.0200           89.78m
        20           0.9529           0.0106           86.61m
        30           0.8730           0.0067           84.13m
        40           0.8237           0.0039           82.12m
        50           0.7873           0.0029           80.76m
        60           0.7587           0.0017           80.51m
        70           0.7446           0.0015           80.19m
        80           0.7271           0.0012           79.14m
        90           0.7191           0.0009           78.65m
       100           0.7029           0.0009           77.70m
       200           0.6413           0.0002           68.72m
       300           0.6029           0.0001           62.70m
       400           0.5763           0.0001           57.39m
       500           0.5558          -0.0000           52.33m
       600           0.5375           0.0000           47.33m
       700           0.5256           0.0000           42.42m
       800           0.5107          -0.0000           37.57m
       900           0.5002           0.0000           32.81m
      1000           0.4893           0.0000           28.04m
### Start Time 2019/11/18-16-54-38  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=296   randForSplit=405   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.93     28200
Train discard       0.90      0.93      0.91     24057

    micro avg       0.92      0.92      0.92     52257
    macro avg       0.92      0.92      0.92     52257
 weighted avg       0.92      0.92      0.92     52257

Train (keep) F2: 0.9182    P: 0.9377    R: 0.9134    NPV: 0.9015

['yes', 'no']
[[25758  2442]
 [ 1711 22346]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.88      5554
Valid discard       0.91      0.90      0.90      7130

    micro avg       0.89      0.89      0.89     12684
    macro avg       0.89      0.89      0.89     12684
 weighted avg       0.89      0.89      0.89     12684

Valid (keep) F2: 0.8786    P: 0.8721    R: 0.8803    NPV: 0.9060

['yes', 'no']
[[4889  665]
 [ 717 6413]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.88      0.88      0.88      4208
Test  discard       0.91      0.91      0.91      5595

    micro avg       0.90      0.90      0.90      9803
    macro avg       0.90      0.90      0.90      9803
 weighted avg       0.90      0.90      0.90      9803

Test  (keep) F2: 0.8833    P: 0.8774    R: 0.8847    NPV: 0.9128

['yes', 'no']
[[3723  485]
 [ 520 5075]]

### Note: Try blessed GB with 2nd data split.

### Best Pipeline Parameters:

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=296,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Feature weights: highest 20
+0.2548	mice figur
+0.1475	wild_typ mice
+0.0863	cre
+0.0602	wild_typ
+0.0334	litterm
+0.0329	mut_mut
+0.0315	knock_out
+0.0253	transgen mice
+0.0248	genotyp
+0.0179	knock_out mice
+0.0130	transgen
+0.0082	mice strain
+0.0081	relat figur
+0.0074	embryonic_day
+0.0071	mice compar
+0.0051	mice express
+0.0049	mice model
+0.0048	defici
+0.0047	mut_mut mice
+0.0045	embryon

### Feature weights: lowest 20
+0.0000	wild_typ vs
+0.0000	window
+0.0000	withdraw
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	wors
+0.0000	wound heal
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone

### Vectorizer:   Number of Features: 6782
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'invad', u'invas', u'invers', u'invers correl', u'invert', u'investig', u'investig effect', u'investig express', u'investig mechan', u'investig possibl']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 717
30274781
24945711
28855256
25754161
30275296

### False negatives for Validation set: 665
29164996
26909801
28881034
2058742
27462106

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        52257        28200        24057          54%
Validation Set      :        12684         5554         7130          44%
Test Set            :         9803         4208         5595          43%
ValidationSplit: 0.20
### End Time 2019/11/18-19-49-06. Total  10468.81 seconds

Recall for papers selected by each curation group. 12684 papers analyzed
ap             selected papers:  4804 predicted keep:  4387 recall: 0.913
gxd            selected papers:   476 predicted keep:   450 recall: 0.945
go             selected papers:  4106 predicted keep:  3678 recall: 0.896
tumor          selected papers:   349 predicted keep:   303 recall: 0.868
qtl            selected papers:    23 predicted keep:    15 recall: 0.652
Totals         keep     papers:  5554 predicted keep:  4889 recall: 0.880
Predictions from GB_val_pred.txt - Mon Nov 18 21:32:57 2019
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3408           0.0373           68.07m
         2           1.3031           0.0385           56.25m
         3           1.2725           0.0313           53.34m
         4           1.2410           0.0308           51.46m
         5           1.2121           0.0290           50.68m
         6           1.1850           0.0262           50.12m
         7           1.1595           0.0253           49.46m
         8           1.1366           0.0225           48.98m
         9           1.1164           0.0221           48.68m
        10           1.0956           0.0202           48.27m
        20           0.9532           0.0105           46.62m
        30           0.8729           0.0059           45.86m
        40           0.8228           0.0044           45.29m
        50           0.7915           0.0030           44.84m
        60           0.7621           0.0016           44.20m
        70           0.7471           0.0013           43.77m
        80           0.7345           0.0012           43.26m
        90           0.7211           0.0009           42.90m
       100           0.7069           0.0009           42.43m
       200           0.6419           0.0003           38.81m
       300           0.6032           0.0003           35.64m
       400           0.5771           0.0000           32.71m
       500           0.5542          -0.0000           29.95m
       600           0.5385           0.0000           27.11m
       700           0.5241           0.0000           24.37m
       800           0.5078           0.0001           21.66m
       900           0.5007          -0.0000           18.94m
      1000           0.4868          -0.0001           16.23m
### Start Time 2019/11/19-09-35-33  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=180   randForSplit=314   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.92     28200
Train discard       0.90      0.93      0.91     24057

    micro avg       0.92      0.92      0.92     52257
    macro avg       0.92      0.92      0.92     52257
 weighted avg       0.92      0.92      0.92     52257

Train (keep) F2: 0.9162    P: 0.9353    R: 0.9115    NPV: 0.8993

['yes', 'no']
[[25705  2495]
 [ 1779 22278]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.87      5554
Valid discard       0.91      0.89      0.90      7130

    micro avg       0.89      0.89      0.89     12684
    macro avg       0.89      0.89      0.89     12684
 weighted avg       0.89      0.89      0.89     12684

Valid (keep) F2: 0.8777    P: 0.8669    R: 0.8804    NPV: 0.9057

['yes', 'no']
[[4890  664]
 [ 751 6379]]

### Note: Try blessed GB with 2nd data split, cut features in half.

### Best Pipeline Parameters:

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=180,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=3000, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Feature weights: highest 20
+0.2323	mice figur
+0.1521	wild_typ mice
+0.0905	cre
+0.0627	wild_typ
+0.0379	litterm
+0.0307	mut_mut
+0.0276	knock_out
+0.0257	genotyp
+0.0248	mice compar
+0.0244	transgen mice
+0.0157	knock_out mice
+0.0148	transgen
+0.0086	relat figur
+0.0083	mice strain
+0.0074	embryonic_day
+0.0073	mut_mut mice
+0.0057	mice express
+0.0057	embryon
+0.0056	mice model
+0.0046	defici

### Feature weights: lowest 20
+0.0000	variat
+0.0000	varieti
+0.0000	vascular
+0.0000	vehicl control
+0.0000	venn
+0.0000	venn diagram
+0.0000	ventral
+0.0000	ventricl
+0.0000	vessel
+0.0000	viabl
+0.0000	visibl
+0.0000	vitro figur
+0.0000	wall
+0.0000	whi
+0.0000	white arrow
+0.0000	width
+0.0000	wild_typ litterm
+0.0000	yellow
+0.0000	zero
+0.0000	zone

### Vectorizer:   Number of Features: 3000
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'issu', u'iv', u'jackson', u'journal__nat_commun', u'journal__plos_one', u'journal__sci_rep', u'junction', u'just', u'kaplan', u'kaplan meier']

Last 10 features: [u'wk', u'wnt', u'work', u'xenograft', u'year', u'yellow', u'yield', u'young', u'zero', u'zone']

### False positives for Validation set: 751
30274781
24945711
29406270
28855256
27617678

### False negatives for Validation set: 664
29164996
26909801
28881034
2058742
28819122

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        52257        28200        24057          54%
Validation Set      :        12684         5554         7130          44%
ValidationSplit: 0.20
### End Time 2019/11/19-10-41-18. Total   3945.46 seconds

Recall for papers selected by each curation group. 12684 papers analyzed
ap             selected papers:  4804 predicted keep:  4390 recall: 0.914
gxd            selected papers:   476 predicted keep:   445 recall: 0.935
go             selected papers:  4106 predicted keep:  3681 recall: 0.897
tumor          selected papers:   349 predicted keep:   304 recall: 0.871
qtl            selected papers:    23 predicted keep:    14 recall: 0.609
Totals         keep     papers:  5554 predicted keep:  4890 recall: 0.880
Predictions from GB_val_pred.txt - Tue Nov 19 10:42:51 2019
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3419           0.0372           94.06m
         2           1.3057           0.0360           79.29m
         3           1.2705           0.0357           73.88m
         4           1.2400           0.0320           71.19m
         5           1.2104           0.0285           68.99m
         6           1.1832           0.0266           68.24m
         7           1.1595           0.0233           67.09m
         8           1.1361           0.0234           66.55m
         9           1.1160           0.0202           66.33m
        10           1.0972           0.0200           66.11m
        20           0.9552           0.0107           64.18m
        30           0.8741           0.0060           63.83m
        40           0.8254           0.0043           63.18m
        50           0.7926           0.0029           62.19m
        60           0.7669           0.0021           61.34m
        70           0.7475           0.0018           60.46m
        80           0.7297           0.0010           59.71m
        90           0.7198           0.0009           59.08m
       100           0.7088           0.0008           58.57m
       200           0.6393           0.0003           53.37m
       300           0.5989           0.0002           49.11m
       400           0.5686           0.0001           44.96m
       500           0.5482           0.0000           40.94m
       600           0.5302          -0.0000           37.33m
       700           0.5117          -0.0001           33.73m
       800           0.5036          -0.0000           29.93m
       900           0.4899          -0.0000           26.13m
      1000           0.4779          -0.0000           22.36m
### Start Time 2019/11/19-11-44-29  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       None
Random Seeds:	randForClassifier=985   randForSplit=82   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.93     28364
Train discard       0.90      0.93      0.92     23982

    micro avg       0.92      0.92      0.92     52346
    macro avg       0.92      0.92      0.92     52346
 weighted avg       0.92      0.92      0.92     52346

Train (keep) F2: 0.9193    P: 0.9383    R: 0.9147    NPV: 0.9020

['yes', 'no']
[[25945  2419]
 [ 1706 22276]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.88      0.87      5432
Valid discard       0.91      0.90      0.90      7403

    micro avg       0.89      0.89      0.89     12835
    macro avg       0.89      0.89      0.89     12835
 weighted avg       0.89      0.89      0.89     12835

Valid (keep) F2: 0.8762    P: 0.8613    R: 0.8800    NPV: 0.9105

['yes', 'no']
[[4780  652]
 [ 770 6633]]

### Note: Try blessed GB with 3rd data split.

### Best Pipeline Parameters:

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=985,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Feature weights: highest 20
+0.2663	mice figur
+0.1349	wild_typ mice
+0.0900	cre
+0.0638	wild_typ
+0.0373	litterm
+0.0297	genotyp
+0.0260	mut_mut
+0.0250	transgen mice
+0.0157	transgen
+0.0150	knock_out
+0.0145	knock_out mice
+0.0129	mut_mut mice
+0.0087	relat figur
+0.0087	mice strain
+0.0085	mice compar
+0.0073	embryonic_day
+0.0058	mice express
+0.0051	mice model
+0.0049	defici
+0.0044	embryon

### Feature weights: lowest 20
+0.0000	withdraw
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xlsx
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	yield
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'investig', u'investig effect', u'investig express', u'investig mechan', u'investig possibl', u'investig potenti', u'investig role', u'invitrogen', u'involv', u'involv cell']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 770
24945711
29406270
28855256
25754161
29033132

### False negatives for Validation set: 652
28362853
28881034
30684640
28594915
27653140

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        52346        28364        23982          54%
Validation Set      :        12835         5432         7403          42%
ValidationSplit: 0.20
### End Time 2019/11/19-13-06-07. Total   4897.63 seconds

Recall for papers selected by each curation group. 12835 papers analyzed
ap             selected papers:  4743 predicted keep:  4327 recall: 0.912
gxd            selected papers:   428 predicted keep:   403 recall: 0.942
go             selected papers:  4015 predicted keep:  3587 recall: 0.893
tumor          selected papers:   305 predicted keep:   274 recall: 0.898
qtl            selected papers:    22 predicted keep:    21 recall: 0.955
Totals         keep     papers:  5432 predicted keep:  4780 recall: 0.880
Predictions from GB_val_pred.txt - Tue Nov 19 13:08:17 2019
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3427           0.0391           95.18m
         2           1.3041           0.0373           80.28m
         3           1.2712           0.0335           74.53m
         4           1.2404           0.0319           71.87m
         5           1.2117           0.0275           70.30m
         6           1.1855           0.0257           69.42m
         7           1.1618           0.0252           68.38m
         8           1.1391           0.0221           67.77m
         9           1.1181           0.0208           67.25m
        10           1.0994           0.0191           66.88m
        20           0.9586           0.0106           64.83m
        30           0.8792           0.0062           63.77m
        40           0.8273           0.0042           62.54m
        50           0.7917           0.0029           62.03m
        60           0.7668           0.0018           61.41m
        70           0.7521           0.0016           60.77m
        80           0.7374           0.0012           59.99m
        90           0.7238           0.0012           59.32m
       100           0.7117           0.0010           58.65m
       200           0.6424           0.0004           53.48m
       300           0.6018           0.0001           49.14m
       400           0.5780           0.0001           45.02m
       500           0.5488           0.0002           41.09m
       600           0.5338           0.0001           37.15m
       700           0.5180           0.0000           33.28m
       800           0.5068          -0.0000           29.66m
       900           0.4921          -0.0000           26.12m
      1000           0.4813          -0.0000           22.52m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3462           0.0401          119.83m
         2           1.3076           0.0383          100.41m
         3           1.2733           0.0344           93.72m
         4           1.2415           0.0320           90.13m
         5           1.2126           0.0284           87.94m
         6           1.1856           0.0271           86.81m
         7           1.1610           0.0252           86.27m
         8           1.1392           0.0225           85.84m
         9           1.1180           0.0213           85.09m
        10           1.0973           0.0197           84.78m
        20           0.9548           0.0112           82.40m
        30           0.8751           0.0058           81.28m
        40           0.8230           0.0040           80.38m
        50           0.7887           0.0030           79.50m
        60           0.7651           0.0020           78.66m
        70           0.7476           0.0015           77.92m
        80           0.7307           0.0014           77.07m
        90           0.7191           0.0009           76.16m
       100           0.7112           0.0008           75.38m
       200           0.6464           0.0005           69.48m
       300           0.6081           0.0002           63.92m
       400           0.5804           0.0000           58.76m
       500           0.5618           0.0000           53.64m
       600           0.5449           0.0000           48.70m
       700           0.5297           0.0000           43.69m
       800           0.5170          -0.0000           38.79m
       900           0.5071           0.0001           33.87m
      1000           0.4940          -0.0000           28.98m
### Start Time 2019/12/05-14-59-38  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=206   randForSplit=491   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.92     28216
Train discard       0.90      0.93      0.91     24521

    micro avg       0.92      0.92      0.92     52737
    macro avg       0.92      0.92      0.92     52737
 weighted avg       0.92      0.92      0.92     52737

Train (keep) F2: 0.9153    P: 0.9363    R: 0.9102    NPV: 0.8999

['yes', 'no']
[[25682  2534]
 [ 1746 22775]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.88      5493
Valid discard       0.91      0.91      0.91      7594

    micro avg       0.90      0.90      0.90     13087
    macro avg       0.89      0.89      0.89     13087
 weighted avg       0.90      0.90      0.90     13087

Valid (keep) F2: 0.8793    P: 0.8706    R: 0.8815    NPV: 0.9135

['yes', 'no']
[[4842  651]
 [ 720 6874]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.88      0.87      0.88      4253
Test  discard       0.90      0.91      0.91      5585

    micro avg       0.90      0.90      0.90      9838
    macro avg       0.89      0.89      0.89      9838
 weighted avg       0.90      0.90      0.90      9838

Test  (keep) F2: 0.8757    P: 0.8825    R: 0.8740    NPV: 0.9047

['yes', 'no']
[[3717  536]
 [ 495 5090]]

### Note: blessed GB.

### Best Pipeline Parameters:

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.05, loss='deviance', max_depth=3,
              max_features=0.7, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=150, min_samples_split=600,
              min_weight_fraction_leaf=0.0, n_estimators=1600,
              n_iter_no_change=None, presort='auto', random_state=206,
              subsample=0.85, tol=0.0001, validation_fraction=0.1,
              verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


### Feature weights: highest 20
+0.2678	mice figur
+0.1212	wild_typ mice
+0.0935	cre
+0.0794	wild_typ
+0.0339	litterm
+0.0275	mut_mut
+0.0270	genotyp
+0.0243	transgen mice
+0.0176	knock_out mice
+0.0133	transgen
+0.0132	knock_out
+0.0085	mut_mut mice
+0.0085	relat figur
+0.0080	mice compar
+0.0076	embryonic_day
+0.0072	mice strain
+0.0071	embryon
+0.0049	defici
+0.0049	mice express
+0.0044	xenograft

### Feature weights: lowest 20
+0.0000	withdraw
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	wors
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6776
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'abdomin', u'aberr', u'abil', u'abl']

Middle 10 features: [u'invad', u'invas', u'invers', u'invers correl', u'invert', u'investig', u'investig effect', u'investig mechan', u'investig possibl', u'investig potenti']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Validation set: 720
28389561
28151936
27474411
27223694
28151995

### False negatives for Validation set: 651
28594915
29126777
30255127
27270268
30217409

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        52737        28216        24521          54%
Validation Set      :        13087         5493         7594          42%
Test Set            :         9838         4253         5585          43%
ValidationSplit: 0.20
### End Time 2019/12/05-17-55-32. Total  10553.86 seconds

Recall for papers selected by each curation group. 13087 papers analyzed
ap             selected papers:  4794 predicted keep:  4377 recall: 0.913
gxd            selected papers:   459 predicted keep:   434 recall: 0.946
go             selected papers:  4019 predicted keep:  3599 recall: 0.896
tumor          selected papers:   328 predicted keep:   295 recall: 0.899
qtl            selected papers:    17 predicted keep:    15 recall: 0.882
Totals         keep     papers:  5493 predicted keep:  4842 recall: 0.881
Predictions from GB_val_pred.txt - Thu Dec  5 17:57:44 2019
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3402           0.0408           97.54m
         2           1.3037           0.0365           80.53m
         3           1.2694           0.0335           75.02m
         4           1.2393           0.0305           72.41m
         5           1.2119           0.0275           70.57m
         6           1.1869           0.0263           69.53m
         7           1.1620           0.0232           68.48m
         8           1.1411           0.0219           67.97m
         9           1.1195           0.0207           67.76m
        10           1.0993           0.0208           67.26m
        20           0.9612           0.0104           64.42m
        30           0.8817           0.0069           63.48m
        40           0.8272           0.0044           62.62m
        50           0.7931           0.0029           61.73m
        60           0.7709           0.0019           60.86m
        70           0.7503           0.0015           60.21m
        80           0.7337           0.0011           59.45m
        90           0.7241           0.0008           58.68m
       100           0.7106           0.0008           58.19m
       200           0.6461           0.0004           53.14m
       300           0.6088           0.0003           48.78m
       400           0.5793           0.0001           44.75m
       500           0.5607           0.0000           40.78m
       600           0.5408          -0.0000           36.85m
       700           0.5237          -0.0001           33.01m
       800           0.5116          -0.0000           29.27m
       900           0.4985          -0.0001           25.52m
      1000           0.4871          -0.0000           21.82m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3455           0.0399          121.08m
         2           1.3092           0.0370          102.33m
         3           1.2748           0.0344           95.59m
         4           1.2424           0.0315           92.48m
         5           1.2132           0.0294           90.35m
         6           1.1866           0.0268           88.98m
         7           1.1627           0.0245           88.54m
         8           1.1396           0.0219           87.85m
         9           1.1193           0.0208           87.10m
        10           1.0995           0.0204           86.57m
        20           0.9575           0.0105           83.59m
        30           0.8770           0.0062           82.74m
        40           0.8268           0.0035           81.53m
        50           0.7931           0.0026           80.37m
        60           0.7694           0.0020           79.37m
        70           0.7486           0.0016           78.56m
        80           0.7301           0.0011           77.69m
        90           0.7209           0.0010           76.68m
       100           0.7126           0.0008           76.02m
       200           0.6457           0.0002           70.16m
       300           0.6070           0.0003           64.44m
       400           0.5817           0.0001           59.26m
       500           0.5609           0.0001           54.16m
       600           0.5458           0.0000           49.18m
       700           0.5287          -0.0001           44.15m
       800           0.5192          -0.0001           39.14m
       900           0.5092           0.0000           34.18m
      1000           0.4967          -0.0001           29.33m
### Start Time 2020/03/23-14-11-54  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage3/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage3/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage3/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=272   randForSplit=188   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.93      0.91      0.92     28289
Train discard       0.90      0.93      0.91     24574

     accuracy                           0.92     52863
    macro avg       0.92      0.92      0.92     52863
 weighted avg       0.92      0.92      0.92     52863

Train (keep) F2: 0.9152    P: 0.9343    R: 0.9106    NPV: 0.9000

['keep', 'discard']
[[25759  2530]
 [ 1811 22763]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.88      5506
Valid discard       0.91      0.90      0.91      7551

     accuracy                           0.89     13057
    macro avg       0.89      0.89      0.89     13057
 weighted avg       0.89      0.89      0.89     13057

Valid (keep) F2: 0.8797    P: 0.8700    R: 0.8821    NPV: 0.9132

['keep', 'discard']
[[4857  649]
 [ 726 6825]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.88      0.88      0.88      4167
Test  discard       0.91      0.91      0.91      5575

     accuracy                           0.90      9742
    macro avg       0.90      0.90      0.90      9742
 weighted avg       0.90      0.90      0.90      9742

Test  (keep) F2: 0.8796    P: 0.8826    R: 0.8788    NPV: 0.9097

['keep', 'discard']
[[3662  505]
 [ 487 5088]]

### Note: blessed GB.

### Best Pipeline Parameters:

vectorizer:
CountVectorizer(analyzer='word', binary=True, decode_error='strict',
                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
                lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
                ngram_range=(1, 2), preprocessor=None, stop_words='english',
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
                tokenizer=None, vocabulary=None)

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=3,
                           max_features=0.7, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=150, min_samples_split=600,
                           min_weight_fraction_leaf=0.0, n_estimators=1600,
                           n_iter_no_change=None, presort='auto',
                           random_state=272, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=1,
                           warm_start=False)


### Feature weights: highest 20
+0.2898	mice figur
+0.1130	wild_typ mice
+0.0820	cre
+0.0654	wild_typ
+0.0384	genotyp
+0.0328	litterm
+0.0300	mut_mut
+0.0224	transgen mice
+0.0161	knock_out mice
+0.0159	transgen
+0.0126	knock_out
+0.0099	mice compar
+0.0097	relat figur
+0.0081	embryonic_day
+0.0080	mut_mut mice
+0.0078	mice strain
+0.0067	embryon
+0.0060	mice express
+0.0042	defici
+0.0041	mice model

### Feature weights: lowest 20
+0.0000	window
+0.0000	withdraw
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	wors
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zoom

### Vectorizer:   Number of Features: 6752
First 10 features: ['aa', 'aaa', 'aav', 'ab', 'abbrevi', 'abcam', 'aberr', 'abil', 'abl', 'ablat']

Middle 10 features: ['investig', 'investig effect', 'investig express', 'investig mechan', 'investig possibl', 'investig potenti', 'investig role', 'invitrogen', 'involv', 'involv cell']

Last 10 features: ['young', 'younger', 'zebrafish', 'zeiss', 'zero', 'zhang', 'zhang et', 'zinc', 'zone', 'zoom']

### False positives for Validation set: 726
28368510
28095433
25121482
28633908
26317997

### False negatives for Validation set: 649
29164996
30684640
28594915
2058742
27462106

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        52863        28289        24574          54%
Validation Set      :        13057         5506         7551          42%
Test Set            :         9742         4167         5575          43%
ValidationSplit: 0.20
### End Time 2020/03/23-16-49-49. Total   9475.05 seconds

Recall for papers selected by each curation group. 13057 papers analyzed
ap             selected papers:  4767 predicted keep:  4368 recall: 0.916
gxd            selected papers:   455 predicted keep:   431 recall: 0.947
go             selected papers:  4095 predicted keep:  3676 recall: 0.898
tumor          selected papers:   308 predicted keep:   275 recall: 0.893
qtl            selected papers:    18 predicted keep:    15 recall: 0.833
Totals         keep     papers:  5506 predicted keep:  4857 recall: 0.882
Predictions from GB_val_pred.txt - Tue Mar 24 08:14:50 2020
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3404           0.0407           96.26m
         2           1.3034           0.0367           80.74m
         3           1.2696           0.0338           74.88m
         4           1.2393           0.0303           72.26m
         5           1.2113           0.0290           70.40m
         6           1.1852           0.0266           69.09m
         7           1.1604           0.0242           68.45m
         8           1.1369           0.0224           67.93m
         9           1.1172           0.0197           67.56m
        10           1.0979           0.0185           67.09m
        20           0.9592           0.0109           64.94m
        30           0.8786           0.0060           64.01m
        40           0.8298           0.0040           62.90m
        50           0.7958           0.0029           61.98m
        60           0.7719           0.0019           61.09m
        70           0.7502           0.0015           60.32m
        80           0.7323           0.0012           59.68m
        90           0.7209           0.0010           59.16m
       100           0.7098           0.0011           58.72m
       200           0.6458           0.0001           53.55m
       300           0.6066           0.0002           49.15m
       400           0.5778          -0.0001           45.12m
       500           0.5569           0.0001           41.14m
       600           0.5431           0.0000           37.41m
       700           0.5257           0.0000           33.48m
       800           0.5126          -0.0001           29.64m
       900           0.4970          -0.0001           25.86m
      1000           0.4856          -0.0001           22.14m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3455           0.0401          117.06m
         2           1.3100           0.0354          100.11m
         3           1.2755           0.0346           94.14m
         4           1.2444           0.0305           90.74m
         5           1.2171           0.0280           89.15m
         6           1.1883           0.0270           87.81m
         7           1.1639           0.0235           86.94m
         8           1.1413           0.0230           86.39m
         9           1.1201           0.0204           86.14m
        10           1.1001           0.0199           85.54m
        20           0.9576           0.0108           82.92m
        30           0.8785           0.0056           82.19m
        40           0.8262           0.0044           81.02m
        50           0.7921           0.0027           79.80m
        60           0.7686           0.0019           78.98m
        70           0.7505           0.0018           78.20m
        80           0.7342           0.0013           77.33m
        90           0.7192           0.0010           76.62m
       100           0.7101           0.0008           75.78m
       200           0.6449           0.0004           69.49m
       300           0.6090           0.0001           64.36m
       400           0.5821           0.0000           59.17m
       500           0.5615          -0.0000           54.16m
       600           0.5475          -0.0000           49.00m
       700           0.5309           0.0000           43.93m
       800           0.5158           0.0001           39.01m
       900           0.5048           0.0000           34.12m
      1000           0.4965           0.0000           29.26m
### Start Time 2020/04/15-18-23-12  GB.py	index file: index.out
Training data path:   ./data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: ./data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       ./data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=441   randForSplit=358   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.93      0.91      0.92     28289
Train discard       0.90      0.93      0.91     24574

     accuracy                           0.92     52863
    macro avg       0.92      0.92      0.92     52863
 weighted avg       0.92      0.92      0.92     52863

Train (keep) F2: 0.9148    P: 0.9348    R: 0.9099    NPV: 0.8994

['keep', 'discard']
[[25741  2548]
 [ 1794 22780]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.88      0.88      5506
Valid discard       0.91      0.90      0.91      7551

     accuracy                           0.89     13057
    macro avg       0.89      0.89      0.89     13057
 weighted avg       0.89      0.89      0.89     13057

Valid (keep) F2: 0.8793    P: 0.8690    R: 0.8819    NPV: 0.9130

['keep', 'discard']
[[4856  650]
 [ 732 6819]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.88      0.88      0.88      4167
Test  discard       0.91      0.91      0.91      5575

     accuracy                           0.90      9742
    macro avg       0.90      0.90      0.90      9742
 weighted avg       0.90      0.90      0.90      9742

Test  (keep) F2: 0.8834    P: 0.8836    R: 0.8834    NPV: 0.9128

['keep', 'discard']
[[3681  486]
 [ 485 5090]]

### Note: blessed GB.

### Best Pipeline Parameters:

vectorizer:
CountVectorizer(analyzer='word', binary=True, decode_error='strict',
                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
                lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
                ngram_range=(1, 2), preprocessor=None, stop_words='english',
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
                tokenizer=None, vocabulary=None)

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=3,
                           max_features=0.7, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=150, min_samples_split=600,
                           min_weight_fraction_leaf=0.0, n_estimators=1600,
                           n_iter_no_change=None, presort='auto',
                           random_state=441, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=1,
                           warm_start=False)


### Feature weights: highest 20
+0.2585	mice figur
+0.1250	wild_typ mice
+0.0876	cre
+0.0737	wild_typ
+0.0334	litterm
+0.0312	mut_mut
+0.0277	genotyp
+0.0264	knock_out
+0.0226	transgen mice
+0.0176	transgen
+0.0152	knock_out mice
+0.0094	relat figur
+0.0082	mice compar
+0.0082	mice strain
+0.0077	mut_mut mice
+0.0072	embryonic_day
+0.0070	embryon
+0.0061	mice express
+0.0043	defici
+0.0043	mice model

### Feature weights: lowest 20
+0.0000	wild_typ mutant
+0.0000	wild_typ versus
+0.0000	window
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	wors
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow
+0.0000	yellow arrow
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zoom

### Vectorizer:   Number of Features: 6752
First 10 features: ['aa', 'aaa', 'aav', 'ab', 'abbrevi', 'abcam', 'aberr', 'abil', 'abl', 'ablat']

Middle 10 features: ['investig', 'investig effect', 'investig express', 'investig mechan', 'investig possibl', 'investig potenti', 'investig role', 'invitrogen', 'involv', 'involv cell']

Last 10 features: ['young', 'younger', 'zebrafish', 'zeiss', 'zero', 'zhang', 'zhang et', 'zinc', 'zone', 'zoom']

### False positives for Validation set: 732
28368510
28095433
25121482
28633908
26317997

### False negatives for Validation set: 650
29164996
30684640
28594915
2058742
27462106

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        52863        28289        24574          54%
Validation Set      :        13057         5506         7551          42%
Test Set            :         9742         4167         5575          43%
ValidationSplit: 0.20
### End Time 2020/04/15-20-56-49. Total   9216.91 seconds

      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3390           0.0408           78.47m
         2           1.3011           0.0370           67.85m
         3           1.2672           0.0340           64.14m
         4           1.2365           0.0292           62.44m
         5           1.2092           0.0286           61.29m
         6           1.1824           0.0262           60.77m
         7           1.1587           0.0232           60.26m
         8           1.1366           0.0223           59.99m
         9           1.1174           0.0212           59.78m
        10           1.0967           0.0193           59.54m
        20           0.9565           0.0101           58.57m
        30           0.8768           0.0060           57.70m
        40           0.8297           0.0038           56.93m
        50           0.7941           0.0030           56.21m
        60           0.7688           0.0022           55.51m
        70           0.7518           0.0013           54.66m
        80           0.7366           0.0013           53.95m
        90           0.7192           0.0012           53.31m
       100           0.7101           0.0009           52.69m
       200           0.6400           0.0004           47.69m
       300           0.6027           0.0001           43.86m
       400           0.5743           0.0000           40.22m
       500           0.5498           0.0000           36.64m
       600           0.5336          -0.0000           33.39m
       700           0.5208          -0.0000           29.90m
       800           0.5073          -0.0000           26.49m
       900           0.4919          -0.0001           23.08m
      1000           0.4802          -0.0001           19.72m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3454           0.0391          102.68m
         2           1.3088           0.0370           87.82m
         3           1.2737           0.0350           82.66m
         4           1.2423           0.0303           80.14m
         5           1.2129           0.0295           78.40m
         6           1.1855           0.0274           77.46m
         7           1.1599           0.0249           76.85m
         8           1.1371           0.0221           76.50m
         9           1.1161           0.0203           76.17m
        10           1.0971           0.0197           76.36m
        20           0.9566           0.0113           74.60m
        30           0.8763           0.0067           73.71m
        40           0.8257           0.0041           72.15m
        50           0.7906           0.0028           71.19m
        60           0.7675           0.0019           70.44m
        70           0.7454           0.0014           69.86m
        80           0.7321           0.0012           68.85m
        90           0.7193           0.0008           67.90m
       100           0.7069           0.0009           67.05m
       200           0.6473           0.0003           61.40m
       300           0.6044           0.0002           56.67m
       400           0.5788           0.0000           52.12m
       500           0.5591           0.0000           47.70m
       600           0.5393           0.0000           43.35m
       700           0.5255          -0.0000           38.94m
       800           0.5147           0.0000           34.52m
       900           0.5035          -0.0001           30.17m
      1000           0.4922          -0.0001           25.76m
### Start Time 2020/04/20-15-05-52  GB.py
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/valSet.txt
Test data path:       /home/jak/work/autolittriage/Train/primTriage/data/sep18/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=588   randForSplit=676   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.91      0.92     28178
Train discard       0.90      0.93      0.91     23813

     accuracy                           0.92     51991
    macro avg       0.92      0.92      0.92     51991
 weighted avg       0.92      0.92      0.92     51991

Train (keep) F2: 0.9164    P: 0.9381    R: 0.9111    NPV: 0.8983

['keep', 'discard']
[[25674  2504]
 [ 1694 22119]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.89      0.88      5596
Valid discard       0.92      0.90      0.91      7463

     accuracy                           0.90     13059
    macro avg       0.90      0.90      0.90     13059
 weighted avg       0.90      0.90      0.90     13059

Valid (keep) F2: 0.8893    P: 0.8731    R: 0.8935    NPV: 0.9187

['keep', 'discard']
[[5000  596]
 [ 727 6736]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.87      0.88      0.88      4188
Test  discard       0.91      0.90      0.91      5506

     accuracy                           0.90      9694
    macro avg       0.89      0.89      0.89      9694
 weighted avg       0.90      0.90      0.90      9694

Test  (keep) F2: 0.8821    P: 0.8750    R: 0.8840    NPV: 0.9110

['keep', 'discard']
[[3702  486]
 [ 529 4977]]

### Note: blessed GB.

### Best Pipeline Parameters:

vectorizer:
CountVectorizer(analyzer='word', binary=True, decode_error='strict',
                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
                lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
                ngram_range=(1, 2), preprocessor=None, stop_words='english',
                strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
                tokenizer=None, vocabulary=None)

classifier:
GradientBoostingClassifier(criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='deviance', max_depth=3,
                           max_features=0.7, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=150, min_samples_split=600,
                           min_weight_fraction_leaf=0.0, n_estimators=1600,
                           n_iter_no_change=None, presort='auto',
                           random_state=588, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=1,
                           warm_start=False)


### Feature weights: highest 20
+0.2667	mice figur
+0.1369	wild_typ mice
+0.0842	cre
+0.0659	wild_typ
+0.0382	litterm
+0.0303	genotyp
+0.0259	mut_mut
+0.0220	transgen mice
+0.0180	knock_out
+0.0178	knock_out mice
+0.0174	transgen
+0.0089	mice compar
+0.0077	mice strain
+0.0075	relat figur
+0.0074	mut_mut mice
+0.0070	embryonic_day
+0.0049	mice model
+0.0048	defici
+0.0048	mice express
+0.0046	embryon

### Feature weights: lowest 20
+0.0000	wk
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	wors
+0.0000	wound
+0.0000	wound heal
+0.0000	wrote
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yellow arrow
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6769
First 10 features: ['aa', 'aaa', 'aav', 'ab', 'abbrevi', 'abcam', 'aberr', 'abil', 'abl', 'ablat']

Middle 10 features: ['investig mechan', 'investig possibl', 'investig potenti', 'investig role', 'invitrogen', 'involv', 'involv cell', 'involv regul', 'iodid', 'ion']

Last 10 features: ['young', 'younger', 'zebrafish', 'zeiss', 'zero', 'zhang', 'zhang et', 'zinc', 'zone', 'zoom']

### False positives for Validation set: 727
29406270
29228333
29955044
28993663
28963450

### False negatives for Validation set: 596
29953499
28062700
26673701
28775166
28837808

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        51991        28178        23813          54%
Validation Set      :        13059         5596         7463          43%
Test Set            :         9694         4188         5506          43%
ValidationSplit: 0.20
### End Time 2020/04/20-17-23-47. Total   8274.33 seconds
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3400           0.0444           57.74m
         2           1.3021           0.0392           49.80m
         3           1.2643           0.0357           47.06m
         4           1.2320           0.0334           45.90m
         5           1.2010           0.0304           45.10m
         6           1.1738           0.0267           44.80m
         7           1.1468           0.0259           44.36m
         8           1.1228           0.0234           44.01m
         9           1.1017           0.0224           44.06m
        10           1.0809           0.0205           43.95m
        20           0.9332           0.0107           42.10m
        30           0.8497           0.0063           40.98m
        40           0.7964           0.0044           39.97m
        50           0.7626           0.0031           39.37m
        60           0.7366           0.0020           39.09m
        70           0.7134           0.0016           38.63m
        80           0.6994           0.0015           38.05m
        90           0.6832           0.0010           37.56m
       100           0.6734           0.0009           37.18m
       200           0.6065           0.0005           33.92m
       300           0.5708           0.0001           31.58m
       400           0.5389           0.0000           29.17m
       500           0.5188           0.0000           26.66m
       600           0.5035          -0.0000           24.15m
       700           0.4884           0.0000           21.69m
       800           0.4796          -0.0001           19.24m
       900           0.4636          -0.0001           16.83m
      1000           0.4546          -0.0001           17.51m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3419           0.0451           81.79m
         2           1.3013           0.0393           67.94m
         3           1.2656           0.0364           63.77m
         4           1.2316           0.0336           61.58m
         5           1.2015           0.0304           60.09m
         6           1.1730           0.0292           59.25m
         7           1.1467           0.0261           58.72m
         8           1.1234           0.0232           58.48m
         9           1.1008           0.0220           58.10m
        10           1.0817           0.0202           57.76m
        20           0.9280           0.0112           56.93m
        30           0.8442           0.0066           56.23m
        40           0.7892           0.0042           55.09m
        50           0.7530           0.0028           53.81m
        60           0.7237           0.0020           53.10m
        70           0.7076           0.0018           51.99m
        80           0.6898           0.0012           51.39m
        90           0.6787           0.0012           50.69m
       100           0.6693           0.0010           49.76m
       200           0.6010           0.0002           44.91m
       300           0.5646           0.0001           40.74m
       400           0.5385           0.0001           37.04m
       500           0.5187           0.0000           33.68m
       600           0.5000           0.0000           30.40m
       700           0.4875           0.0000           27.14m
       800           0.4793          -0.0000           24.05m
       900           0.4654           0.0001           20.98m
      1000           0.4573          -0.0000           17.91m
### Start Time 2020/11/05-12-25-04  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/oct2020/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/oct2020/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/oct2020/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=370   randForSplit=431   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.92      0.93     29889
Train discard       0.91      0.93      0.92     26810

     accuracy                           0.92     56699
    macro avg       0.92      0.92      0.92     56699
 weighted avg       0.92      0.92      0.92     56699

Train (keep) F2: 0.9207    P: 0.9379    R: 0.9166    NPV: 0.9093

['keep', 'discard']
[[27395  2494]
 [ 1814 24996]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.89      0.91      0.90      6510
Valid discard       0.93      0.91      0.92      8303

     accuracy                           0.91     14813
    macro avg       0.91      0.91      0.91     14813
 weighted avg       0.91      0.91      0.91     14813

Valid (keep) F2: 0.9041    P: 0.8914    R: 0.9074    NPV: 0.9263

['keep', 'discard']
[[5907  603]
 [ 720 7583]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.90      0.90      0.90      4899
Test  discard       0.92      0.92      0.92      6096

     accuracy                           0.91     10995
    macro avg       0.91      0.91      0.91     10995
 weighted avg       0.91      0.91      0.91     10995

Test  (keep) F2: 0.8979    P: 0.9017    R: 0.8969    NPV: 0.9175

['keep', 'discard']
[[4394  505]
 [ 479 5617]]

### Note: blessed GB.

### Best Pipeline Parameters:

vectorizer:
CountVectorizer(binary=True, lowercase=False, max_df=0.75, min_df=0.02,
                ngram_range=(1, 2), stop_words='english')

classifier:
GradientBoostingClassifier(learning_rate=0.05, max_features=0.7,
                           min_samples_leaf=150, min_samples_split=600,
                           n_estimators=1600, random_state=370, subsample=0.85,
                           verbose=1)


### Feature weights: highest 20
+0.2895	mice figur
+0.1640	wild_typ mice
+0.0847	cre
+0.0435	wild_typ
+0.0382	litterm
+0.0286	genotyp
+0.0283	mut_mut
+0.0258	transgen mice
+0.0174	knock_out mice
+0.0143	transgen
+0.0132	mut_mut mice
+0.0109	knock_out
+0.0106	relat figur
+0.0089	mice compar
+0.0062	embryonic_day
+0.0062	mice strain
+0.0053	mice express
+0.0047	defici
+0.0042	support inform
+0.0037	xenograft

### Feature weights: lowest 20
+0.0000	wild_typ litterm
+0.0000	wild_typ versus
+0.0000	window
+0.0000	withdraw
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	wors
+0.0000	worsen
+0.0000	wound heal
+0.0000	wrote
+0.0000	wrote manuscript
+0.0000	xenograft model
+0.0000	yellow arrow
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zhang et
+0.0000	zinc

### Vectorizer:   Number of Features: 6707
First 10 features: ['aa', 'aaa', 'aav', 'ab', 'abbrevi', 'abcam', 'abdomin', 'aberr', 'abil', 'abl']

Middle 10 features: ['introduct', 'intron', 'invad', 'invas', 'invers', 'invers correl', 'invert', 'investig', 'investig effect', 'investig express']

Last 10 features: ['young', 'younger', 'zebrafish', 'zeiss', 'zero', 'zhang', 'zhang et', 'zinc', 'zone', 'zoom']

### False positives for Validation set: 720
30615976
25754161
29033132
30858604
29360825

### False negatives for Validation set: 603
29061338
28362853
28733331
30510163
29223394

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        56699        29889        26810          53%
Validation Set      :        14813         6510         8303          44%
Test Set            :        10995         4899         6096          45%
ValidationSplit: 0.20
### End Time 2020/11/05-14-11-33. Total   6389.73 seconds

Recall for papers selected by each curation group. 14813 papers analyzed
ap             selected papers:  6028 predicted keep:  5558 recall: 0.922
gxd            selected papers:   485 predicted keep:   457 recall: 0.942
go             selected papers:  5201 predicted keep:  4829 recall: 0.928
tumor          selected papers:   454 predicted keep:   413 recall: 0.910
qtl            selected papers:    22 predicted keep:    19 recall: 0.864
Totals         keep     papers:  6510 predicted keep:  5907 recall: 0.907
Predictions from GB_val_pred.txt - Thu Nov  5 14:49:17 2020
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3400           0.0406           58.26m
         2           1.3014           0.0377           49.19m
         3           1.2653           0.0362           45.80m
         4           1.2347           0.0320           44.49m
         5           1.2045           0.0306           43.30m
         6           1.1763           0.0271           42.70m
         7           1.1518           0.0256           42.13m
         8           1.1279           0.0230           41.70m
         9           1.1046           0.0228           41.28m
        10           1.0839           0.0205           41.18m
        20           0.9398           0.0116           40.00m
        30           0.8565           0.0064           39.71m
        40           0.8014           0.0045           39.12m
        50           0.7671           0.0031           38.46m
        60           0.7424           0.0020           37.98m
        70           0.7202           0.0013           37.48m
        80           0.7051           0.0012           37.04m
        90           0.6895           0.0012           36.58m
       100           0.6812           0.0008           36.20m
       200           0.6110           0.0003           32.75m
       300           0.5759           0.0000           30.11m
       400           0.5440           0.0001           27.56m
       500           0.5241           0.0000           25.16m
       600           0.5127           0.0001           24.16m
       700           0.4946           0.0001           23.19m
       800           0.4778          -0.0000           21.61m
       900           0.4720          -0.0001           19.84m
      1000           0.4566          -0.0000           17.81m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3409           0.0436           70.24m
         2           1.3012           0.0393           59.67m
         3           1.2665           0.0358           55.65m
         4           1.2329           0.0329           53.42m
         5           1.2027           0.0296           52.50m
         6           1.1741           0.0278           51.87m
         7           1.1492           0.0260           51.55m
         8           1.1254           0.0241           51.16m
         9           1.1023           0.0224           50.91m
        10           1.0825           0.0206           50.52m
        20           0.9315           0.0104           58.02m
        30           0.8496           0.0062           61.26m
        40           0.7958           0.0041           57.44m
        50           0.7588           0.0029           74.40m
        60           0.7313           0.0024           70.17m
        70           0.7133           0.0018           66.11m
        80           0.6956           0.0013           65.87m
        90           0.6804           0.0014           64.26m
       100           0.6721           0.0010           61.70m
       200           0.6045           0.0003           63.54m
       300           0.5688           0.0004           55.74m
       400           0.5417           0.0003          268.09m
       500           0.5246           0.0000          218.73m
       600           0.5066           0.0000          438.88m
       700           0.4942           0.0001          356.12m
       800           0.4814          -0.0001          279.85m
       900           0.4720           0.0000          219.87m
      1000           0.4641           0.0000          171.31m
### Start Time 2020/11/06-18-26-10  GB.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Train/primTriage/data/nov2020/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Train/primTriage/data/nov2020/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Train/primTriage/data/nov2020/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=24   randForSplit=356   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.92      0.93     29894
Train discard       0.91      0.93      0.92     25954

     accuracy                           0.92     55848
    macro avg       0.92      0.92      0.92     55848
 weighted avg       0.92      0.92      0.92     55848

Train (keep) F2: 0.9211    P: 0.9379    R: 0.9169    NPV: 0.9067

['keep', 'discard']
[[27411  2483]
 [ 1814 24140]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.90      0.90      0.90      6706
Valid discard       0.92      0.91      0.91      7967

     accuracy                           0.91     14673
    macro avg       0.91      0.91      0.91     14673
 weighted avg       0.91      0.91      0.91     14673

Valid (keep) F2: 0.8998    P: 0.8967    R: 0.9005    NPV: 0.9160

['keep', 'discard']
[[6039  667]
 [ 696 7271]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.89      0.90      0.90      4814
Test  discard       0.92      0.91      0.92      5980

     accuracy                           0.91     10794
    macro avg       0.91      0.91      0.91     10794
 weighted avg       0.91      0.91      0.91     10794

Test  (keep) F2: 0.9010    P: 0.8946    R: 0.9026    NPV: 0.9210

['keep', 'discard']
[[4345  469]
 [ 512 5468]]

### Note: blessed GB.

### Best Pipeline Parameters:

vectorizer:
CountVectorizer(binary=True, lowercase=False, max_df=0.75, min_df=0.02,
                ngram_range=(1, 2), stop_words='english')

classifier:
GradientBoostingClassifier(learning_rate=0.05, max_features=0.7,
                           min_samples_leaf=150, min_samples_split=600,
                           n_estimators=1600, random_state=24, subsample=0.85,
                           verbose=1)


### Feature weights: highest 20
+0.2391	mice figur
+0.1738	wild_typ mice
+0.0861	cre
+0.0697	wild_typ
+0.0425	litterm
+0.0314	mut_mut
+0.0282	transgen mice
+0.0279	genotyp
+0.0169	knock_out mice
+0.0146	transgen
+0.0121	knock_out
+0.0115	relat figur
+0.0104	mut_mut mice
+0.0090	mice compar
+0.0069	mice strain
+0.0058	embryonic_day
+0.0049	support inform
+0.0046	mice express
+0.0046	mice model
+0.0043	xenograft

### Feature weights: lowest 20
+0.0000	window
+0.0000	withdraw
+0.0000	wnt signal
+0.0000	work
+0.0000	wors
+0.0000	worsen
+0.0000	wound heal
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	xlsx
+0.0000	yeast
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zinc
+0.0000	zone
+0.0000	zoom

### Vectorizer:   Number of Features: 6740
First 10 features: ['aa', 'aaa', 'aav', 'ab', 'abbrevi', 'abcam', 'abdomin', 'aberr', 'abil', 'abl']

Middle 10 features: ['invert', 'investig', 'investig effect', 'investig express', 'investig mechan', 'investig possibl', 'investig potenti', 'investig role', 'invitrogen', 'involv']

Last 10 features: ['young', 'younger', 'zebrafish', 'zeiss', 'zero', 'zhang', 'zhang et', 'zinc', 'zone', 'zoom']

### False positives for Validation set: 696
30067809
30118751
30530483
29863499
27458976

### False negatives for Validation set: 667
26909801
26808375
24316165
31371490
31714935

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        55848        29894        25954          54%
Validation Set      :        14673         6706         7967          46%
Test Set            :        10794         4814         5980          45%
ValidationSplit: 0.20
### End Time 2020/11/07-00-38-26. Total  22335.73 seconds

Recall for papers selected by each curation group. 14673 papers analyzed
ap             selected papers:  6222 predicted keep:  5706 recall: 0.917
gxd            selected papers:   499 predicted keep:   467 recall: 0.936
go             selected papers:  5385 predicted keep:  4975 recall: 0.924
tumor          selected papers:   458 predicted keep:   413 recall: 0.902
qtl            selected papers:    26 predicted keep:    22 recall: 0.846
Totals         keep     papers:  6706 predicted keep:  6039 recall: 0.901
Predictions from GB_val_pred.txt - Sat Nov  7 01:40:32 2020
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3400           0.0408           97.79m
         2           1.3008           0.0397           83.12m
         3           1.2648           0.0358           78.16m
         4           1.2322           0.0324           75.68m
         5           1.2031           0.0293           73.99m
         6           1.1760           0.0273           72.81m
         7           1.1514           0.0251           72.20m
         8           1.1284           0.0229           71.66m
         9           1.1067           0.0211           71.16m
        10           1.0885           0.0196           70.79m
        20           0.9414           0.0110           68.60m
        30           0.8585           0.0069           68.00m
        40           0.8041           0.0051           66.98m
        50           0.7672           0.0027           66.31m
        60           0.7424           0.0021           65.97m
        70           0.7212           0.0018           65.24m
        80           0.7048           0.0013           64.27m
        90           0.6901           0.0011           63.54m
       100           0.6801           0.0008           62.91m
       200           0.6095           0.0004           57.16m
       300           0.5701           0.0002           52.50m
       400           0.5419           0.0001           48.16m
       500           0.5250          -0.0000           44.28m
       600           0.5078           0.0000           40.07m
       700           0.4938          -0.0000           35.95m
       800           0.4785           0.0000           31.85m
       900           0.4665          -0.0001           27.81m
      1000           0.4583          -0.0001           23.79m
      Iter       Train Loss      OOB Improve   Remaining Time 
         1           1.3409           0.0435          124.80m
         2           1.3013           0.0395          105.51m
         3           1.2663           0.0346          100.53m
         4           1.2330           0.0335           98.41m
         5           1.2029           0.0302           96.11m
         6           1.1747           0.0277           94.65m
         7           1.1493           0.0255           93.65m
         8           1.1243           0.0240           92.64m
         9           1.1018           0.0219           92.09m
        10           1.0820           0.0210           91.88m
        20           0.9316           0.0108           88.73m
        30           0.8489           0.0066           87.72m
        40           0.7972           0.0046           86.67m
        50           0.7565           0.0030           85.87m
        60           0.7296           0.0021           84.82m
        70           0.7129           0.0018           83.78m
        80           0.6967           0.0015           83.03m
        90           0.6807           0.0011           82.08m
       100           0.6710           0.0012           81.04m
       200           0.6026           0.0003           74.86m
       300           0.5710           0.0001           68.81m
       400           0.5446           0.0000           63.02m
       500           0.5257           0.0001           57.55m
       600           0.5095          -0.0000           51.96m
       700           0.4952          -0.0000           46.66m
       800           0.4816           0.0000           41.41m
       900           0.4725          -0.0001           36.12m
      1000           0.4621          -0.0000           30.92m
### Start Time 2021/01/01-12-38-19  GB.py	index file: index.out
Training data path:   /home/jak/work/autolittriage/Train/primTriage/data/nov2020/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /home/jak/work/autolittriage/Train/primTriage/data/nov2020/LegendsWords/Proc1/valSet.txt
Test data path:       /home/jak/work/autolittriage/Train/primTriage/data/nov2020/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=188   randForSplit=333   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.94      0.92      0.93     29894
Train discard       0.91      0.93      0.92     25954

     accuracy                           0.92     55848
    macro avg       0.92      0.92      0.92     55848
 weighted avg       0.92      0.92      0.92     55848

Train (keep) F2: 0.9218    P: 0.9380    R: 0.9178    NPV: 0.9076

['keep', 'discard']
[[27437  2457]
 [ 1812 24142]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.90      0.90      0.90      6706
Valid discard       0.92      0.91      0.92      7967

     accuracy                           0.91     14673
    macro avg       0.91      0.91      0.91     14673
 weighted avg       0.91      0.91      0.91     14673

Valid (keep) F2: 0.9000    P: 0.8982    R: 0.9004    NPV: 0.9160

['keep', 'discard']
[[6038  668]
 [ 684 7283]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.89      0.90      0.90      4814
Test  discard       0.92      0.91      0.92      5980

     accuracy                           0.91     10794
    macro avg       0.91      0.91      0.91     10794
 weighted avg       0.91      0.91      0.91     10794

Test  (keep) F2: 0.8990    P: 0.8940    R: 0.9003    NPV: 0.9193

['keep', 'discard']
[[4334  480]
 [ 514 5466]]

### Note: blessed GB.

### Best Pipeline Parameters:

vectorizer:
CountVectorizer(binary=True, lowercase=False, max_df=0.75, min_df=0.02,
                ngram_range=(1, 2), stop_words='english')

classifier:
GradientBoostingClassifier(learning_rate=0.05, max_features=0.7,
                           min_samples_leaf=150, min_samples_split=600,
                           n_estimators=1600, random_state=188, subsample=0.85,
                           verbose=1)


### Feature weights: highest 20
+0.3188	mice figur
+0.1101	wild_typ mice
+0.0808	cre
+0.0596	wild_typ
+0.0338	litterm
+0.0314	mut_mut
+0.0300	genotyp
+0.0275	transgen mice
+0.0205	knock_out
+0.0164	knock_out mice
+0.0148	transgen
+0.0115	relat figur
+0.0095	mut_mut mice
+0.0077	mice compar
+0.0071	mice strain
+0.0067	embryonic_day
+0.0047	support inform
+0.0045	mice model
+0.0042	xenograft
+0.0041	mice express

### Feature weights: lowest 20
+0.0000	window
+0.0000	withdraw
+0.0000	wnt
+0.0000	wnt signal
+0.0000	wonder
+0.0000	work
+0.0000	wors
+0.0000	worsen
+0.0000	wound heal
+0.0000	xenograft model
+0.0000	xenograft tumor_typ
+0.0000	yeast
+0.0000	yellow arrow
+0.0000	yfp
+0.0000	younger
+0.0000	zeiss
+0.0000	zero
+0.0000	zhang
+0.0000	zinc
+0.0000	zoom

### Vectorizer:   Number of Features: 6740
First 10 features: ['aa', 'aaa', 'aav', 'ab', 'abbrevi', 'abcam', 'abdomin', 'aberr', 'abil', 'abl']

Middle 10 features: ['invert', 'investig', 'investig effect', 'investig express', 'investig mechan', 'investig possibl', 'investig potenti', 'investig role', 'invitrogen', 'involv']

Last 10 features: ['young', 'younger', 'zebrafish', 'zeiss', 'zero', 'zhang', 'zhang et', 'zinc', 'zone', 'zoom']

### False positives for Validation set: 684
30067809
30118751
30530483
29863499
27458976

### False negatives for Validation set: 668
26909801
26808375
24316165
31371490
31714935

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Training Set        :        55848        29894        25954          54%
Validation Set      :        14673         6706         7967          46%
Test Set            :        10794         4814         5980          45%
ValidationSplit: 0.20
### End Time 2021/01/01-15-23-30. Total   9911.25 seconds

Recall for papers selected by each curation group. 14673 papers analyzed
ap             selected papers:  6222 predicted keep:  5700 recall: 0.916
gxd            selected papers:   499 predicted keep:   468 recall: 0.938
go             selected papers:  5385 predicted keep:  4973 recall: 0.923
tumor          selected papers:   458 predicted keep:   413 recall: 0.902
qtl            selected papers:    26 predicted keep:    22 recall: 0.846
Totals         keep     papers:  6706 predicted keep:  6038 recall: 0.900
Predictions from GB_val_pred.txt - Fri Jan  1 15:23:44 2021
