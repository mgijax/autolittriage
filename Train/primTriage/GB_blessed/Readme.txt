
source file for the "blessed" GB model:
-r--r--r--  1 jak  JAX\Domain Users       1040 Dec 16 11:44 GBsrc.py

The model trained on whole training, validation, and test sets
(all samples from Sept 8, 2019):
-r--r--r--  1 jak  JAX\Domain Users  561922520 Dec 16 15:31 GBgood.pkl

features from training:
-r--r--r--  1 jak  JAX\Domain Users       1911 Dec 16 15:31 GBfeatures.txt
-rw-r--r--  1 jak  JAX\Domain Users        976 Dec 16 11:44 GBsrc.pyc

What was trained on (re-preprocessed and split on Dec 5):
-rw-r--r--  1 jak  JAX\Domain Users  935227660 Dec  5 14:48 trainSet.txt
-rw-r--r--  1 jak  JAX\Domain Users  224733913 Dec  5 14:48 valSet.txt
-rw-r--r--  1 jak  JAX\Domain Users  168121764 Dec  5 14:47 testSet.txt

Little training sets for debugging... (throw away)
-rw-r--r--  1 jak  JAX\Domain Users     206359 Dec 16 09:38 testSet_1.txt
-rw-r--r--  1 jak  JAX\Domain Users      34689 Dec 16 09:23 testSet_a.txt
-rw-r--r--  1 jak  JAX\Domain Users      34689 Dec 16 09:23 testSet_b.txt
