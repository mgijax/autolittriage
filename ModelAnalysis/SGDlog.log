Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2018/12/05-16-49-56  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=104   randForSplit=813   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.71      0.92      0.80     22463
Train discard       0.87      0.59      0.70     20260

  avg / total       0.79      0.76      0.76     42723

Train F4: 0.906 (keep)

['yes', 'no']
[[20699  1764]
 [ 8363 11897]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.59      0.93      0.72      3060
Valid discard       0.93      0.60      0.73      4885

  avg / total       0.80      0.73      0.73      7945

Valid F4: 0.900 (keep)

['yes', 'no']
[[2846  214]
 [1965 2920]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.57      0.93      0.71      2268
Test  discard       0.93      0.58      0.71      3700

  avg / total       0.79      0.71      0.71      5968

Test  F4: 0.895 (keep)

['yes', 'no']
[[2104  164]
 [1568 2132]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.01
vectorizer__ngram_range: (1, 1)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=104, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.01,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.01, 0.05]
vectorizer__ngram_range:[(1, 1)]

### Top positive features (20)
+0.0794	mice
+0.0717	wildtyp
+0.0486	knockout
+0.0419	mut_mut
+0.0396	defici
+0.0373	genotyp
+0.0315	section
+0.0311	cre
+0.0277	delet
+0.0262	litterm
+0.0258	old
+0.0245	stain
+0.0222	transgen
+0.0206	quantif
+0.0200	week
+0.0180	scale
+0.0179	loss
+0.0177	age
+0.0170	embryonic_day
+0.0166	arrowhead

### Top negative features (20)
-0.0129	includ
-0.0129	mechan
-0.0131	therapi
-0.0133	growth
-0.0133	drug
-0.0137	treatment
-0.0139	provid
-0.0141	method
-0.0153	concentr
-0.0158	differ
-0.0166	review
-0.0166	tumor
-0.0173	clinic
-0.0177	patient
-0.0177	potenti
-0.0195	base
-0.0210	human
-0.0211	cancer
-0.0232	effect
-0.0281	studi

### Vectorizer:   Number of Features: 2934
First 10 features: [u'a549', u'aa', u'aaa', u'aacr', u'aav', u'ab', u'abbrevi', u'abdomin', u'aberr', u'abil']

Middle 10 features: [u'larg', u'larger', u'largest', u'larva', u'laser', u'late', u'latenc', u'later', u'lavag', u'layer']

Last 10 features: [u'yeast', u'yellow', u'yfp', u'yield', u'young', u'zebrafish', u'zero', u'zinc', u'zone', u'zoom']

### False positives for Test set: 1568
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 164
28228254
27062441
26676765
26094765
28543188

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/05-16-53-36

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2018/12/05-17-05-10  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=242   randForSplit=987   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.91      0.82     22463
Train discard       0.86      0.65      0.74     20260

  avg / total       0.80      0.79      0.78     42723

Train F4: 0.895 (keep)

['yes', 'no']
[[20364  2099]
 [ 7021 13239]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.62      0.91      0.74      3060
Valid discard       0.92      0.66      0.77      4885

  avg / total       0.81      0.76      0.76      7945

Valid F4: 0.890 (keep)

['yes', 'no']
[[2799  261]
 [1681 3204]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.61      0.91      0.73      2268
Test  discard       0.92      0.64      0.76      3700

  avg / total       0.80      0.75      0.75      5968

Test  F4: 0.887 (keep)

['yes', 'no']
[[2071  197]
 [1319 2381]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=242, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.01, 0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0748	mice
+0.0668	wildtyp
+0.0517	wildtyp mice
+0.0457	knockout
+0.0394	mut_mut
+0.0371	defici
+0.0351	genotyp
+0.0342	knockout mice
+0.0304	mut_mut mice
+0.0298	cre
+0.0288	section
+0.0263	delet
+0.0247	litterm
+0.0242	wildtyp wildtyp
+0.0236	old
+0.0227	compar wildtyp
+0.0216	stain
+0.0214	scale bar
+0.0210	transgen
+0.0208	mice figur

### Top negative features (20)
-0.0131	therapi
-0.0131	drug
-0.0133	includ
-0.0133	growth
-0.0133	mechan
-0.0139	provid
-0.0142	method
-0.0146	treatment
-0.0153	concentr
-0.0162	review
-0.0164	tumor
-0.0170	differ
-0.0173	clinic
-0.0178	potenti
-0.0180	patient
-0.0195	base
-0.0206	cancer
-0.0215	human
-0.0237	effect
-0.0287	studi

### Vectorizer:   Number of Features: 2759
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lane', u'larg', u'larger', u'laser', u'late', u'latenc', u'later', u'layer', u'lc', u'lead']

Last 10 features: [u'work', u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 1319
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 197
28228254
27062441
26676765
26094765
12115612

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/05-17-17-21

Fitting 1 folds for each of 4 candidates, totalling 4 fits
### Start Time 2018/12/05-17-21-45  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=838   randForSplit=316   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.72      0.91      0.81     22463
Train discard       0.87      0.61      0.72     20260

  avg / total       0.79      0.77      0.77     42723

Train F4: 0.900 (keep)

['yes', 'no']
[[20537  1926]
 [ 7817 12443]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.60      0.92      0.73      3060
Valid discard       0.93      0.62      0.74      4885

  avg / total       0.80      0.74      0.74      7945

Valid F4: 0.895 (keep)

['yes', 'no']
[[2824  236]
 [1861 3024]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.59      0.92      0.72      2268
Test  discard       0.93      0.61      0.73      3700

  avg / total       0.80      0.73      0.73      5968

Test  F4: 0.891 (keep)

['yes', 'no']
[[2088  180]
 [1449 2251]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.05
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=838, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.05,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.1, 1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05, 0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0765	mice
+0.0684	wildtyp
+0.0531	wildtyp mice
+0.0468	knockout
+0.0403	mut_mut
+0.0380	defici
+0.0364	genotyp
+0.0351	knockout mice
+0.0311	mut_mut mice
+0.0309	cre
+0.0303	section
+0.0271	delet
+0.0256	litterm
+0.0248	wildtyp wildtyp
+0.0247	old
+0.0234	compar wildtyp
+0.0227	stain
+0.0225	scale bar
+0.0216	transgen
+0.0214	mice figur

### Top negative features (20)
-0.0134	includ
-0.0134	mechan
-0.0135	therapi
-0.0135	drug
-0.0137	growth
-0.0142	provid
-0.0144	method
-0.0148	treatment
-0.0158	concentr
-0.0166	review
-0.0168	differ
-0.0172	tumor
-0.0177	clinic
-0.0181	potenti
-0.0184	patient
-0.0200	base
-0.0215	cancer
-0.0220	human
-0.0240	effect
-0.0291	studi

### Vectorizer:   Number of Features: 1127
First 10 features: [u'ab', u'abil', u'abnorm', u'abov', u'absenc', u'abund', u'accompani', u'accord', u'accumul', u'acid']

Middle 10 features: [u'lane', u'larg', u'larger', u'late', u'later', u'layer', u'lead', u'led', u'left', u'left panel']

Last 10 features: [u'white', u'white arrow', u'whitney', u'whitney test', u'wide', u'wildtyp', u'wildtyp mice', u'wildtyp wildtyp', u'work', u'yellow']

### False positives for Test set: 1449
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 180
28228254
27062441
26676765
26094765
12115612

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/05-17-34-36

Fitting 1 folds for each of 4 candidates, totalling 4 fits
### Start Time 2018/12/05-17-48-21  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=853   randForSplit=871   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.53      1.00      0.69     22463
Train discard       0.84      0.02      0.04     20260

  avg / total       0.68      0.53      0.38     42723

Train F4: 0.948 (keep)

['yes', 'no']
[[22392    71]
 [19885   375]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.39      1.00      0.56      3060
Valid discard       0.93      0.02      0.05      4885

  avg / total       0.72      0.40      0.24      7945

Valid F4: 0.913 (keep)

['yes', 'no']
[[3051    9]
 [4770  115]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.38      1.00      0.55      2268
Test  discard       0.89      0.02      0.03      3700

  avg / total       0.70      0.39      0.23      5968

Test  F4: 0.911 (keep)

['yes', 'no']
[[2261    7]
 [3642   58]]

### Best Pipeline Parameters:
classifier__alpha: 10
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.08
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=10, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=853, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.08,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[10, 1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05, 0.08]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0102	mice
+0.0092	wildtyp
+0.0067	wildtyp mice
+0.0060	knockout
+0.0051	mut_mut
+0.0050	defici
+0.0048	genotyp
+0.0047	section
+0.0044	knockout mice
+0.0043	stain
+0.0040	scale bar
+0.0039	cre
+0.0039	mut_mut mice
+0.0036	delet
+0.0034	old
+0.0033	bar
+0.0033	scale
+0.0033	wildtyp wildtyp
+0.0032	quantif
+0.0031	compar wildtyp

### Top negative features (20)
-0.0012	new
-0.0012	rat
-0.0012	predict
-0.0013	recent
-0.0013	therapeut
-0.0013	method
-0.0014	cell line
-0.0014	provid
-0.0015	therapi
-0.0015	concentr
-0.0015	drug
-0.0017	potenti
-0.0018	tumor
-0.0018	patient
-0.0019	clinic
-0.0020	human
-0.0020	effect
-0.0020	base
-0.0024	cancer
-0.0026	studi

### Vectorizer:   Number of Features: 701
First 10 features: [u'abil', u'abnorm', u'abov', u'absenc', u'abund', u'accord', u'accumul', u'acid', u'act', u'actin']

Middle 10 features: [u'like', u'limit', u'line', u'line indic', u'link', u'lipid', u'live', u'liver', u'load', u'load control']

Last 10 features: [u'weight', u'western', u'western blot', u'wherea', u'white', u'wide', u'wildtyp', u'wildtyp mice', u'wildtyp wildtyp', u'yellow']

### False positives for Test set: 3642
28538172
28538185
28052251
28614716
28355573

### False negatives for Test set: 7
22464334
29017051
27679855
29266437
29050983

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/05-18-01-12

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2018/12/06-08-27-18  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=600   randForSplit=289   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.84      0.89      0.86     22463
Train discard       0.87      0.81      0.84     20260

  avg / total       0.85      0.85      0.85     42723

Train F4: 0.886 (keep)

['yes', 'no']
[[19975  2488]
 [ 3863 16397]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.75      0.88      0.81      3060
Valid discard       0.92      0.81      0.86      4885

  avg / total       0.85      0.84      0.84      7945

Valid F4: 0.874 (keep)

['yes', 'no']
[[2703  357]
 [ 919 3966]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.73      0.87      0.79      2268
Test  discard       0.91      0.80      0.85      3700

  avg / total       0.84      0.83      0.83      5968

Test  F4: 0.856 (keep)

['yes', 'no']
[[1963  305]
 [ 722 2978]]

### Best Pipeline Parameters:
classifier__alpha: 0.001
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.05
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=600, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.05,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.001, 0.01]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+1.7421	mice
+1.0156	cre
+0.8524	transgen mice
+0.8350	litterm
+0.8203	wildtyp mice
+0.7593	knockout mice
+0.7440	mut_mut
+0.6163	figur figur
+0.5481	defici mice
+0.5340	mut_mut mice
+0.5096	genotyp
+0.4514	mice model
+0.4336	mice express
+0.4180	knockout
+0.4112	mice figur
+0.4091	embryonic_day
+0.3936	mice compar
+0.3884	defici
+0.3698	mice wildtyp
+0.3364	c57bl

### Top negative features (20)
-0.1978	healthi
-0.2017	viabil
-0.2033	volum
-0.2064	replic
-0.2081	focus
-0.2128	stem
-0.2134	et
-0.2406	cell transfect
-0.2430	immun
-0.2573	patient
-0.2749	host
-0.2825	genom
-0.2950	growth
-0.2974	repres
-0.3069	infect
-0.3241	pathogen
-0.3490	c57bl mice
-0.3834	rat
-0.4095	cancer cell
-0.5819	review

### Vectorizer:   Number of Features: 1127
First 10 features: [u'ab', u'abil', u'abnorm', u'abov', u'absenc', u'abund', u'accompani', u'accord', u'accumul', u'acid']

Middle 10 features: [u'lane', u'larg', u'larger', u'late', u'later', u'layer', u'lead', u'led', u'left', u'left panel']

Last 10 features: [u'white', u'white arrow', u'whitney', u'whitney test', u'wide', u'wildtyp', u'wildtyp mice', u'wildtyp wildtyp', u'work', u'yellow']

### False positives for Test set: 722
28538172
28538185
28052251
28614716
28355573

### False negatives for Test set: 305
28958789
28614720
28228254
27062441
26676765

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/06-08-39-08

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2018/12/06-08-45-34  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=94   randForSplit=327   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.90      0.71      0.79     22463
Train discard       0.74      0.91      0.81     20260

  avg / total       0.82      0.80      0.80     42723

Train F4: 0.714 (keep)

['yes', 'no']
[[15849  6614]
 [ 1852 18408]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.83      0.69      0.75      3060
Valid discard       0.82      0.91      0.87      4885

  avg / total       0.83      0.83      0.82      7945

Valid F4: 0.696 (keep)

['yes', 'no']
[[2109  951]
 [ 430 4455]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.82      0.68      0.75      2268
Test  discard       0.82      0.91      0.87      3700

  avg / total       0.82      0.82      0.82      5968

Test  F4: 0.690 (keep)

['yes', 'no']
[[1550  718]
 [ 332 3368]]

### Best Pipeline Parameters:
classifier__alpha: 0.0001
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.05
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',
       epsilon=0.1, eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=94, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.05,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.001, 0.0001]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+4.0852	mice
+2.7133	cre
+2.6060	transgen mice
+2.4521	litterm
+1.7375	knockout mice
+1.4867	genotyp
+1.4817	wildtyp mice
+1.4633	defici mice
+1.4438	mut_mut
+1.3373	figur figur
+1.1655	mice use
+1.1463	embryon
+1.1434	month
+1.1393	gapdh
+1.1282	g003
+1.1015	c57bl
+1.0791	mice express
+1.0020	g002
+0.9307	knockout
+0.9297	mice wildtyp

### Top negative features (20)
-0.6489	method
-0.6509	transmiss
-0.6604	select
-0.6694	genom
-0.6730	downstream
-0.7018	cytometri
-0.7022	pathogenesi
-0.7256	confoc
-0.7293	cell line
-0.7345	focus
-0.7380	sds page
-0.7395	infect
-0.7411	probe
-0.7524	altern
-0.7904	hematoxylin eosin
-0.7930	analysi perform
-0.8122	doi
-1.1308	ex
-1.1740	cancer cell
-1.4040	c57bl mice

### Vectorizer:   Number of Features: 1127
First 10 features: [u'ab', u'abil', u'abnorm', u'abov', u'absenc', u'abund', u'accompani', u'accord', u'accumul', u'acid']

Middle 10 features: [u'lane', u'larg', u'larger', u'late', u'later', u'layer', u'lead', u'led', u'left', u'left panel']

Last 10 features: [u'white', u'white arrow', u'whitney', u'whitney test', u'wide', u'wildtyp', u'wildtyp mice', u'wildtyp wildtyp', u'work', u'yellow']

### False positives for Test set: 332
28538185
28052251
28355573
28423311
29091761

### False negatives for Test set: 718
28958789
27149846
28614720
28228254
29069605

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/06-08-57-09

Fitting 1 folds for each of 12 candidates, totalling 12 fits
### Start Time 2018/12/06-11-19-04  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 2
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=15   randForSplit=128   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.89      0.85      0.87     22463
Train discard       0.84      0.88      0.86     20260

  avg / total       0.86      0.86      0.86     42723

Train F2: 0.858 (keep)

['yes', 'no']
[[19113  3350]
 [ 2470 17790]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.81      0.86      0.83      3060
Valid discard       0.91      0.87      0.89      4885

  avg / total       0.87      0.87      0.87      7945

Valid F2: 0.846 (keep)

['yes', 'no']
[[2617  443]
 [ 615 4270]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.79      0.83      0.81      2268
Test  discard       0.89      0.87      0.88      3700

  avg / total       0.85      0.85      0.85      5968

Test  F2: 0.822 (keep)

['yes', 'no']
[[1880  388]
 [ 488 3212]]

### Best Pipeline Parameters:
classifier__alpha: 0.01
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.01, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=15, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.01, 0.001, 0.0001]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05, 0.02]
vectorizer__ngram_range:[(1, 1), (1, 2)]

### Top positive features (20)
+1.0670	mice
+0.5019	wildtyp mice
+0.4564	mut_mut
+0.4047	cre
+0.3802	wildtyp
+0.3748	knockout mice
+0.3738	knockout
+0.3513	mut_mut mice
+0.3424	transgen mice
+0.3256	figur figur
+0.3160	litterm
+0.3102	relat figur
+0.3088	defici
+0.3035	mice model
+0.3017	genotyp
+0.2325	defici mice
+0.2305	mice figur
+0.2297	transgen
+0.2108	mice compar
+0.2068	mutant mice

### Top negative features (20)
-0.1313	differ
-0.1317	effect
-0.1343	cancer cell
-0.1383	growth
-0.1389	invas
-0.1394	inocul
-0.1406	blood
-0.1415	infect
-0.1438	articl
-0.1446	nude
-0.1449	journal ppat
-0.1465	ppat
-0.1567	repres
-0.1590	issu
-0.1598	patient
-0.1795	human
-0.1800	studi
-0.2338	rat
-0.2420	review
-0.2541	xenograft

### Vectorizer:   Number of Features: 2759
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lane', u'larg', u'larger', u'laser', u'late', u'latenc', u'later', u'layer', u'lc', u'lead']

Last 10 features: [u'work', u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 488
28538185
28052251
28355573
28423311
29358166

### False negatives for Test set: 388
28228254
27062441
26676765
26094765
12115612

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/06-11-38-25

Fitting 1 folds for each of 12 candidates, totalling 12 fits
Fitting 1 folds for each of 16 candidates, totalling 16 fits
Fitting 1 folds for each of 8 candidates, totalling 8 fits
Fitting 1 folds for each of 8 candidates, totalling 8 fits
Fitting 1 folds for each of 6 candidates, totalling 6 fits
Fitting 1 folds for each of 6 candidates, totalling 6 fits
### Start Time 2018/12/06-13-27-20  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 2
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=601   randForSplit=346   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.90      0.84      0.87     22463
Train discard       0.84      0.90      0.87     20260

  avg / total       0.87      0.87      0.87     42723

Train F2: 0.853 (keep)

['yes', 'no']
[[18889  3574]
 [ 2036 18224]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.83      0.84      3060
Valid discard       0.90      0.90      0.90      4885

  avg / total       0.87      0.87      0.87      7945

Valid F2: 0.834 (keep)

['yes', 'no']
[[2547  513]
 [ 486 4399]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.81      0.81      0.81      2268
Test  discard       0.88      0.88      0.88      3700

  avg / total       0.86      0.86      0.86      5968

Test  F2: 0.810 (keep)

['yes', 'no']
[[1838  430]
 [ 429 3271]]

### Best Pipeline Parameters:
classifier__alpha: 0.01
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.01, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=601, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.1, 0.01, 0.001]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05, 0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.9691	mice
+0.4163	mut_mut
+0.4028	wildtyp mice
+0.3806	cre
+0.3382	knockout
+0.3356	figur figur
+0.3351	knockout mice
+0.3220	transgen mice
+0.3087	mut_mut mice
+0.2851	litterm
+0.2810	wildtyp
+0.2796	defici
+0.2761	mice and
+0.2694	mice model
+0.2600	genotyp
+0.2576	to figur
+0.2338	mice were
+0.2163	transgen
+0.2008	defici mice
+0.1880	from wildtyp

### Top negative features (20)
-0.1152	growth
-0.1169	patient
-0.1192	studi
-0.1198	this
-0.1203	fish
-0.1271	issu
-0.1291	nude
-0.1292	repres
-0.1327	blood
-0.1372	cancer cell
-0.1374	invas
-0.1379	infect
-0.1390	inocul
-0.1395	journal ppat
-0.1410	ppat
-0.1532	human
-0.1767	review
-0.1861	rat
-0.2454	xenograft
-0.3658	none

### Vectorizer:   Number of Features: 5191
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abil of', u'abil to', u'abl', u'abl to', u'ablat']

Middle 10 features: [u'log2', u'long', u'long term', u'longer', u'longitudin', u'loop', u'loss', u'loss in', u'loss of', u'lost']

Last 10 features: [u'xenograft', u'year', u'yellow', u'yellow and', u'yellow arrow', u'yet', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 429
28538185
28052251
28423311
26194975
27592607

### False negatives for Test set: 430
28445726
28614720
28228254
28768198
28954232

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/06-13-43-58. Total    998.42 seconds

Fitting 1 folds for each of 12 candidates, totalling 12 fits
### Start Time 2018/12/06-19-14-44  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=988   randForSplit=581   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.85      0.84      0.84     22463
Train discard       0.82      0.84      0.83     20260

  avg / total       0.84      0.84      0.84     42723

Train F2: 0.842 (keep)

['yes', 'no']
[[18852  3611]
 [ 3309 16951]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.76      0.84      0.80      3060
Valid discard       0.89      0.84      0.86      4885

  avg / total       0.84      0.84      0.84      7945

Valid F2: 0.824 (keep)

['yes', 'no']
[[2575  485]
 [ 804 4081]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.75      0.84      0.79      2268
Test  discard       0.90      0.83      0.86      3700

  avg / total       0.84      0.83      0.84      5968

Test  F2: 0.822 (keep)

['yes', 'no']
[[1908  360]
 [ 631 3069]]

### Best Pipeline Parameters:
classifier__alpha: 0.1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)
vectorizer__stop_words: 'english'

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=988, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.1, 0.01, 0.001]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.05, 0.02]
vectorizer__ngram_range:[(1, 2)]
vectorizer__stop_words:['english', None]

### Top positive features (20)
+0.3997	mice
+0.2653	wildtyp
+0.2292	wildtyp mice
+0.1955	knockout
+0.1855	mut_mut
+0.1563	defici
+0.1537	knockout mice
+0.1427	genotyp
+0.1426	mut_mut mice
+0.1402	cre
+0.1116	litterm
+0.1075	mice model
+0.1033	figur figur
+0.1019	delet
+0.0997	transgen
+0.0980	transgen mice
+0.0970	mice figur
+0.0951	wildtyp wildtyp
+0.0859	mice compar
+0.0859	compar wildtyp

### Top negative features (20)
-0.0516	mechan
-0.0517	associ
-0.0523	evalu
-0.0526	method
-0.0537	tumor
-0.0558	treatment
-0.0563	infect
-0.0576	xenograft
-0.0621	potenti
-0.0626	growth
-0.0635	clinic
-0.0644	base
-0.0668	cancer
-0.0721	differ
-0.0779	rat
-0.0787	patient
-0.0792	review
-0.0846	human
-0.0870	effect
-0.1099	studi

### Vectorizer:   Number of Features: 2759
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lane', u'larg', u'larger', u'laser', u'late', u'latenc', u'later', u'layer', u'lc', u'lead']

Last 10 features: [u'work', u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 631
28538185
28052251
28355573
28423311
29091758

### False negatives for Test set: 360
28228254
28768198
27062441
26676765
26094765

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/06-19-38-16. Total   1411.25 seconds

Fitting 1 folds for each of 3 candidates, totalling 3 fits
### Start Time 2018/12/06-19-45-22  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=178   randForSplit=230   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.86      0.81      0.83     22463
Train discard       0.80      0.85      0.83     20260

  avg / total       0.83      0.83      0.83     42723

Train F2: 0.817 (keep)

['yes', 'no']
[[18131  4332]
 [ 2969 17291]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.78      0.80      0.79      3060
Valid discard       0.87      0.86      0.86      4885

  avg / total       0.84      0.84      0.84      7945

Valid F2: 0.798 (keep)

['yes', 'no']
[[2458  602]
 [ 705 4180]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.77      0.79      0.78      2268
Test  discard       0.87      0.86      0.86      3700

  avg / total       0.83      0.83      0.83      5968

Test  F2: 0.784 (keep)

['yes', 'no']
[[1785  483]
 [ 533 3167]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=178, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=False, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1, 0.1, 0.01]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0873	mice
+0.0433	wildtyp
+0.0432	mut_mut
+0.0423	figur figur
+0.0387	knockout
+0.0371	cre
+0.0319	embryonic_day
+0.0287	defici
+0.0252	relat figur
+0.0242	knockout mice
+0.0240	genotyp
+0.0238	mef
+0.0202	delet
+0.0200	mut_mut mice
+0.0189	wildtyp mice
+0.0187	litterm
+0.0182	po0
+0.0177	fl
+0.0157	neuron
+0.0156	transgen

### Top negative features (20)
-0.0162	treatment
-0.0163	concentr
-0.0164	assay
-0.0173	base
-0.0182	inject
-0.0183	vaccin
-0.0189	diseas
-0.0190	blood
-0.0194	associ
-0.0199	mechan
-0.0203	differ
-0.0207	cancer
-0.0238	group
-0.0248	effect
-0.0263	infect
-0.0278	immun
-0.0285	human
-0.0289	rat
-0.0295	patient
-0.0373	studi

### Vectorizer:   Number of Features: 2759
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lane', u'larg', u'larger', u'laser', u'late', u'latenc', u'later', u'layer', u'lc', u'lead']

Last 10 features: [u'work', u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 533
28538185
28052251
28355573
28423311
29091761

### False negatives for Test set: 483
28228254
28768198
29045833
26934489
27062441

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/06-19-56-47. Total    685.31 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/07-09-21-48  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=402   randForSplit=320   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.75      0.90      0.82     22463
Train discard       0.86      0.66      0.75     20260

  avg / total       0.80      0.79      0.78     42723

Train F2: 0.868 (keep)

['yes', 'no']
[[20326  2137]
 [ 6943 13317]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.63      0.91      0.74      3060
Valid discard       0.92      0.66      0.77      4885

  avg / total       0.81      0.76      0.76      7945

Valid F2: 0.836 (keep)

['yes', 'no']
[[2791  269]
 [1661 3224]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.61      0.91      0.73      2268
Test  discard       0.92      0.65      0.76      3700

  avg / total       0.81      0.75      0.75      5968

Test  F2: 0.831 (keep)

['yes', 'no']
[[2066  202]
 [1298 2402]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=402, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0748	mice
+0.0668	wildtyp
+0.0517	wildtyp mice
+0.0456	knockout
+0.0394	mut_mut
+0.0371	defici
+0.0351	genotyp
+0.0342	knockout mice
+0.0304	mut_mut mice
+0.0298	cre
+0.0288	section
+0.0263	delet
+0.0247	litterm
+0.0242	wildtyp wildtyp
+0.0236	old
+0.0227	compar wildtyp
+0.0216	stain
+0.0213	scale bar
+0.0210	transgen
+0.0208	mice figur

### Top negative features (20)
-0.0131	therapi
-0.0131	drug
-0.0133	includ
-0.0133	mechan
-0.0133	growth
-0.0140	provid
-0.0142	method
-0.0146	treatment
-0.0154	concentr
-0.0163	review
-0.0164	tumor
-0.0170	differ
-0.0173	clinic
-0.0178	potenti
-0.0180	patient
-0.0195	base
-0.0206	cancer
-0.0215	human
-0.0238	effect
-0.0287	studi

### Vectorizer:   Number of Features: 2759
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lane', u'larg', u'larger', u'laser', u'late', u'latenc', u'later', u'layer', u'lc', u'lead']

Last 10 features: [u'work', u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 1298
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 202
28228254
27062441
26676765
26094765
12115612

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/07-09-32-52. Total    664.34 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/07-14-48-12  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec5/Proc1/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc1/valSetFig.txt
Test data path:       ../Data/dec5/Proc1/testSetFig2.txt
Random Seeds:	randForClassifier=155   randForSplit=534   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.75      0.90      0.82     22463
Train discard       0.86      0.66      0.75     20260

  avg / total       0.80      0.79      0.78     42723

Train F2: 0.868 (keep)

['yes', 'no']
[[20326  2137]
 [ 6911 13349]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.63      0.91      0.74      3060
Valid discard       0.92      0.66      0.77      4885

  avg / total       0.81      0.76      0.76      7945

Valid F2: 0.837 (keep)

['yes', 'no']
[[2792  268]
 [1655 3230]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.62      0.91      0.74      2268
Test  discard       0.93      0.65      0.76      3700

  avg / total       0.81      0.75      0.75      5968

Test  F2: 0.834 (keep)

['yes', 'no']
[[2075  193]
 [1289 2411]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=155, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0749	mice
+0.0668	wildtyp
+0.0517	wildtyp mice
+0.0457	knockout
+0.0394	mut_mut
+0.0371	defici
+0.0351	genotyp
+0.0342	knockout mice
+0.0304	mut_mut mice
+0.0298	cre
+0.0288	section
+0.0263	delet
+0.0247	litterm
+0.0242	wildtyp wildtyp
+0.0236	old
+0.0227	compar wildtyp
+0.0216	stain
+0.0214	scale bar
+0.0210	transgen
+0.0208	mice figur

### Top negative features (20)
-0.0130	therapi
-0.0131	drug
-0.0132	includ
-0.0132	mechan
-0.0133	growth
-0.0139	provid
-0.0141	method
-0.0146	treatment
-0.0153	concentr
-0.0162	review
-0.0164	tumor
-0.0168	differ
-0.0172	clinic
-0.0178	potenti
-0.0180	patient
-0.0194	base
-0.0205	cancer
-0.0214	human
-0.0237	effect
-0.0286	studi

### Vectorizer:   Number of Features: 2759
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lane', u'larg', u'larger', u'laser', u'late', u'latenc', u'later', u'layer', u'lc', u'lead']

Last 10 features: [u'work', u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zone']

### False positives for Test set: 1289
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 193
27062441
26676765
26094765
12115612
26949218

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/07-14-59-23. Total    671.21 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
Fitting 1 folds for each of 1 candidates, totalling 1 fits
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/08-16-25-39  SGDlog.py	index file: index.out
Training data path:   ../Data/dec5/Proc2/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc2/valSetFig.txt
Test data path:       ../Data/dec5/Proc2/testSetFig.txt
Random Seeds:	randForClassifier=475   randForSplit=332   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.91      0.82     22463
Train discard       0.87      0.64      0.74     20260

  avg / total       0.80      0.78      0.78     42723

Train F2: 0.872 (keep)

['yes', 'no']
[[20518  1945]
 [ 7245 13015]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.62      0.92      0.74      3060
Valid discard       0.93      0.65      0.76      4885

  avg / total       0.81      0.75      0.76      7945

Valid F2: 0.839 (keep)

['yes', 'no']
[[2812  248]
 [1712 3173]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.61      0.92      0.73      2268
Test  discard       0.93      0.64      0.75      3700

  avg / total       0.80      0.74      0.75      5968

Test  F2: 0.832 (keep)

['yes', 'no']
[[2080  188]
 [1346 2354]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=475, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0708	mice
+0.0649	wild_typ
+0.0514	wild_typ mice
+0.0412	mut_mut
+0.0366	defici
+0.0360	genotyp
+0.0317	mut_mut mice
+0.0306	knockout
+0.0305	cre
+0.0303	knock_out
+0.0292	section
+0.0265	delet
+0.0249	litterm
+0.0240	old
+0.0235	wild_typ wild_typ
+0.0230	knock_out mice
+0.0223	compar wild_typ
+0.0216	mice figur
+0.0215	transgen
+0.0208	stain

### Top negative features (20)
-0.0132	includ
-0.0134	therapeut
-0.0135	therapi
-0.0136	associ
-0.0137	growth
-0.0145	provid
-0.0146	mechan
-0.0146	concentr
-0.0149	treatment
-0.0162	review
-0.0168	differ
-0.0170	tumor
-0.0175	clinic
-0.0183	potenti
-0.0185	patient
-0.0189	base
-0.0212	cancer
-0.0222	human
-0.0234	effect
-0.0295	studi

### Vectorizer:   Number of Features: 2827
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'layer', u'lc', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres', u'left right']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1346
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 188
27062441
26676765
26094765
12115612
26949218

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/08-16-38-33. Total    773.65 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/08-18-54-04  SGDlog.py	index file: index.out
Training data path:   ../Data/dec5/Proc2/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc2/valSetFig.txt
Test data path:       ../Data/dec5/Proc2/testSetFig.txt
Random Seeds:	randForClassifier=152   randForSplit=693   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.92      0.82     22463
Train discard       0.87      0.63      0.73     20260

  avg / total       0.80      0.78      0.78     42723

Train F2: 0.874 (keep)

['yes', 'no']
[[20595  1868]
 [ 7404 12856]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.62      0.92      0.74      3060
Valid discard       0.93      0.64      0.76      4885

  avg / total       0.81      0.75      0.75      7945

Valid F2: 0.839 (keep)

['yes', 'no']
[[2823  237]
 [1757 3128]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.60      0.92      0.73      2268
Test  discard       0.93      0.63      0.75      3700

  avg / total       0.80      0.74      0.74      5968

Test  F2: 0.833 (keep)

['yes', 'no']
[[2087  181]
 [1372 2328]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=152, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0709	mice
+0.0657	wild_typ
+0.0524	wild_typ mice
+0.0456	knock_out
+0.0411	mut_mut
+0.0365	defici
+0.0360	genotyp
+0.0346	knock_out mice
+0.0316	mut_mut mice
+0.0305	cre
+0.0293	section
+0.0264	delet
+0.0248	litterm
+0.0247	wild_typ wild_typ
+0.0240	old
+0.0230	compar wild_typ
+0.0216	mice figur
+0.0215	transgen
+0.0209	stain
+0.0202	supplementari figur

### Top negative features (20)
-0.0131	drug
-0.0133	therapeut
-0.0134	therapi
-0.0135	associ
-0.0135	growth
-0.0144	provid
-0.0145	mechan
-0.0145	concentr
-0.0148	treatment
-0.0161	review
-0.0165	differ
-0.0169	tumor
-0.0174	clinic
-0.0182	potenti
-0.0184	patient
-0.0188	base
-0.0211	cancer
-0.0220	human
-0.0232	effect
-0.0292	studi

### Vectorizer:   Number of Features: 2825
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'layer', u'lc', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres', u'left right']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1372
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 181
27062441
26676765
26094765
12115612
26949218

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/08-19-07-01. Total    777.54 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/10-15-54-02  SGDlog.py	index file: index.out
Training data path:   ../Data/dec5/Proc2/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: ../Data/dec5/Proc2/valSetFig.txt
Test data path:       ../Data/dec5/Proc2/testSetFig.txt
Random Seeds:	randForClassifier=556   randForSplit=263   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.91      0.82     22463
Train discard       0.87      0.64      0.74     20260

  avg / total       0.80      0.79      0.78     42723

Train F2: 0.87259 (keep)

['yes', 'no']
[[20519  1944]
 [ 7204 13056]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.62      0.92      0.74      3060
Valid discard       0.93      0.65      0.77      4885

  avg / total       0.81      0.76      0.76      7945

Valid F2: 0.83990 (keep)

['yes', 'no']
[[2813  247]
 [1693 3192]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.61      0.92      0.73      2268
Test  discard       0.93      0.64      0.76      3700

  avg / total       0.81      0.75      0.75      5968

Test  F2: 0.83387 (keep)

['yes', 'no']
[[2082  186]
 [1330 2370]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=556, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0707	mice
+0.0655	wild_typ
+0.0524	wild_typ mice
+0.0455	knock_out
+0.0411	mut_mut
+0.0364	defici
+0.0359	genotyp
+0.0345	knock_out mice
+0.0315	mut_mut mice
+0.0305	cre
+0.0292	section
+0.0264	delet
+0.0248	litterm
+0.0246	wild_typ wild_typ
+0.0240	old
+0.0229	compar wild_typ
+0.0215	mice figur
+0.0215	transgen
+0.0208	stain
+0.0202	supplementari figur

### Top negative features (20)
-0.0131	includ
-0.0133	therapeut
-0.0134	therapi
-0.0135	associ
-0.0136	growth
-0.0144	provid
-0.0145	mechan
-0.0146	concentr
-0.0148	treatment
-0.0161	review
-0.0167	differ
-0.0174	clinic
-0.0182	potenti
-0.0184	patient
-0.0189	base
-0.0190	tumor_typ
-0.0210	cancer
-0.0221	human
-0.0233	effect
-0.0293	studi

### Vectorizer:   Number of Features: 2826
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lc', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres', u'left right', u'left untreat']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1330
28538185
28052251
28614716
28355573
28423311

### False negatives for Test set: 186
27062441
26676765
26094765
12115612
26949218

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7945         3060         4885          39%
Training Set        :        42723        22463        20260          53%
Test Set            :         5968         2268         3700          38%
TestSplit: 0.20
### End Time 2018/12/10-16-07-52. Total    830.03 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/19-12-46-56  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec19/Proc2/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/dec19/Proc2/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/dec19/Proc2/testSetFig.txt
Random Seeds:	randForClassifier=919   randForSplit=611   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.91      0.82     21544
Train discard       0.88      0.66      0.75     20218

  avg / total       0.81      0.79      0.79     41762

Train F2: 0.87374 (keep)

['yes', 'no']
[[19705  1839]
 [ 6882 13336]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.61      0.92      0.73      2772
Valid discard       0.94      0.67      0.78      4981

  avg / total       0.82      0.76      0.76      7753

Valid F2: 0.83677 (keep)

['yes', 'no']
[[2560  212]
 [1649 3332]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.62      0.92      0.74      2153
Test  discard       0.94      0.67      0.78      3682

  avg / total       0.82      0.76      0.77      5835

Test  F2: 0.84194 (keep)

['yes', 'no']
[[1989  164]
 [1211 2471]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=919, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0714	mice
+0.0674	wild_typ
+0.0544	wild_typ mice
+0.0476	knock_out
+0.0420	mut_mut
+0.0376	genotyp
+0.0374	defici
+0.0364	knock_out mice
+0.0329	mut_mut mice
+0.0318	cre
+0.0300	section
+0.0271	delet
+0.0259	litterm
+0.0254	wild_typ wild_typ
+0.0246	old
+0.0238	compar wild_typ
+0.0226	transgen
+0.0224	mice figur
+0.0206	stain
+0.0205	scale bar

### Top negative features (20)
-0.0128	high
-0.0130	therapi
-0.0132	method
-0.0134	growth
-0.0136	associ
-0.0143	provid
-0.0147	mechan
-0.0156	treatment
-0.0158	concentr
-0.0162	review
-0.0166	differ
-0.0171	clinic
-0.0176	patient
-0.0181	potenti
-0.0183	base
-0.0185	tumor_typ
-0.0207	cancer
-0.0222	human
-0.0233	effect
-0.0297	studi

### Vectorizer:   Number of Features: 2816
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'late', u'latenc', u'later', u'layer', u'lc', u'lead', u'lead increas', u'learn', u'led', u'left']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1211
28538185
28591580
28297671
28147285
28199847

### False negatives for Test set: 164
27312243
29427452
12115612
25982834
27321946

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7753         2772         4981          36%
Training Set        :        41762        21544        20218          52%
Test Set            :         5835         2153         3682          37%
TestSplit: 0.20
### End Time 2018/12/19-13-00-44. Total    827.72 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/19-17-07-12  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec19/Proc3/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/dec19/Proc3/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/dec19/Proc3/testSetFig.txt
Random Seeds:	randForClassifier=964   randForSplit=414   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.75      0.91      0.82     21544
Train discard       0.87      0.67      0.76     20218

  avg / total       0.81      0.79      0.79     41762

Train F2: 0.87173 (keep)

['yes', 'no']
[[19602  1942]
 [ 6653 13565]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.62      0.92      0.74      2772
Valid discard       0.94      0.68      0.79      4981

  avg / total       0.82      0.77      0.77      7753

Valid F2: 0.83623 (keep)

['yes', 'no']
[[2547  225]
 [1594 3387]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.63      0.92      0.75      2153
Test  discard       0.94      0.69      0.79      3682

  avg / total       0.82      0.77      0.78      5835

Test  F2: 0.84220 (keep)

['yes', 'no']
[[1979  174]
 [1158 2524]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=964, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0710	mice
+0.0672	wild_typ
+0.0543	wild_typ mice
+0.0475	knock_out
+0.0418	mut_mut
+0.0376	genotyp
+0.0373	defici
+0.0363	knock_out mice
+0.0328	mut_mut mice
+0.0317	cre
+0.0299	section
+0.0270	delet
+0.0259	litterm
+0.0254	wild_typ wild_typ
+0.0246	old
+0.0238	compar wild_typ
+0.0236	mice cell_lin
+0.0225	transgen
+0.0223	mice figur
+0.0204	stain

### Top negative features (20)
-0.0130	high
-0.0131	therapi
-0.0133	method
-0.0134	growth
-0.0137	associ
-0.0145	provid
-0.0148	mechan
-0.0158	treatment
-0.0159	concentr
-0.0162	review
-0.0168	differ
-0.0171	clinic
-0.0177	patient
-0.0182	potenti
-0.0185	base
-0.0186	tumor_typ
-0.0207	cancer
-0.0223	human
-0.0235	effect
-0.0300	studi

### Vectorizer:   Number of Features: 2822
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'later', u'layer', u'lc', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1158
28538185
28591580
28297671
28147285
28199847

### False negatives for Test set: 174
27312243
29427452
12115612
25982834
27321946

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7753         2772         4981          36%
Training Set        :        41762        21544        20218          52%
Test Set            :         5835         2153         3682          37%
TestSplit: 0.20
### End Time 2018/12/19-17-21-17. Total    845.34 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2018/12/20-13-46-18  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/dec19/Proc4/trainingSetFig.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/dec19/Proc4/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/dec19/Proc4/testSetFig.txt
Random Seeds:	randForClassifier=275   randForSplit=24   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.91      0.82     21544
Train discard       0.88      0.67      0.76     20218

  avg / total       0.81      0.79      0.79     41762

Train F2: 0.87295 (keep)

['yes', 'no']
[[19652  1892]
 [ 6733 13485]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.61      0.92      0.74      2772
Valid discard       0.94      0.68      0.79      4981

  avg / total       0.82      0.76      0.77      7753

Valid F2: 0.83623 (keep)

['yes', 'no']
[[2551  221]
 [1614 3367]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.63      0.92      0.75      2153
Test  discard       0.94      0.68      0.79      3682

  avg / total       0.82      0.77      0.77      5835

Test  F2: 0.84197 (keep)

['yes', 'no']
[[1982  171]
 [1176 2506]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=275, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0712	mice
+0.0673	wild_typ
+0.0543	wild_typ mice
+0.0475	knock_out
+0.0418	mut_mut
+0.0376	genotyp
+0.0374	defici
+0.0364	knock_out mice
+0.0328	mut_mut mice
+0.0317	cre
+0.0300	section
+0.0270	delet
+0.0259	litterm
+0.0254	wild_typ wild_typ
+0.0247	old
+0.0238	compar wild_typ
+0.0237	mice cell_lin
+0.0226	transgen
+0.0223	mice figur
+0.0206	stain

### Top negative features (20)
-0.0129	high
-0.0131	therapi
-0.0133	method
-0.0133	growth
-0.0136	associ
-0.0144	provid
-0.0148	mechan
-0.0157	treatment
-0.0159	concentr
-0.0162	review
-0.0167	differ
-0.0171	clinic
-0.0177	patient
-0.0182	potenti
-0.0184	base
-0.0185	tumor_typ
-0.0207	cancer
-0.0222	human
-0.0234	effect
-0.0299	studi

### Vectorizer:   Number of Features: 2829
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'later', u'layer', u'lc', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1176
28538185
28591580
28297671
28147285
28199847

### False negatives for Test set: 171
27312243
29427452
12115612
25982834
27321946

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7753         2772         4981          36%
Training Set        :        41762        21544        20218          52%
Test Set            :         5835         2153         3682          37%
TestSplit: 0.20
### End Time 2018/12/20-14-00-29. Total    850.81 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/02-16-08-32  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=57   randForSplit=382   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.76      0.91      0.83     21507
Train discard       0.87      0.67      0.76     19296

  avg / total       0.81      0.80      0.80     40803

Train F2: 0.87698 (keep)

['yes', 'no']
[[19647  1860]
 [ 6340 12956]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.64      0.92      0.75      2868
Valid discard       0.93      0.67      0.78      4628

  avg / total       0.82      0.77      0.77      7496

Valid F2: 0.84571 (keep)

['yes', 'no']
[[2642  226]
 [1506 3122]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.65      0.93      0.76      2127
Test  discard       0.94      0.69      0.80      3515

  avg / total       0.83      0.78      0.78      5642

Test  F2: 0.85193 (keep)

['yes', 'no']
[[1970  157]
 [1084 2431]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=57, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0710	mice
+0.0673	wild_typ
+0.0551	wild_typ mice
+0.0485	knock_out
+0.0424	mut_mut
+0.0387	genotyp
+0.0382	defici
+0.0369	knock_out mice
+0.0329	mut_mut mice
+0.0325	cre
+0.0299	section
+0.0278	delet
+0.0263	litterm
+0.0258	wild_typ wild_typ
+0.0248	old
+0.0240	mice cell_lin
+0.0239	compar wild_typ
+0.0227	transgen
+0.0223	mice figur
+0.0211	supplementari figur

### Top negative features (20)
-0.0128	growth
-0.0129	cell line
-0.0130	investig
-0.0131	result
-0.0132	rat
-0.0132	associ
-0.0141	valu
-0.0144	method
-0.0164	clinic
-0.0165	concentr
-0.0167	treatment
-0.0169	potenti
-0.0176	differ
-0.0179	patient
-0.0190	base
-0.0191	tumor_typ
-0.0208	cancer
-0.0220	human
-0.0246	effect
-0.0304	studi

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1084
28147276
28052251
28297671
28658617
28423311

### False negatives for Test set: 157
28514652
28355571
24418349
26733414
18179890

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/02-16-23-41. Total    909.37 seconds

Fitting 1 folds for each of 4 candidates, totalling 4 fits
### Start Time 2019/01/04-16-32-15  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=498   randForSplit=938   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.57      0.99      0.72     21507
Train discard       0.92      0.16      0.27     19296

  avg / total       0.74      0.60      0.51     40803

Train F2: 0.86045 (keep)

['yes', 'no']
[[21247   260]
 [16189  3107]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.42      0.99      0.59      2868
Valid discard       0.97      0.17      0.28      4628

  avg / total       0.76      0.48      0.40      7496

Valid F2: 0.78290 (keep)

['yes', 'no']
[[2846   22]
 [3858  770]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.42      0.99      0.59      2127
Test  discard       0.97      0.17      0.30      3515

  avg / total       0.76      0.48      0.41      5642

Test  F2: 0.77982 (keep)

['yes', 'no']
[[2108   19]
 [2900  615]]

### Best Pipeline Parameters:
classifier__alpha: 5
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=498, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1, 5]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.7, 0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0178	mice
+0.0172	wild_typ
+0.0136	wild_typ mice
+0.0121	knock_out
+0.0104	mut_mut
+0.0099	genotyp
+0.0097	defici
+0.0091	knock_out mice
+0.0087	section
+0.0081	cre
+0.0081	mut_mut mice
+0.0072	delet
+0.0066	old
+0.0066	litterm
+0.0065	wild_typ wild_typ
+0.0065	stain
+0.0065	scale bar
+0.0062	mice cell_lin
+0.0061	compar wild_typ
+0.0056	transgen

### Top negative features (20)
-0.0027	provid
-0.0027	therapeut
-0.0028	correl
-0.0029	differ
-0.0030	cancer cell
-0.0030	therapi
-0.0030	drug
-0.0031	cell line
-0.0031	method
-0.0032	treatment
-0.0037	potenti
-0.0037	concentr
-0.0038	clinic
-0.0039	patient
-0.0042	base
-0.0045	tumor_typ
-0.0047	human
-0.0050	cancer
-0.0050	effect
-0.0064	studi

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 2900
28538172
28147276
28052251
28297671
28658617

### False negatives for Test set: 19
29054992
27760307
18632560
18445651
29438690

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/04-16-45-53. Total    817.11 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/01/04-16-54-41  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=1   randForSplit=578   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.57      0.99      0.72     21507
Train discard       0.92      0.17      0.28     19296

  avg / total       0.74      0.60      0.51     40803

Train F2: 0.86096 (keep)

['yes', 'no']
[[21240   267]
 [16082  3214]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.43      0.99      0.60      2868
Valid discard       0.97      0.17      0.29      4628

  avg / total       0.76      0.49      0.41      7496

Valid F2: 0.78370 (keep)

['yes', 'no']
[[2845   23]
 [3834  794]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.42      0.99      0.59      2127
Test  discard       0.97      0.18      0.30      3515

  avg / total       0.76      0.49      0.41      5642

Test  F2: 0.78074 (keep)

['yes', 'no']
[[2108   19]
 [2884  631]]

### Best Pipeline Parameters:
classifier__alpha: 5
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=1, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1, 5]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0178	mice
+0.0172	wild_typ
+0.0136	wild_typ mice
+0.0121	knock_out
+0.0104	mut_mut
+0.0099	genotyp
+0.0097	defici
+0.0091	knock_out mice
+0.0087	section
+0.0081	cre
+0.0081	mut_mut mice
+0.0072	delet
+0.0066	old
+0.0066	litterm
+0.0065	wild_typ wild_typ
+0.0065	stain
+0.0065	scale bar
+0.0062	mice cell_lin
+0.0061	compar wild_typ
+0.0056	transgen

### Top negative features (20)
-0.0027	provid
-0.0027	therapeut
-0.0028	correl
-0.0029	differ
-0.0030	cancer cell
-0.0030	therapi
-0.0030	drug
-0.0031	cell line
-0.0031	method
-0.0032	treatment
-0.0037	potenti
-0.0037	concentr
-0.0038	clinic
-0.0039	patient
-0.0042	base
-0.0045	tumor_typ
-0.0047	human
-0.0050	cancer
-0.0050	effect
-0.0064	studi

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 2884
28538172
28147276
28052251
28297671
28658617

### False negatives for Test set: 19
29054992
27760307
18632560
18445651
29438690

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/04-17-07-52. Total    790.75 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/01/05-16-03-27  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=383   randForSplit=424   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.76      0.91      0.83     21507
Train discard       0.87      0.67      0.76     19296

  avg / total       0.81      0.80      0.80     40803

Train F2: 0.87671 (keep)

['yes', 'no']
[[19641  1866]
 [ 6346 12950]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.64      0.92      0.75      2868
Valid discard       0.93      0.67      0.78      4628

  avg / total       0.82      0.77      0.77      7496

Valid F2: 0.84533 (keep)

['yes', 'no']
[[2642  226]
 [1513 3115]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.64      0.93      0.76      2127
Test  discard       0.94      0.69      0.80      3515

  avg / total       0.83      0.78      0.78      5642

Test  F2: 0.85171 (keep)

['yes', 'no']
[[1970  157]
 [1087 2428]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=383, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1, 5]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0709	mice
+0.0673	wild_typ
+0.0551	wild_typ mice
+0.0485	knock_out
+0.0424	mut_mut
+0.0387	genotyp
+0.0382	defici
+0.0369	knock_out mice
+0.0330	mut_mut mice
+0.0325	cre
+0.0299	section
+0.0278	delet
+0.0263	litterm
+0.0258	wild_typ wild_typ
+0.0248	old
+0.0240	mice cell_lin
+0.0239	compar wild_typ
+0.0227	transgen
+0.0223	mice figur
+0.0211	supplementari figur

### Top negative features (20)
-0.0128	growth
-0.0130	cell line
-0.0130	investig
-0.0131	result
-0.0132	associ
-0.0132	rat
-0.0141	valu
-0.0144	method
-0.0165	clinic
-0.0165	concentr
-0.0167	treatment
-0.0170	potenti
-0.0176	differ
-0.0180	patient
-0.0190	base
-0.0192	tumor_typ
-0.0208	cancer
-0.0221	human
-0.0246	effect
-0.0304	studi

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1087
28147276
28052251
28297671
28658617
28423311

### False negatives for Test set: 157
28514652
28355571
24418349
26733414
18179890

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/05-16-16-18. Total    770.49 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/29-08-48-28  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=816   randForSplit=411   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.78      0.91      0.84     21300
Train discard       0.86      0.68      0.76     17779

  avg / total       0.81      0.81      0.80     39079

Train F2: 0.87850 (keep)

['yes', 'no']
[[19357  1943]
 [ 5614 12165]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.66      0.92      0.77      2823
Valid discard       0.93      0.69      0.79      4277

  avg / total       0.83      0.78      0.79      7100

Valid F2: 0.85725 (keep)

['yes', 'no']
[[2611  212]
 [1326 2951]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.64      0.92      0.76      2111
Test  discard       0.93      0.67      0.78      3233

  avg / total       0.81      0.77      0.77      5344

Test  F2: 0.84570 (keep)

['yes', 'no']
[[1937  174]
 [1071 2162]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=816, shuffle=True,
       verbose=0, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0706	mice
+0.0676	wild_typ
+0.0564	wild_typ mice
+0.0497	knock_out
+0.0432	mut_mut
+0.0390	genotyp
+0.0389	defici
+0.0377	knock_out mice
+0.0337	mut_mut mice
+0.0330	cre
+0.0296	section
+0.0282	delet
+0.0267	litterm
+0.0264	wild_typ wild_typ
+0.0254	old
+0.0240	compar wild_typ
+0.0239	mice cell_lin
+0.0228	transgen
+0.0228	mice figur
+0.0208	mice compar

### Top negative features (20)
-0.0140	evalu
-0.0140	investig
-0.0146	cell line
-0.0148	result
-0.0151	signific
-0.0155	potenti
-0.0156	clinic
-0.0157	method
-0.0158	assay
-0.0175	valu
-0.0176	treatment
-0.0177	concentr
-0.0179	differ
-0.0183	patient
-0.0189	base
-0.0201	tumor_typ
-0.0208	cancer
-0.0219	human
-0.0247	effect
-0.0311	studi

### Vectorizer:   Number of Features: 2940
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'left repres', u'left right', u'left untreat', u'legend', u'legend continu', u'legend figur', u'legend reader', u'length', u'lentivir', u'lentivirus']

Last 10 features: [u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone', u'zoom']

### False positives for Test set: 1071
28122243
28591580
28658617
28355573
28683305

### False negatives for Test set: 174
27312243
27522067
24418349
28007587
23659896

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7100         2823         4277          40%
Training Set        :        39079        21300        17779          55%
Test Set            :         5344         2111         3233          40%
TestSplit: 0.20
### End Time 2019/01/29-08-58-49. Total    620.94 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/04-12-45-22  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=188   randForSplit=910   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.79      0.90      0.84     21183
Train discard       0.86      0.70      0.77     17563

  avg / total       0.82      0.81      0.81     38746

Train F2: 0.87595 (keep)

['yes', 'no']
[[19098  2085]
 [ 5183 12380]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.68      0.91      0.78      2832
Valid discard       0.92      0.71      0.80      4185

  avg / total       0.83      0.79      0.79      7017

Valid F2: 0.85412 (keep)

['yes', 'no']
[[2582  250]
 [1205 2980]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.67      0.91      0.77      2127
Test  discard       0.92      0.70      0.80      3150

  avg / total       0.82      0.79      0.79      5277

Test  F2: 0.85075 (keep)

['yes', 'no']
[[1938  189]
 [ 944 2206]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=188, shuffle=True,
       verbose=0, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0719	mice
+0.0674	wild_typ
+0.0565	wild_typ mice
+0.0498	knock_out
+0.0440	mut_mut
+0.0391	genotyp
+0.0390	defici
+0.0379	knock_out mice
+0.0343	mut_mut mice
+0.0332	cre
+0.0299	section
+0.0279	delet
+0.0272	litterm
+0.0264	wild_typ wild_typ
+0.0249	old
+0.0240	compar wild_typ
+0.0240	mice cell_lin
+0.0229	transgen
+0.0226	mice figur
+0.0211	mice compar

### Top negative features (20)
-0.0141	investig
-0.0143	correl
-0.0143	result
-0.0145	cell line
-0.0151	clinic
-0.0155	signific
-0.0156	potenti
-0.0156	method
-0.0161	assay
-0.0175	treatment
-0.0176	valu
-0.0182	concentr
-0.0185	patient
-0.0186	differ
-0.0188	base
-0.0197	tumor_typ
-0.0206	cancer
-0.0218	human
-0.0252	effect
-0.0313	studi

### Vectorizer:   Number of Features: 2949
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'left', u'left panel', u'left repres', u'left right', u'left untreat', u'legend', u'legend continu', u'legend figur', u'legend reader', u'length']

Last 10 features: [u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone', u'zoom']

### False positives for Test set: 944
28355573
28423311
29241553
29091763
29091761

### False negatives for Test set: 189
29510224
26996529
26683421
24418349
23659896

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7017         2832         4185          40%
Training Set        :        38746        21183        17563          55%
Test Set            :         5277         2127         3150          40%
TestSplit: 0.20
### End Time 2019/02/04-12-55-20. Total    598.02 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/05-10-33-50  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Leg_para/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Leg_para/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Leg_para/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=724   randForSplit=548   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.84      0.86      0.85     21507
Train discard       0.84      0.81      0.83     19296

  avg / total       0.84      0.84      0.84     40803

Train F2: 0.85627 (keep)

['yes', 'no']
[[18528  2979]
 [ 3634 15662]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.74      0.87      0.80      2868
Valid discard       0.91      0.82      0.86      4628

  avg / total       0.85      0.84      0.84      7496

Valid F2: 0.83947 (keep)

['yes', 'no']
[[2487  381]
 [ 854 3774]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.75      0.87      0.81      2127
Test  discard       0.91      0.83      0.87      3515

  avg / total       0.85      0.84      0.85      5642

Test  F2: 0.84428 (keep)

['yes', 'no']
[[1851  276]
 [ 603 2912]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=724, shuffle=True,
       verbose=0, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0659	mice figur
+0.0658	wild_typ mice
+0.0571	wild_typ
+0.0459	knock_out
+0.0435	genotyp
+0.0430	mice compar
+0.0404	compar wild_typ
+0.0400	knock_out mice
+0.0385	litterm
+0.0382	mut_mut
+0.0374	cre
+0.0349	defici
+0.0316	mut_mut mice
+0.0311	wild_typ wild_typ
+0.0309	transgen
+0.0292	mice wild_typ
+0.0284	delet
+0.0282	mice signific
+0.0281	mice cell_lin
+0.0280	mice express

### Top negative features (20)
-0.0127	support inform
-0.0133	control group
-0.0135	improv
-0.0138	method
-0.0139	therapi
-0.0144	tumor_typ
-0.0145	evalu
-0.0148	year
-0.0148	drug
-0.0150	growth
-0.0154	potenti
-0.0161	concentr
-0.0167	cancer
-0.0172	rang
-0.0178	treatment
-0.0183	base
-0.0184	patient
-0.0203	tabl
-0.0214	human
-0.0234	clinic

### Vectorizer:   Number of Features: 8252
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'abdomin', u'aberr', u'abi', u'abil']

Middle 10 features: [u'island', u'islet', u'isofluran', u'isoform', u'isol', u'isol cell', u'isol mice', u'isol use', u'isol wild_typ', u'isotyp']

Last 10 features: [u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zinc finger', u'zone', u'zoom']

### False positives for Test set: 603
28538172
28147276
28052251
28297671
28423311

### False negatives for Test set: 276
28514652
28355571
27579714
24418349
26733414

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1710 predicted keep:  1551 recall: 0.907
gxd_status     selected papers:   183 predicted keep:   177 recall: 0.967
go_status      selected papers:  1755 predicted keep:  1579 recall: 0.900
tumor_status   selected papers:   147 predicted keep:   115 recall: 0.782
qtl_status     selected papers:     3 predicted keep:     1 recall: 0.333
Totals         selected papers:  2127 predicted keep:  1851 recall: 0.870
### End Time 2019/02/05-11-07-24. Total   2014.39 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/12-11-05-16  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=787   randForSplit=11   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.84      0.86      0.85     21281
Train discard       0.83      0.80      0.82     17985

  avg / total       0.83      0.83      0.83     39266

Train F2: 0.85403 (keep)

['yes', 'no']
[[18258  3023]
 [ 3511 14474]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.75      0.87      0.80      2845
Valid discard       0.90      0.81      0.85      4304

  avg / total       0.84      0.83      0.83      7149

Valid F2: 0.83930 (keep)

['yes', 'no']
[[2463  382]
 [ 830 3474]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.74      0.86      0.80      2150
Test  discard       0.90      0.80      0.85      3231

  avg / total       0.83      0.82      0.83      5381

Test  F2: 0.83303 (keep)

['yes', 'no']
[[1847  303]
 [ 639 2592]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=787, shuffle=True,
       verbose=0, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0685	wild_typ mice
+0.0610	wild_typ
+0.0494	knock_out
+0.0447	mice compar
+0.0439	genotyp
+0.0414	knock_out mice
+0.0413	compar wild_typ
+0.0405	mut_mut
+0.0394	defici
+0.0388	litterm
+0.0377	cre
+0.0336	mut_mut mice
+0.0310	wild_typ wild_typ
+0.0302	mice cell_lin
+0.0297	transgen
+0.0297	mice wild_typ
+0.0294	delet
+0.0293	mice signific
+0.0274	control mice
+0.0273	mice express

### Top negative features (20)
-0.0137	cell line
-0.0138	drug
-0.0138	growth
-0.0141	control group
-0.0143	tabl
-0.0143	high
-0.0151	method
-0.0154	support inform
-0.0155	evalu
-0.0157	tumor_typ
-0.0172	valu
-0.0174	rang
-0.0175	respect
-0.0182	concentr
-0.0189	cancer
-0.0189	patient
-0.0190	treatment
-0.0194	base
-0.0208	human
-0.0208	clinic

### Vectorizer:   Number of Features: 6247
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'late stage', u'latenc', u'later', u'later stage', u'later time', u'lavag', u'layer', u'lc', u'lc ms', u'lc3']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 639
29635032
28954219
28700935
28700948
29091761

### False negatives for Test set: 303
28052252
28383107
28681958
25171793
28017375

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7149         2845         4304          40%
Training Set        :        39266        21281        17985          54%
Test Set            :         5381         2150         3231          40%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1708 predicted keep:  1525 recall: 0.893
gxd_status     selected papers:   175 predicted keep:   167 recall: 0.954
go_status      selected papers:  1760 predicted keep:  1567 recall: 0.890
tumor_status   selected papers:   156 predicted keep:   115 recall: 0.737
qtl_status     selected papers:     7 predicted keep:     4 recall: 0.571
Totals         selected papers:  2150 predicted keep:  1847 recall: 0.859

### End Time 2019/02/12-11-31-26. Total   1570.11 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/02/13-14-18-33  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=310   randForSplit=562   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.83      0.87      0.85     21281
Train discard       0.83      0.79      0.81     17985

  avg / total       0.83      0.83      0.83     39266

Train F2: 0.86024 (keep)

['yes', 'no']
[[18469  2812]
 [ 3755 14230]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.74      0.88      0.80      2845
Valid discard       0.91      0.79      0.85      4304

  avg / total       0.84      0.83      0.83      7149

Valid F2: 0.84372 (keep)

['yes', 'no']
[[2491  354]
 [ 891 3413]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.73      0.87      0.79      2150
Test  discard       0.90      0.79      0.84      3231

  avg / total       0.83      0.82      0.82      5381

Test  F2: 0.83737 (keep)

['yes', 'no']
[[1868  282]
 [ 686 2545]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=310, shuffle=True,
       verbose=0, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02, 0.04]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0685	wild_typ mice
+0.0611	wild_typ
+0.0495	knock_out
+0.0447	mice compar
+0.0439	genotyp
+0.0415	knock_out mice
+0.0413	compar wild_typ
+0.0405	mut_mut
+0.0394	defici
+0.0389	litterm
+0.0378	cre
+0.0337	mut_mut mice
+0.0310	wild_typ wild_typ
+0.0303	mice cell_lin
+0.0298	transgen
+0.0297	mice wild_typ
+0.0294	delet
+0.0293	mice signific
+0.0274	control mice
+0.0274	mice express

### Top negative features (20)
-0.0137	cell line
-0.0137	growth
-0.0137	drug
-0.0140	control group
-0.0141	high
-0.0142	tabl
-0.0150	method
-0.0154	support inform
-0.0154	evalu
-0.0156	tumor_typ
-0.0170	valu
-0.0173	respect
-0.0173	rang
-0.0181	concentr
-0.0188	patient
-0.0188	cancer
-0.0188	treatment
-0.0192	base
-0.0206	human
-0.0207	clinic

### Vectorizer:   Number of Features: 6247
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'late stage', u'latenc', u'later', u'later stage', u'later time', u'lavag', u'layer', u'lc', u'lc ms', u'lc3']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 686
29635032
28954219
28700935
28700948
29091761

### False negatives for Test set: 282
28383107
28681958
25171793
28017375
28739801

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7149         2845         4304          40%
Training Set        :        39266        21281        17985          54%
Test Set            :         5381         2150         3231          40%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1708 predicted keep:  1537 recall: 0.900
gxd_status     selected papers:   175 predicted keep:   168 recall: 0.960
go_status      selected papers:  1760 predicted keep:  1578 recall: 0.897
tumor_status   selected papers:   156 predicted keep:   118 recall: 0.756
qtl_status     selected papers:     7 predicted keep:     4 recall: 0.571
Totals         selected papers:  2150 predicted keep:  1868 recall: 0.869
### End Time 2019/02/13-14-46-34. Total   1681.04 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/02/13-15-19-19  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=805   randForSplit=446   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.88      0.82      0.85     21281
Train discard       0.81      0.86      0.83     17985

  avg / total       0.84      0.84      0.84     39266

Train F2: 0.83429 (keep)

['yes', 'no']
[[17547  3734]
 [ 2490 15495]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.80      0.84      0.82      2845
Valid discard       0.89      0.86      0.88      4304

  avg / total       0.86      0.85      0.85      7149

Valid F2: 0.83153 (keep)

['yes', 'no']
[[2387  458]
 [ 586 3718]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.79      0.82      0.81      2150
Test  discard       0.88      0.86      0.87      3231

  avg / total       0.84      0.84      0.84      5381

Test  F2: 0.81664 (keep)

['yes', 'no']
[[1769  381]
 [ 462 2769]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__class_weight: None
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'hinge'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight=None, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=805, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__class_weight:[None, 'balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['hinge']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1160	wild_typ mice
+0.1071	wild_typ
+0.0796	knock_out
+0.0696	mice compar
+0.0692	mut_mut
+0.0657	knock_out mice
+0.0655	genotyp
+0.0653	compar wild_typ
+0.0635	defici
+0.0562	mut_mut mice
+0.0559	litterm
+0.0552	cre
+0.0508	wild_typ wild_typ
+0.0499	transgen
+0.0463	mice signific
+0.0458	mice cell_lin
+0.0445	mice wild_typ
+0.0433	transgen mice
+0.0424	mice express
+0.0412	control mice

### Top negative features (20)
-0.0210	higher
-0.0222	sampl
-0.0228	tumor_typ
-0.0230	evalu
-0.0231	high
-0.0232	growth
-0.0235	tabl
-0.0235	method
-0.0238	control group
-0.0239	support inform
-0.0251	rang
-0.0256	concentr
-0.0265	valu
-0.0285	cancer
-0.0288	base
-0.0291	treatment
-0.0304	respect
-0.0313	patient
-0.0319	clinic
-0.0335	human

### Vectorizer:   Number of Features: 6247
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'late stage', u'latenc', u'later', u'later stage', u'later time', u'lavag', u'layer', u'lc', u'lc ms', u'lc3']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 462
29635032
28954219
28700935
28700948
29091761

### False negatives for Test set: 381
28052252
28768188
29045841
27579714
28383107

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7149         2845         4304          40%
Training Set        :        39266        21281        17985          54%
Test Set            :         5381         2150         3231          40%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1708 predicted keep:  1477 recall: 0.865
gxd_status     selected papers:   175 predicted keep:   163 recall: 0.931
go_status      selected papers:  1760 predicted keep:  1510 recall: 0.858
tumor_status   selected papers:   156 predicted keep:   107 recall: 0.686
qtl_status     selected papers:     7 predicted keep:     3 recall: 0.429
Totals         selected papers:  2150 predicted keep:  1769 recall: 0.823
### End Time 2019/02/13-15-48-13. Total   1734.12 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/02/13-16-02-36  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=578   randForSplit=125   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.87      0.83      0.85     21281
Train discard       0.81      0.86      0.83     17985

  avg / total       0.84      0.84      0.84     39266

Train F4: 0.82906 (keep)

['yes', 'no']
[[17589  3692]
 [ 2580 15405]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.79      0.84      0.82      2845
Valid discard       0.89      0.86      0.87      4304

  avg / total       0.85      0.85      0.85      7149

Valid F4: 0.83723 (keep)

['yes', 'no']
[[2390  455]
 [ 619 3685]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.79      0.83      0.81      2150
Test  discard       0.88      0.85      0.87      3231

  avg / total       0.84      0.84      0.84      5381

Test  F4: 0.82342 (keep)

['yes', 'no']
[[1775  375]
 [ 471 2760]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__class_weight: None
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'hinge'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight=None, epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=578, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__class_weight:[None, 'balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['hinge']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1159	wild_typ mice
+0.1069	wild_typ
+0.0795	knock_out
+0.0695	mice compar
+0.0693	mut_mut
+0.0656	knock_out mice
+0.0653	genotyp
+0.0651	compar wild_typ
+0.0632	defici
+0.0563	mut_mut mice
+0.0558	litterm
+0.0552	cre
+0.0508	wild_typ wild_typ
+0.0499	transgen
+0.0463	mice signific
+0.0458	mice cell_lin
+0.0446	mice wild_typ
+0.0433	transgen mice
+0.0425	mice express
+0.0414	control mice

### Top negative features (20)
-0.0211	higher
-0.0221	sampl
-0.0228	tumor_typ
-0.0230	growth
-0.0231	evalu
-0.0233	high
-0.0235	method
-0.0236	tabl
-0.0238	control group
-0.0242	support inform
-0.0252	rang
-0.0255	concentr
-0.0267	valu
-0.0285	cancer
-0.0290	base
-0.0292	treatment
-0.0307	respect
-0.0313	patient
-0.0319	clinic
-0.0336	human

### Vectorizer:   Number of Features: 6247
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'late stage', u'latenc', u'later', u'later stage', u'later time', u'lavag', u'layer', u'lc', u'lc ms', u'lc3']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 471
29635032
28954219
28700935
28700948
29091761

### False negatives for Test set: 375
28052252
28768188
29045841
27579714
28383107

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7149         2845         4304          40%
Training Set        :        39266        21281        17985          54%
Test Set            :         5381         2150         3231          40%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1708 predicted keep:  1479 recall: 0.866
gxd_status     selected papers:   175 predicted keep:   163 recall: 0.931
go_status      selected papers:  1760 predicted keep:  1514 recall: 0.860
tumor_status   selected papers:   156 predicted keep:   108 recall: 0.692
qtl_status     selected papers:     7 predicted keep:     3 recall: 0.429
Totals         selected papers:  2150 predicted keep:  1775 recall: 0.826
### End Time 2019/02/13-16-28-39. Total   1562.71 seconds
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/18-10-28-38  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_mtbTest/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/jan2_mtbTest/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_mtbTest/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=878   randForSplit=596   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.84      0.85      0.85     22615
Train discard       0.81      0.80      0.80     17929

  avg / total       0.83      0.83      0.83     40544

Train F4: 0.84733 (keep)

['yes', 'no']
[[19169  3446]
 [ 3578 14351]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.74      0.87      0.80      2801
Valid discard       0.91      0.80      0.85      4348

  avg / total       0.84      0.83      0.83      7149

Valid F4: 0.86496 (keep)

['yes', 'no']
[[2448  353]
 [ 849 3499]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.74      0.87      0.80      2138
Test  discard       0.90      0.80      0.85      3243

  avg / total       0.84      0.83      0.83      5381

Test  F4: 0.85921 (keep)

['yes', 'no']
[[1856  282]
 [ 658 2585]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=878, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0678	wild_typ mice
+0.0596	wild_typ
+0.0486	knock_out
+0.0441	mice compar
+0.0438	genotyp
+0.0405	knock_out mice
+0.0400	compar wild_typ
+0.0398	mut_mut
+0.0392	defici
+0.0386	cre
+0.0385	litterm
+0.0329	mut_mut mice
+0.0305	wild_typ wild_typ
+0.0303	transgen
+0.0296	mice cell_lin
+0.0294	mice wild_typ
+0.0294	delet
+0.0287	mice signific
+0.0273	mice express
+0.0272	control mice

### Top negative features (20)
-0.0132	high
-0.0133	assay
-0.0134	correl
-0.0135	tabl
-0.0135	follow
-0.0135	sampl
-0.0139	group
-0.0143	control group
-0.0159	support inform
-0.0159	evalu
-0.0162	method
-0.0163	patient
-0.0173	rang
-0.0174	valu
-0.0180	respect
-0.0186	treatment
-0.0186	base
-0.0189	human
-0.0193	clinic
-0.0197	concentr

### Vectorizer:   Number of Features: 6280
First 10 features: [u'aa', u'aaa', u'aacr', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl']

Middle 10 features: [u'later stage', u'later time', u'layer', u'lc', u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 658
28099842
28538185
28052251
28614716
28355573

### False negatives for Test set: 282
29212021
28355571
28854357
28040797
28386934

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7149         2801         4348          39%
Training Set        :        40544        22615        17929          56%
Test Set            :         5381         2138         3243          40%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1720 predicted keep:  1561 recall: 0.908
gxd_status     selected papers:   176 predicted keep:   167 recall: 0.949
go_status      selected papers:  1784 predicted keep:  1579 recall: 0.885
tumor_status   selected papers:   142 predicted keep:   112 recall: 0.789
qtl_status     selected papers:     3 predicted keep:     2 recall: 0.667
Totals         selected papers:  2138 predicted keep:  1856 recall: 0.868
### End Time 2019/02/18-10-55-29. Total   1611.19 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/18-16-18-09  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=930   randForSplit=520   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.85      0.85      0.85     25900
Train discard       0.81      0.81      0.81     20459

  avg / total       0.83      0.83      0.83     46359

Train F4: 0.85075 (keep)

['yes', 'no']
[[22039  3861]
 [ 3954 16505]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.75      0.86      0.80      3124
Valid discard       0.90      0.82      0.86      5005

  avg / total       0.84      0.83      0.84      8129

Valid F4: 0.85162 (keep)

['yes', 'no']
[[2684  440]
 [ 910 4095]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.75      0.87      0.81      2345
Test  discard       0.91      0.82      0.86      3761

  avg / total       0.85      0.84      0.84      6106

Test  F4: 0.86367 (keep)

['yes', 'no']
[[2044  301]
 [ 669 3092]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=930, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0672	wild_typ mice
+0.0593	wild_typ
+0.0473	knock_out
+0.0445	genotyp
+0.0444	mice compar
+0.0401	knock_out mice
+0.0399	compar wild_typ
+0.0393	mut_mut
+0.0391	cre
+0.0383	litterm
+0.0378	defici
+0.0323	mut_mut mice
+0.0322	transgen
+0.0303	mice cell_lin
+0.0300	wild_typ wild_typ
+0.0296	delet
+0.0293	mice signific
+0.0291	mice wild_typ
+0.0278	mice express
+0.0276	control mice

### Top negative features (20)
-0.0129	improv
-0.0129	follow
-0.0131	sampl
-0.0132	potenti
-0.0134	high
-0.0140	tabl
-0.0143	control group
-0.0147	group
-0.0152	method
-0.0155	support inform
-0.0159	evalu
-0.0164	valu
-0.0168	rang
-0.0172	patient
-0.0175	respect
-0.0176	human
-0.0178	treatment
-0.0192	base
-0.0193	concentr
-0.0197	clinic

### Vectorizer:   Number of Features: 6289
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn', u'leav', u'lectin', u'led']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 669
28538172
28273465
28813664
28746868
28808138

### False negatives for Test set: 301
28355571
29166619
30026265
27338806
12115612

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3124         5005          38%
Training Set        :        46359        25900        20459          56%
Test Set            :         6106         2345         3761          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1909 predicted keep:  1699 recall: 0.890
gxd_status     selected papers:   197 predicted keep:   185 recall: 0.939
go_status      selected papers:  1990 predicted keep:  1758 recall: 0.883
tumor_status   selected papers:   168 predicted keep:   147 recall: 0.875
qtl_status     selected papers:     5 predicted keep:     3 recall: 0.600
Totals         selected papers:  2345 predicted keep:  2044 recall: 0.872
### End Time 2019/02/18-16-49-10. Total   1860.49 seconds

Fitting 1 folds for each of 4 candidates, totalling 4 fits
### Start Time 2019/02/18-20-59-28  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/testSet.txt
Random Seeds:	randForClassifier=311   randForSplit=565   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.78      0.90      0.84     25931
Train discard       0.84      0.68      0.76     20428

  avg / total       0.81      0.81      0.80     46359

Train F4: 0.89269 (keep)

['yes', 'no']
[[23352  2579]
 [ 6455 13973]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.65      0.92      0.76      3103
Valid discard       0.93      0.70      0.80      5026

  avg / total       0.82      0.78      0.78      8129

Valid F4: 0.89442 (keep)

['yes', 'no']
[[2842  261]
 [1527 3499]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.64      0.92      0.76      2335
Test  discard       0.93      0.68      0.79      3771

  avg / total       0.82      0.77      0.78      6106

Test  F4: 0.89623 (keep)

['yes', 'no']
[[2146  189]
 [1200 2571]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=311, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1, 0.1]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log', 'hinge']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0720	mice
+0.0661	wild_typ
+0.0544	wild_typ mice
+0.0470	knock_out
+0.0416	mut_mut
+0.0404	genotyp
+0.0383	defici
+0.0359	knock_out mice
+0.0342	cre
+0.0327	mut_mut mice
+0.0306	section
+0.0283	delet
+0.0264	litterm
+0.0263	old
+0.0252	transgen
+0.0250	wild_typ wild_typ
+0.0236	mice cell_lin
+0.0235	mice model
+0.0227	compar wild_typ
+0.0226	mice figur

### Top negative features (20)
-0.0127	correl
-0.0132	result
-0.0136	investig
-0.0138	evalu
-0.0146	method
-0.0147	assay
-0.0151	signific
-0.0151	rat
-0.0160	potenti
-0.0162	clinic
-0.0164	treatment
-0.0169	patient
-0.0173	human
-0.0173	valu
-0.0181	concentr
-0.0184	base
-0.0185	differ
-0.0191	tabl
-0.0254	effect
-0.0312	studi

### Vectorizer:   Number of Features: 2909
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lentivirus', u'lesion', u'lethal', u'letter', u'leukocyt', u'level', u'level cell', u'level cell_lin', u'level determin', u'level express']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 1200
28052251
28614716
29020625
28954219
28683305

### False negatives for Test set: 189
29510224
28355572
28199845
28355571
28834748

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3103         5026          38%
Training Set        :        46359        25931        20428          56%
Test Set            :         6106         2335         3771          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1899 predicted keep:  1793 recall: 0.944
gxd_status     selected papers:   197 predicted keep:   193 recall: 0.980
go_status      selected papers:  1954 predicted keep:  1808 recall: 0.925
tumor_status   selected papers:   152 predicted keep:   136 recall: 0.895
### End Time 2019/02/18-21-12-12. Total    763.81 seconds

Fitting 1 folds for each of 4 candidates, totalling 4 fits
Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/02/19-16-26-01  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=903   randForSplit=453   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.71      0.95      0.81     25900
Train discard       0.89      0.50      0.64     20459

  avg / total       0.79      0.75      0.74     46359

Train F4: 0.93161 (keep)

['yes', 'no']
[[24619  1281]
 [10228 10231]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.54      0.96      0.69      3124
Valid discard       0.95      0.49      0.65      5005

  avg / total       0.79      0.67      0.66      8129

Valid F4: 0.91548 (keep)

['yes', 'no']
[[2990  134]
 [2549 2456]]

### Metrics: Test Set			--- VERY INTERESTING
               precision    recall  f1-score   support

   Test  keep       0.55      0.96      0.70      2345
Test  discard       0.95      0.51      0.66      3761

  avg / total       0.80      0.68      0.68      6106

Test  F4: 0.92040 (keep)

['yes', 'no']
[[2254   91]
 [1858 1903]]

### Best Pipeline Parameters:
classifier__alpha: 5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=903, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1, 5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0180	wild_typ mice
+0.0162	wild_typ
+0.0130	knock_out
+0.0126	mice compar
+0.0126	genotyp
+0.0113	compar wild_typ
+0.0109	knock_out mice
+0.0109	cre
+0.0108	defici
+0.0108	litterm
+0.0105	mut_mut
+0.0089	transgen
+0.0088	mice cell_lin
+0.0087	delet
+0.0086	mut_mut mice
+0.0084	mice signific
+0.0083	wild_typ wild_typ
+0.0081	mice wild_typ
+0.0081	control mice
+0.0079	old

### Top negative features (20)
-0.0034	correl
-0.0034	control group
-0.0035	potenti
-0.0035	case
-0.0036	standard
-0.0036	drug
-0.0037	predict
-0.0040	evalu
-0.0040	support inform
-0.0041	treatment
-0.0041	tabl
-0.0041	patient
-0.0042	method
-0.0042	respect
-0.0045	human
-0.0046	valu
-0.0051	clinic
-0.0051	rang
-0.0054	base
-0.0056	concentr

### Vectorizer:   Number of Features: 6289
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn', u'leav', u'lectin', u'led']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 1858
28538172
28658617
28273465
29166612
28813664

### False negatives for Test set: 91
12115612
24418349
28017375
10593920
29449372

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3124         5005          38%
Training Set        :        46359        25900        20459          56%
Test Set            :         6106         2345         3761          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1909 predicted keep:  1855 recall: 0.972
gxd_status     selected papers:   197 predicted keep:   197 recall: 1.000
go_status      selected papers:  1990 predicted keep:  1921 recall: 0.965
tumor_status   selected papers:   168 predicted keep:   160 recall: 0.952
qtl_status     selected papers:     5 predicted keep:     4 recall: 0.800
Totals         selected papers:  2345 predicted keep:  2254 recall: 0.961
### End Time 2019/02/19-16-55-58. Total   1797.50 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/19-19-19-47  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=22   randForSplit=0   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.85      0.85      0.85     25898
Train discard       0.81      0.82      0.82     20461

  avg / total       0.84      0.84      0.84     46359

Train F4: 0.85286 (keep)

['yes', 'no']
[[22084  3814]
 [ 3747 16714]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.77      0.86      0.81      3164
Valid discard       0.90      0.83      0.87      4965

  avg / total       0.85      0.84      0.85      8129

Valid F4: 0.85535 (keep)

['yes', 'no']
[[2726  438]
 [ 829 4136]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.74      0.86      0.79      2307
Test  discard       0.90      0.82      0.86      3799

  avg / total       0.84      0.83      0.83      6106

Test  F4: 0.84875 (keep)

['yes', 'no']
[[1976  331]
 [ 690 3109]]

### Best Pipeline Parameters:
classifier__alpha: 1
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=1, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=22, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[1]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0662	mice figur
+0.0660	wild_typ mice
+0.0559	wild_typ
+0.0453	knock_out
+0.0446	genotyp
+0.0434	mice compar
+0.0398	knock_out mice
+0.0395	cre
+0.0392	compar wild_typ
+0.0391	litterm
+0.0380	mut_mut
+0.0348	defici
+0.0335	transgen
+0.0314	mut_mut mice
+0.0302	wild_typ wild_typ
+0.0296	transgen mice
+0.0293	mice wild_typ
+0.0291	delet
+0.0288	mice use
+0.0288	mice express

### Top negative features (20)
-0.0124	year
-0.0135	present
-0.0137	higher
-0.0139	drug
-0.0140	support inform
-0.0141	improv
-0.0143	control group
-0.0143	potenti
-0.0146	valu
-0.0150	group
-0.0158	method
-0.0165	patient
-0.0167	rang
-0.0169	evalu
-0.0173	human
-0.0175	treatment
-0.0178	concentr
-0.0181	base
-0.0210	tabl
-0.0213	clinic

### Vectorizer:   Number of Features: 8561
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abc', u'abcam', u'abdomin', u'aberr', u'abi']

Middle 10 features: [u'jolla', u'journal', u'judg', u'juli', u'jun', u'junction', u'june', u'just', u'kaplan', u'kaplan meier']

Last 10 features: [u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zinc finger', u'zone', u'zoom']

### False positives for Test set: 690
28122243
28297671
28423311
29020625
29091758

### False negatives for Test set: 331
29510224
28423313
29166619
26147692
29325869

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3164         4965          39%
Training Set        :        46359        25898        20461          56%
Test Set            :         6106         2307         3799          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1841 predicted keep:  1639 recall: 0.890
gxd_status     selected papers:   177 predicted keep:   171 recall: 0.966
go_status      selected papers:  1922 predicted keep:  1681 recall: 0.875
tumor_status   selected papers:   171 predicted keep:   142 recall: 0.830
qtl_status     selected papers:     3 predicted keep:     0 recall: 0.000
Totals         selected papers:  2307 predicted keep:  1976 recall: 0.857
### End Time 2019/02/19-19-56-32. Total   2205.83 seconds

Fitting 1 folds for each of 3 candidates, totalling 3 fits
### Start Time 2019/02/20-07-03-16  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=578   randForSplit=725   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.74      0.93      0.82     25898
Train discard       0.87      0.57      0.69     20461

  avg / total       0.80      0.78      0.77     46359

Train F4: 0.91924 (keep)

['yes', 'no']
[[24185  1713]
 [ 8711 11750]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.59      0.94      0.73      3164
Valid discard       0.94      0.59      0.72      4965

  avg / total       0.81      0.73      0.73      8129

Valid F4: 0.91155 (keep)

['yes', 'no']
[[2984  180]
 [2042 2923]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.57      0.95      0.71      2307
Test  discard       0.95      0.57      0.71      3799

  avg / total       0.81      0.71      0.71      6106

Test  F4: 0.91076 (keep)

['yes', 'no']
[[2181  126]
 [1617 2182]]

### Best Pipeline Parameters:
classifier__alpha: 5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.03
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=578, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.03,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[5, 1, 0.1]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.03]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0192	mice figur
+0.0184	wild_typ mice
+0.0159	wild_typ
+0.0131	genotyp
+0.0130	knock_out
+0.0129	mice compar
+0.0116	cre
+0.0115	litterm
+0.0115	compar wild_typ
+0.0113	knock_out mice
+0.0106	mut_mut
+0.0105	defici
+0.0098	transgen
+0.0090	delet
+0.0087	mut_mut mice
+0.0087	mice cell_lin
+0.0087	wild_typ wild_typ
+0.0086	control mice
+0.0086	mice signific
+0.0085	mice wild_typ

### Top negative features (20)
-0.0036	inform
-0.0036	correl
-0.0036	standard
-0.0037	order
-0.0037	predict
-0.0038	support inform
-0.0039	improv
-0.0040	potenti
-0.0042	treatment
-0.0042	patient
-0.0042	drug
-0.0044	valu
-0.0045	evalu
-0.0046	method
-0.0046	human
-0.0054	base
-0.0054	concentr
-0.0055	rang
-0.0057	tabl
-0.0059	clinic

### Vectorizer:   Number of Features: 5548
First 10 features: [u'aa', u'aaa', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat', u'abnorm']

Middle 10 features: [u'involv', u'involv cell', u'involv regul', u'iodid', u'ion', u'ip', u'ir', u'ire', u'irradi', u'irregular']

Last 10 features: [u'yellow', u'yfp', u'yield', u'young', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone']

### False positives for Test set: 1617
28122243
28297671
28614706
28423311
29020625

### False negatives for Test set: 126
26147692
29045814
28673964
28972154
28882895

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3164         4965          39%
Training Set        :        46359        25898        20461          56%
Test Set            :         6106         2307         3799          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1841 predicted keep:  1784 recall: 0.969
gxd_status     selected papers:   177 predicted keep:   177 recall: 1.000
go_status      selected papers:  1922 predicted keep:  1833 recall: 0.954
tumor_status   selected papers:   171 predicted keep:   161 recall: 0.942
qtl_status     selected papers:     3 predicted keep:     1 recall: 0.333
Totals         selected papers:  2307 predicted keep:  2181 recall: 0.945
### End Time 2019/02/20-07-44-44. Total   2487.51 seconds
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/20-09-19-42  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=0   randForSplit=109   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.75      0.93      0.83     25898
Train discard       0.87      0.60      0.71     20461

  avg / total       0.80      0.78      0.78     46359

Train F2: 0.88552 (keep)

['yes', 'no']
[[24059  1839]
 [ 8195 12266]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.61      0.94      0.74      3164
Valid discard       0.94      0.62      0.75      4965

  avg / total       0.81      0.74      0.74      8129

Valid F2: 0.84585 (keep)

['yes', 'no']
[[2961  203]
 [1886 3079]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.59      0.94      0.72      2307
Test  discard       0.94      0.60      0.73      3799

  avg / total       0.81      0.73      0.73      6106

Test  F2: 0.84030 (keep)

['yes', 'no']
[[2171  136]
 [1519 2280]]

### Best Pipeline Parameters:
classifier__alpha: 5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.03
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.03,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.03]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.0192	mice figur
+0.0184	wild_typ mice
+0.0159	wild_typ
+0.0131	genotyp
+0.0130	knock_out
+0.0129	mice compar
+0.0116	cre
+0.0115	litterm
+0.0115	compar wild_typ
+0.0113	knock_out mice
+0.0106	mut_mut
+0.0105	defici
+0.0098	transgen
+0.0090	delet
+0.0087	mut_mut mice
+0.0087	mice cell_lin
+0.0087	wild_typ wild_typ
+0.0086	control mice
+0.0086	mice signific
+0.0085	mice wild_typ

### Top negative features (20)
-0.0036	inform
-0.0036	correl
-0.0036	standard
-0.0037	order
-0.0038	predict
-0.0038	support inform
-0.0039	improv
-0.0039	potenti
-0.0042	treatment
-0.0042	patient
-0.0042	drug
-0.0044	valu
-0.0045	evalu
-0.0046	method
-0.0046	human
-0.0054	base
-0.0054	concentr
-0.0055	rang
-0.0057	tabl
-0.0059	clinic

### Vectorizer:   Number of Features: 5548
First 10 features: [u'aa', u'aaa', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat', u'abnorm']

Middle 10 features: [u'involv', u'involv cell', u'involv regul', u'iodid', u'ion', u'ip', u'ir', u'ire', u'irradi', u'irregular']

Last 10 features: [u'yellow', u'yfp', u'yield', u'young', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone']

### False positives for Test set: 1519
28122243
28297671
28614706
28423311
29020625

### False negatives for Test set: 136
26147692
29045814
28673964
28972154
28882895

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3164         4965          39%
Training Set        :        46359        25898        20461          56%
Test Set            :         6106         2307         3799          38%
TestSplit: 0.20
Recall for papers selected by each curation group
ap_status      selected papers:  1841 predicted keep:  1778 recall: 0.966
gxd_status     selected papers:   177 predicted keep:   177 recall: 1.000
go_status      selected papers:  1922 predicted keep:  1827 recall: 0.951
tumor_status   selected papers:   171 predicted keep:   160 recall: 0.936
qtl_status     selected papers:     3 predicted keep:     1 recall: 0.333
Totals         selected papers:  2307 predicted keep:  2171 recall: 0.941
### End Time 2019/02/20-09-58-34. Total   2332.47 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/02/20-10-45-54  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=33   randForSplit=622   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.87      0.84      0.86     25898
Train discard       0.81      0.85      0.83     20461

  avg / total       0.85      0.85      0.85     46359

Train F2: 0.85006 (keep)

['yes', 'no']
[[21865  4033]
 [ 3151 17310]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.79      0.85      0.82      3164
Valid discard       0.90      0.86      0.88      4965

  avg / total       0.86      0.86      0.86      8129

Valid F2: 0.83868 (keep)

['yes', 'no']
[[2693  471]
 [ 706 4259]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.78      0.85      0.81      2307
Test  discard       0.90      0.85      0.88      3799

  avg / total       0.85      0.85      0.85      6106

Test  F2: 0.83270 (keep)

['yes', 'no']
[[1957  350]
 [ 566 3233]]

### Best Pipeline Parameters:
classifier__alpha: 0.5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=33, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02, 0.03]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1045	wild_typ mice
+0.1025	mice figur
+0.0871	wild_typ
+0.0700	knock_out
+0.0679	genotyp
+0.0660	mice compar
+0.0620	knock_out mice
+0.0608	cre
+0.0605	mut_mut
+0.0599	litterm
+0.0594	compar wild_typ
+0.0526	defici
+0.0515	transgen
+0.0500	mut_mut mice
+0.0477	transgen mice
+0.0465	wild_typ wild_typ
+0.0450	mice wild_typ
+0.0444	mice use
+0.0441	mice express
+0.0436	mice signific

### Top negative features (20)
-0.0198	year
-0.0200	drug
-0.0203	valu
-0.0211	potenti
-0.0212	improv
-0.0213	present
-0.0214	higher
-0.0218	support inform
-0.0227	control group
-0.0228	rang
-0.0230	method
-0.0242	group
-0.0250	concentr
-0.0254	evalu
-0.0258	patient
-0.0262	base
-0.0265	human
-0.0275	treatment
-0.0322	tabl
-0.0322	clinic

### Vectorizer:   Number of Features: 8561
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abc', u'abcam', u'abdomin', u'aberr', u'abi']

Middle 10 features: [u'jolla', u'journal', u'judg', u'juli', u'jun', u'junction', u'june', u'just', u'kaplan', u'kaplan meier']

Last 10 features: [u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zinc finger', u'zone', u'zoom']

### False positives for Test set: 566
28122243
28297671
28423311
29020625
29091763

### False negatives for Test set: 350
29510224
28423313
29166619
26147692
26176793

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3164         4965          39%
Training Set        :        46359        25898        20461          56%
Test Set            :         6106         2307         3799          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1841 predicted keep:  1631 recall: 0.886
gxd_status     selected papers:   177 predicted keep:   169 recall: 0.955
go_status      selected papers:  1922 predicted keep:  1666 recall: 0.867
tumor_status   selected papers:   171 predicted keep:   144 recall: 0.842
qtl_status     selected papers:     3 predicted keep:     0 recall: 0.000
Totals         selected papers:  2307 predicted keep:  1957 recall: 0.848
### End Time 2019/02/20-11-25-45. Total   2391.67 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/20-11-46-38  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=757   randForSplit=493   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.88      0.84      0.86     25898
Train discard       0.81      0.85      0.83     20461

  avg / total       0.85      0.85      0.85     46359

Train F4: 0.84264 (keep)

['yes', 'no']
[[21769  4129]
 [ 3048 17413]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.80      0.85      0.82      3164
Valid discard       0.90      0.86      0.88      4965

  avg / total       0.86      0.86      0.86      8129

Valid F4: 0.84419 (keep)

['yes', 'no']
[[2681  483]
 [ 684 4281]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.78      0.84      0.81      2307
Test  discard       0.90      0.85      0.88      3799

  avg / total       0.85      0.85      0.85      6106

Test  F4: 0.83937 (keep)

['yes', 'no']
[[1946  361]
 [ 555 3244]]

### Best Pipeline Parameters:
classifier__alpha: 0.5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=757, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1045	wild_typ mice
+0.1025	mice figur
+0.0871	wild_typ
+0.0701	knock_out
+0.0679	genotyp
+0.0661	mice compar
+0.0621	knock_out mice
+0.0608	cre
+0.0605	mut_mut
+0.0599	litterm
+0.0595	compar wild_typ
+0.0526	defici
+0.0515	transgen
+0.0500	mut_mut mice
+0.0477	transgen mice
+0.0465	wild_typ wild_typ
+0.0450	mice wild_typ
+0.0444	mice use
+0.0441	mice express
+0.0436	mice signific

### Top negative features (20)
-0.0199	year
-0.0201	drug
-0.0203	valu
-0.0211	improv
-0.0212	potenti
-0.0212	present
-0.0214	higher
-0.0217	support inform
-0.0227	control group
-0.0229	rang
-0.0230	method
-0.0241	group
-0.0251	concentr
-0.0254	evalu
-0.0259	patient
-0.0262	base
-0.0266	human
-0.0275	treatment
-0.0321	tabl
-0.0322	clinic

### Vectorizer:   Number of Features: 8561
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abc', u'abcam', u'abdomin', u'aberr', u'abi']

Middle 10 features: [u'jolla', u'journal', u'judg', u'juli', u'jun', u'junction', u'june', u'just', u'kaplan', u'kaplan meier']

Last 10 features: [u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zinc finger', u'zone', u'zoom']

### False positives for Test set: 555
28122243
28297671
28423311
29020625
29091763

### False negatives for Test set: 361
29510224
28423313
29166619
26147692
26176793

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3164         4965          39%
Training Set        :        46359        25898        20461          56%
Test Set            :         6106         2307         3799          38%
TestSplit: 0.20
### End Time 2019/02/20-12-24-03. Total   2244.75 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/20-12-50-56  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/testSet.txt
Random Seeds:	randForClassifier=550   randForSplit=575   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.86      0.84      0.85     25931
Train discard       0.81      0.82      0.81     20428

  avg / total       0.84      0.83      0.83     46359

Train F2: 0.84592 (keep)

['yes', 'no']
[[21851  4080]
 [ 3580 16848]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.76      0.86      0.81      3103
Valid discard       0.91      0.83      0.87      5026

  avg / total       0.85      0.84      0.85      8129

Valid F2: 0.83737 (keep)

['yes', 'no']
[[2664  439]
 [ 831 4195]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.75      0.86      0.80      2335
Test  discard       0.90      0.82      0.86      3771

  avg / total       0.84      0.83      0.84      6106

Test  F2: 0.83243 (keep)

['yes', 'no']
[[2002  333]
 [ 683 3088]]

### Best Pipeline Parameters:
classifier__alpha: 0.25
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.25, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=550, shuffle=True,
       verbose=0, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.25]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.2087	mice
+0.1679	wild_typ
+0.1452	wild_typ mice
+0.1231	knock_out
+0.1131	mut_mut
+0.1030	genotyp
+0.0985	defici
+0.0963	knock_out mice
+0.0919	cre
+0.0894	mut_mut mice
+0.0707	mice model
+0.0698	litterm
+0.0698	transgen
+0.0689	delet
+0.0655	section
+0.0654	supplementari figur
+0.0640	wild_typ wild_typ
+0.0619	old
+0.0614	transgen mice
+0.0607	mice figur

### Top negative features (20)
-0.0313	associ
-0.0343	method
-0.0359	assay
-0.0361	evalu
-0.0367	investig
-0.0383	result
-0.0393	valu
-0.0394	concentr
-0.0400	potenti
-0.0411	clinic
-0.0425	tabl
-0.0426	treatment
-0.0432	base
-0.0439	signific
-0.0442	human
-0.0459	patient
-0.0467	rat
-0.0498	differ
-0.0625	effect
-0.0799	studi

### Vectorizer:   Number of Features: 2909
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lentivirus', u'lesion', u'lethal', u'letter', u'leukocyt', u'level', u'level cell', u'level cell_lin', u'level determin', u'level express']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 683
28052251
29020625
28954219
28683305
29791838

### False negatives for Test set: 333
29510224
28355572
28199845
28355571
29241547

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3103         5026          38%
Training Set        :        46359        25931        20428          56%
Test Set            :         6106         2335         3771          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1899 predicted keep:  1697 recall: 0.894
gxd_status     selected papers:   197 predicted keep:   190 recall: 0.964
go_status      selected papers:  1954 predicted keep:  1705 recall: 0.873
tumor_status   selected papers:   152 predicted keep:   127 recall: 0.836
### End Time 2019/02/20-13-02-00. Total    664.44 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/20-13-08-05  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/testSet.txt
Random Seeds:	randForClassifier=98   randForSplit=145   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.83      0.86      0.85     25931
Train discard       0.82      0.78      0.80     20428

  avg / total       0.82      0.82      0.82     46359

Train F2: 0.85655 (keep)

['yes', 'no']
[[22391  3540]
 [ 4589 15839]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.72      0.88      0.79      3103
Valid discard       0.92      0.79      0.85      5026

  avg / total       0.84      0.82      0.83      8129

Valid F2: 0.84525 (keep)

['yes', 'no']
[[2743  360]
 [1071 3955]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.71      0.88      0.78      2335
Test  discard       0.91      0.78      0.84      3771

  avg / total       0.83      0.81      0.82      6106

Test  F2: 0.83762 (keep)

['yes', 'no']
[[2050  285]
 [ 847 2924]]

### Best Pipeline Parameters:
classifier__alpha: 0.5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=98, shuffle=True, verbose=0,
       warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1255	mice
+0.1096	wild_typ
+0.0919	wild_typ mice
+0.0788	knock_out
+0.0708	mut_mut
+0.0669	genotyp
+0.0637	defici
+0.0608	knock_out mice
+0.0577	cre
+0.0558	mut_mut mice
+0.0470	section
+0.0460	delet
+0.0443	litterm
+0.0432	transgen
+0.0421	old
+0.0417	wild_typ wild_typ
+0.0416	mice model
+0.0388	supplementari figur
+0.0388	mice cell_lin
+0.0382	mice figur

### Top negative features (20)
-0.0202	correl
-0.0233	investig
-0.0234	evalu
-0.0236	method
-0.0237	result
-0.0243	assay
-0.0265	potenti
-0.0270	clinic
-0.0271	signific
-0.0274	rat
-0.0277	valu
-0.0279	treatment
-0.0284	concentr
-0.0289	human
-0.0290	patient
-0.0298	base
-0.0304	tabl
-0.0319	differ
-0.0420	effect
-0.0524	studi

### Vectorizer:   Number of Features: 2909
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lentivirus', u'lesion', u'lethal', u'letter', u'leukocyt', u'level', u'level cell', u'level cell_lin', u'level determin', u'level express']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 847
28052251
28614716
29020625
28954219
28683305

### False negatives for Test set: 285
29510224
28355572
28199845
28355571
29241547

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3103         5026          38%
Training Set        :        46359        25931        20428          56%
Test Set            :         6106         2335         3771          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1899 predicted keep:  1732 recall: 0.912
gxd_status     selected papers:   197 predicted keep:   190 recall: 0.964
go_status      selected papers:  1954 predicted keep:  1740 recall: 0.890
tumor_status   selected papers:   152 predicted keep:   130 recall: 0.855
### End Time 2019/02/20-13-19-09. Total    663.42 seconds


----------------------------------
Start April 2019
----------------------------------


Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/24-11-43-17  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/Legends/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/Legends/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/Legends/Proc1/testSet.txt
Random Seeds:	randForClassifier=847   randForSplit=146   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.83      0.87      0.85     27624
Train discard       0.82      0.78      0.80     21843

  avg / total       0.83      0.83      0.83     49467

Train F2: 0.86032 (keep)

['yes', 'no']
[[23980  3644]
 [ 4891 16952]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.70      0.89      0.79      3434
Valid discard       0.92      0.76      0.83      5400

  avg / total       0.83      0.81      0.81      8834

Valid F2: 0.84633 (keep)

['yes', 'no']
[[3061  373]
 [1287 4113]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.72      0.88      0.79      2599
Test  discard       0.91      0.78      0.84      4038

  avg / total       0.84      0.82      0.82      6637

Test  F2: 0.84328 (keep)

['yes', 'no']
[[2288  311]
 [ 882 3156]]

### Best Pipeline Parameters:
classifier__alpha: 0.5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=847, shuffle=True,
       verbose=0, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1273	mice
+0.1102	wild_typ
+0.0941	wild_typ mice
+0.0803	knock_out
+0.0709	mut_mut
+0.0669	genotyp
+0.0649	defici
+0.0621	knock_out mice
+0.0573	cre
+0.0560	mut_mut mice
+0.0474	section
+0.0464	delet
+0.0447	litterm
+0.0428	transgen
+0.0422	old
+0.0420	wild_typ wild_typ
+0.0403	mice model
+0.0396	mice cell_lin
+0.0391	mice figur
+0.0385	supplementari figur

### Top negative features (20)
-0.0203	correl
-0.0222	evalu
-0.0226	method
-0.0228	investig
-0.0234	result
-0.0236	assay
-0.0259	valu
-0.0261	signific
-0.0263	potenti
-0.0273	rat
-0.0273	clinic
-0.0274	treatment
-0.0281	patient
-0.0284	concentr
-0.0289	human
-0.0290	base
-0.0302	tabl
-0.0328	differ
-0.0413	effect
-0.0509	studi

### Vectorizer:   Number of Features: 2902
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'length', u'lentivir', u'lentivirus', u'lesion', u'lethal', u'letter', u'leukocyt', u'level', u'level cell', u'level cell_lin']

Last 10 features: [u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone', u'zoom']

### False positives for Test set: 882
29635032
28467904
28538172
29212033
29091761

### False negatives for Test set: 311
29660410
28903050
29241547
28854357
28793256

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3434         5400          39%
Training Set        :        49467        27624        21843          56%
Test Set            :         6637         2599         4038          39%
TestSplit: 0.20
### End Time 2019/04/24-11-55-36. Total    738.85 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2144 predicted keep:  1940 recall: 0.905
gxd_status     selected papers:   198 predicted keep:   191 recall: 0.965
go_status      selected papers:  2182 predicted keep:  1964 recall: 0.900
tumor_status   selected papers:   159 predicted keep:   129 recall: 0.811
qtl_status     selected papers:     3 predicted keep:     1 recall: 0.333
Totals         selected papers:  2599 predicted keep:  2288 recall: 0.880
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/24-12-50-33  SGDlog.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=17   randForSplit=727   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.87      0.84      0.85     27648
Train discard       0.80      0.85      0.82     21819

  avg / total       0.84      0.84      0.84     49467

Train F2: 0.84307 (keep)

['yes', 'no']
[[23107  4541]
 [ 3342 18477]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.78      0.85      0.81      3402
Valid discard       0.90      0.85      0.87      5432

  avg / total       0.85      0.85      0.85      8834

Valid F2: 0.83198 (keep)

['yes', 'no']
[[2878  524]
 [ 810 4622]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.78      0.84      0.81      2607
Test  discard       0.89      0.85      0.87      4030

  avg / total       0.85      0.85      0.85      6637

Test  F2: 0.83025 (keep)

['yes', 'no']
[[2198  409]
 [ 611 3419]]

### Best Pipeline Parameters:
classifier__alpha: 0.5
classifier__class_weight: 'balanced'
classifier__eta0: 0.01
classifier__learning_rate: 'optimal'
classifier__loss: 'log'
classifier__penalty: 'l2'
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
SGDClassifier(alpha=0.5, average=False, class_weight='balanced', epsilon=0.1,
       eta0=0.01, fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,
       penalty='l2', power_t=0.5, random_state=17, shuffle=True, verbose=0,
       warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__alpha:[0.5]
classifier__class_weight:['balanced']
classifier__eta0:[0.01]
classifier__learning_rate:['optimal']
classifier__loss:['log']
classifier__penalty:['l2']
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features (20)
+0.1088	wild_typ mice
+0.0939	wild_typ
+0.0763	knock_out
+0.0696	mice compar
+0.0693	genotyp
+0.0648	knock_out mice
+0.0630	mut_mut
+0.0619	compar wild_typ
+0.0613	cre
+0.0598	litterm
+0.0596	defici
+0.0520	mut_mut mice
+0.0504	transgen
+0.0477	wild_typ wild_typ
+0.0472	mice cell_lin
+0.0464	mice wild_typ
+0.0463	mice signific
+0.0454	transgen mice
+0.0448	delet
+0.0444	mice express

### Top negative features (20)
-0.0196	higher
-0.0203	improv
-0.0204	potenti
-0.0206	present
-0.0210	follow
-0.0215	high
-0.0226	method
-0.0230	control group
-0.0232	group
-0.0233	rang
-0.0241	valu
-0.0242	support inform
-0.0244	evalu
-0.0268	human
-0.0270	concentr
-0.0272	respect
-0.0280	base
-0.0286	patient
-0.0297	treatment
-0.0311	clinic

### Vectorizer:   Number of Features: 6288
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn', u'leav']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 611
28355573
28178514
29045831
29262323
29719241

### False negatives for Test set: 409
28903050
28854357
29045841
30184487
25704808

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3402         5432          39%
Training Set        :        49467        27648        21819          56%
Test Set            :         6637         2607         4030          39%
TestSplit: 0.20
### End Time 2019/04/24-13-22-22. Total   1909.07 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2142 predicted keep:  1873 recall: 0.874
gxd_status     selected papers:   207 predicted keep:   199 recall: 0.961
go_status      selected papers:  2179 predicted keep:  1898 recall: 0.871
tumor_status   selected papers:   187 predicted keep:   150 recall: 0.802
qtl_status     selected papers:     4 predicted keep:     1 recall: 0.250
Totals         selected papers:  2607 predicted keep:  2198 recall: 0.843
