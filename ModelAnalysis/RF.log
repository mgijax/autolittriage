Fitting 1 folds for each of 1 candidates, totalling 1 fits
Fitting 1 folds for each of 1 candidates, totalling 1 fits
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/05-16-34-03  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=325   randForSplit=686   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.98      0.73      0.83     21507
Train discard       0.76      0.98      0.86     19296

  avg / total       0.88      0.85      0.85     40803

Train F2: 0.76621 (keep)

['yes', 'no']
[[15628  5879]
 [  327 18969]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.96      0.73      0.83      2868
Valid discard       0.85      0.98      0.91      4628

  avg / total       0.89      0.88      0.88      7496

Valid F2: 0.76317 (keep)

['yes', 'no']
[[2083  785]
 [  92 4536]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.66      0.38      0.48      2127
Test  discard       0.70      0.88      0.78      3515

  avg / total       0.68      0.69      0.67      5642

Test  F2: 0.41568 (keep)

['yes', 'no']
[[ 810 1317]
 [ 425 3090]]

### Best Pipeline Parameters:
classifier__max_features: 30
classifier__n_estimators: 2
classifier__n_jobs: 4
vectorizer__max_df: 0.75
vectorizer__min_df: 10
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=30,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=4,
            oob_score=False, random_state=325, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=10,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[30]
classifier__n_estimators:[2]
classifier__n_jobs:[4]
vectorizer__max_df:[0.75]
vectorizer__min_df:[10]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 330981
First 10 features: [u'_2', u'a00', u'a00 b00', u'a02', u'a10', u'a10 mv', u'a100', u'a100 mv', u'a100 pa', u'a11']

Middle 10 features: [u'larva expos', u'larva express', u'larva fed', u'larva figur', u'larva follow', u'larva genotyp', u'larva group', u'larva hpf', u'larva imag', u'larva indic']

Last 10 features: [u'zymographi perform', u'zymographi use', u'zymosan', u'zymosan induc', u'zymosan inject', u'zymosan mg', u'zymosan ml', u'zymosan particl', u'zyxin', u'zz']

### False positives for Test set: 425
28052251
28423311
29222174
27562772
26392163

### False negatives for Test set: 1317
21745596
28052242
28467912
28402849
28514652

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/05-16-45-28. Total    685.11 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/05-16-59-05  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=354   randForSplit=208   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.98      0.81      0.88     21507
Train discard       0.82      0.98      0.89     19296

  avg / total       0.90      0.89      0.89     40803

Train F2: 0.83536 (keep)

['yes', 'no']
[[17324  4183]
 [  340 18956]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.96      0.81      0.88      2868
Valid discard       0.89      0.98      0.93      4628

  avg / total       0.92      0.91      0.91      7496

Valid F2: 0.83321 (keep)

['yes', 'no']
[[2312  556]
 [  90 4538]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.74      0.54      0.62      2127
Test  discard       0.76      0.88      0.82      3515

  avg / total       0.75      0.75      0.74      5642

Test  F2: 0.56853 (keep)

['yes', 'no']
[[1144  983]
 [ 409 3106]]

### Best Pipeline Parameters:
classifier__max_features: 30
classifier__n_estimators: 2
classifier__n_jobs: 4
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=30,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=4,
            oob_score=False, random_state=354, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[30]
classifier__n_estimators:[2]
classifier__n_jobs:[4]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 409
28147276
28297671
28658617
28423311
28700948

### False negatives for Test set: 983
28800889
28052242
28228267
28636934
28514653

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/05-17-09-57. Total    651.58 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/05-17-13-10  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=155   randForSplit=92   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       1.00      0.99      0.99     21507
Train discard       0.99      1.00      0.99     19296

  avg / total       0.99      0.99      0.99     40803

Train F2: 0.99006 (keep)

['yes', 'no']
[[21252   255]
 [   47 19249]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       1.00      0.99      0.99      2868
Valid discard       0.99      1.00      1.00      4628

  avg / total       0.99      0.99      0.99      7496

Valid F2: 0.98994 (keep)

['yes', 'no']
[[2834   34]
 [   8 4620]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.79      0.82      0.81      2127
Test  discard       0.89      0.87      0.88      3515

  avg / total       0.85      0.85      0.85      5642

Test  F2: 0.81576 (keep)

['yes', 'no']
[[1749  378]
 [ 463 3052]]

### Best Pipeline Parameters:
classifier__max_features: 30
classifier__n_estimators: 10
classifier__n_jobs: 4
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=30,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,
            oob_score=False, random_state=155, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[30]
classifier__n_estimators:[10]
classifier__n_jobs:[4]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 463
28538172
28147276
28052251
28423311
28178514

### False negatives for Test set: 378
28800889
28402849
28514652
28355571
29466735

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/05-17-24-13. Total    663.63 seconds

Fitting 1 folds for each of 2 candidates, totalling 2 fits
### Start Time 2019/01/05-17-35-51  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=375   randForSplit=709   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       1.00      1.00      1.00     21507
Train discard       1.00      1.00      1.00     19296

  avg / total       1.00      1.00      1.00     40803

Train F2: 0.99858 (keep)

['yes', 'no']
[[21473    34]
 [   17 19279]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       1.00      1.00      1.00      2868
Valid discard       1.00      1.00      1.00      4628

  avg / total       1.00      1.00      1.00      7496

Valid F2: 0.99986 (keep)

['yes', 'no']
[[2868    0]
 [   2 4626]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.81      0.86      0.83      2127
Test  discard       0.91      0.88      0.90      3515

  avg / total       0.87      0.87      0.87      5642

Test  F2: 0.84729 (keep)

['yes', 'no']
[[1821  306]
 [ 417 3098]]

### Best Pipeline Parameters:
classifier__n_estimators: 20
classifier__n_jobs: 4
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=4,
            oob_score=False, random_state=375, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__n_estimators:[10, 20]
classifier__n_jobs:[4]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 417
28147276
28423311
28700948
29262323
29202196

### False negatives for Test set: 306
28800889
28402849
28514652
28355571
29020624

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/05-17-47-37. Total    706.01 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
building tree 1 of 20building tree 2 of 20

building tree 3 of 20
building tree 4 of 20
building tree 5 of 20
building tree 6 of 20
building tree 7 of 20
building tree 8 of 20
building tree 9 of 20
building tree 10 of 20
building tree 11 of 20
building tree 12 of 20
building tree 13 of 20
building tree 14 of 20
building tree 15 of 20
building tree 16 of 20
building tree 17 of 20
building tree 18 of 20
building tree 19 of 20
building tree 20 of 20
building tree 1 of 20
building tree 2 of 20
building tree 3 of 20
building tree 4 of 20
building tree 5 of 20
building tree 6 of 20
building tree 7 of 20
building tree 8 of 20
building tree 9 of 20
building tree 10 of 20
building tree 11 of 20
building tree 12 of 20
building tree 13 of 20
building tree 14 of 20
building tree 15 of 20
building tree 16 of 20
building tree 17 of 20
building tree 18 of 20
building tree 19 of 20
building tree 20 of 20
### Start Time 2019/01/08-10-30-53  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=8   randForSplit=773   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       1.00      1.00      1.00     21507
Train discard       1.00      1.00      1.00     19296

  avg / total       1.00      1.00      1.00     40803

Train F2: 0.99750 (keep)

['yes', 'no']
[[21444    63]
 [   17 19279]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       1.00      1.00      1.00      2868
Valid discard       1.00      1.00      1.00      4628

  avg / total       1.00      1.00      1.00      7496

Valid F2: 0.99909 (keep)

['yes', 'no']
[[2867    1]
 [   9 4619]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.81      0.87      0.84      2127
Test  discard       0.92      0.88      0.90      3515

  avg / total       0.88      0.87      0.88      5642

Test  F2: 0.85629 (keep)

['yes', 'no']
[[1846  281]
 [ 425 3090]]

### Best Pipeline Parameters:
classifier__max_features: 100
classifier__n_estimators: 20
classifier__n_jobs: 4
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=100,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=4,
            oob_score=False, random_state=8, verbose=3, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[100]
classifier__n_estimators:[20]
classifier__n_jobs:[4]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 425
28538172
28147276
28297671
28658617
28423311

### False negatives for Test set: 281
28800889
28402849
28514652
29466735
29361613

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/08-10-43-27. Total    754.37 seconds
Fitting 1 folds for each of 3 candidates, totalling 3 fits
### Start Time 2019/01/10-15-07-16  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=633   randForSplit=511   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.98      0.98      0.98     21507
Train discard       0.98      0.98      0.98     19296

  avg / total       0.98      0.98      0.98     40803

Train F2: 0.98081 (keep)

['yes', 'no']
[[21073   434]
 [  326 18970]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.97      0.99      0.98      2868
Valid discard       0.99      0.98      0.99      4628

  avg / total       0.98      0.98      0.98      7496

Valid F2: 0.98309 (keep)

['yes', 'no']
[[2826   42]
 [  75 4553]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.82      0.88      0.85      2127
Test  discard       0.92      0.88      0.90      3515

  avg / total       0.88      0.88      0.88      5642

Test  F2: 0.86552 (keep)

['yes', 'no']
[[1869  258]
 [ 420 3095]]

### Best Pipeline Parameters:
classifier__max_features: 50
classifier__min_samples_split: 10
classifier__n_estimators: 50
classifier__n_jobs: 6
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=50,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=10,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=633, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[50]
classifier__min_samples_split:[10, 20, 30]
classifier__n_estimators:[50]
classifier__n_jobs:[6]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 420
28538172
28147276
28052251
28423311
28178514

### False negatives for Test set: 258
28800889
28402849
28514652
29020624
29466735

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-15-17-35. Total    619.29 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/10-15-27-34  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=835   randForSplit=391   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.95      0.94      0.95     21507
Train discard       0.94      0.95      0.94     19296

  avg / total       0.95      0.95      0.95     40803

Train F2: 0.94655 (keep)

['yes', 'no']
[[20320  1187]
 [  989 18307]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.93      0.95      0.94      2868
Valid discard       0.97      0.96      0.96      4628

  avg / total       0.96      0.95      0.95      7496

Valid F2: 0.94873 (keep)

['yes', 'no']
[[2735  133]
 [ 207 4421]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.80      0.87      0.84      2127
Test  discard       0.92      0.87      0.89      3515

  avg / total       0.88      0.87      0.87      5642

Test  F2: 0.85904 (keep)

['yes', 'no']
[[1860  267]
 [ 458 3057]]

### Best Pipeline Parameters:
classifier__max_features: 25
classifier__min_samples_split: 30
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=25,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=30,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=835, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[25]
classifier__min_samples_split:[30]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 458
28147276
28052251
28297671
28423311
29020625

### False negatives for Test set: 267
28800889
28402849
28514652
29466735
27579714

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-15-36-40. Total    545.52 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/10-15-39-15  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=789   randForSplit=443   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.93      0.92      0.93     21507
Train discard       0.91      0.92      0.92     19296

  avg / total       0.92      0.92      0.92     40803

Train F2: 0.92399 (keep)

['yes', 'no']
[[19848  1659]
 [ 1528 17768]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.89      0.93      0.91      2868
Valid discard       0.96      0.93      0.94      4628

  avg / total       0.93      0.93      0.93      7496

Valid F2: 0.92177 (keep)

['yes', 'no']
[[2670  198]
 [ 341 4287]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.77      0.87      0.82      2127
Test  discard       0.91      0.84      0.88      3515

  avg / total       0.86      0.85      0.85      5642

Test  F2: 0.84503 (keep)

['yes', 'no']
[[1842  285]
 [ 549 2966]]

### Best Pipeline Parameters:
classifier__max_features: 10
classifier__min_samples_split: 50
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=10,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=50,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=789, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[10]
classifier__min_samples_split:[50]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 549
28147276
28052251
28297671
28658617
28423311

### False negatives for Test set: 285
28800889
28402849
28514652
29212023
29466735

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-15-47-54. Total    519.17 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/10-15-53-21  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=328   randForSplit=942   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.91      0.91     21507
Train discard       0.90      0.90      0.90     19296

  avg / total       0.90      0.90      0.90     40803

Train F2: 0.90866 (keep)

['yes', 'no']
[[19529  1978]
 [ 1904 17392]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.92      0.89      2868
Valid discard       0.95      0.91      0.93      4628

  avg / total       0.91      0.91      0.91      7496

Valid F2: 0.90393 (keep)

['yes', 'no']
[[2625  243]
 [ 423 4205]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.77      0.87      0.82      2127
Test  discard       0.92      0.84      0.88      3515

  avg / total       0.86      0.86      0.86      5642

Test  F2: 0.85242 (keep)

['yes', 'no']
[[1861  266]
 [ 547 2968]]

### Best Pipeline Parameters:
classifier__max_features: 10
classifier__min_samples_split: 75
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features=10,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=75,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=328, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_features:[10]
classifier__min_samples_split:[75]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 547
28147276
28052251
28297671
28423311
28178514

### False negatives for Test set: 266
28800889
28402849
28514652
29466735
27579714

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-16-02-01. Total    519.95 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/10-16-03-49  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=45   randForSplit=728   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.84      0.88     21507
Train discard       0.84      0.91      0.87     19296

  avg / total       0.88      0.87      0.87     40803

Train F2: 0.85447 (keep)

['yes', 'no']
[[18082  3425]
 [ 1698 17598]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.85      0.86      2868
Valid discard       0.91      0.92      0.92      4628

  avg / total       0.89      0.89      0.89      7496

Valid F2: 0.85401 (keep)

['yes', 'no']
[[2437  431]
 [ 359 4269]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.85      0.85      0.85      2127
Test  discard       0.91      0.91      0.91      3515

  avg / total       0.89      0.89      0.89      5642

Test  F2: 0.84682 (keep)

['yes', 'no']
[[1800  327]
 [ 320 3195]]

### Best Pipeline Parameters:
classifier__max_depth: 15
classifier__min_samples_split: 75
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=15, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=75,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=45, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_depth:[15]
classifier__min_samples_split:[75]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 320
28538172
28147276
28052251
28423311
28700948

### False negatives for Test set: 327
28800889
28402849
28514652
29466735
29361613

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-16-12-28. Total    518.59 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/10-18-14-24  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=769   randForSplit=191   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.84      0.88     21507
Train discard       0.84      0.91      0.87     19296

  avg / total       0.88      0.88      0.88     40803

Train F2: 0.85405 (keep)

['yes', 'no']
[[18060  3447]
 [ 1644 17652]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.87      0.85      0.86      2868
Valid discard       0.91      0.92      0.92      4628

  avg / total       0.90      0.90      0.90      7496

Valid F2: 0.85774 (keep)

['yes', 'no']
[[2448  420]
 [ 350 4278]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.85      0.84      0.85      2127
Test  discard       0.91      0.91      0.91      3515

  avg / total       0.88      0.88      0.88      5642

Test  F2: 0.84541 (keep)

['yes', 'no']
[[1797  330]
 [ 323 3192]]

### Best Pipeline Parameters:
classifier__max_depth: 15
classifier__min_samples_split: 75
classifier__n_estimators: 100
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=15, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=75,
            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=6,
            oob_score=False, random_state=769, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_depth:[15]
classifier__min_samples_split:[75]
classifier__n_estimators:[100]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 323
28147276
28052251
28297671
28423311
28700948

### False negatives for Test set: 330
28800889
28402849
28514652
29466735
27579714

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-18-23-03. Total    519.05 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/10-18-27-01  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=215   randForSplit=809   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.92      0.89      0.90     21507
Train discard       0.88      0.92      0.90     19296

  avg / total       0.90      0.90      0.90     40803

Train F2: 0.89430 (keep)

['yes', 'no']
[[19090  2417]
 [ 1613 17683]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.88      0.90      0.89      2868
Valid discard       0.94      0.92      0.93      4628

  avg / total       0.92      0.91      0.91      7496

Valid F2: 0.89469 (keep)

['yes', 'no']
[[2576  292]
 [ 348 4280]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.87      0.85      2127
Test  discard       0.92      0.90      0.91      3515

  avg / total       0.89      0.88      0.88      5642

Test  F2: 0.85861 (keep)

['yes', 'no']
[[1840  287]
 [ 367 3148]]

### Best Pipeline Parameters:
classifier__max_depth: 30
classifier__min_samples_split: 75
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=30, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=75,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=215, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_depth:[30]
classifier__min_samples_split:[75]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 367
28538172
28147276
28052251
28297671
28423311

### False negatives for Test set: 287
28800889
28402849
28514652
29466735
29361613

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/10-18-35-46. Total    525.15 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/14-12-25-56  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=52   randForSplit=16   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.89      0.82      0.85     21507
Train discard       0.81      0.88      0.85     19296

  avg / total       0.85      0.85      0.85     40803

Train F2: 0.83197 (keep)

['yes', 'no']
[[17626  3881]
 [ 2275 17021]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.83      0.83      0.83      2868
Valid discard       0.89      0.89      0.89      4628

  avg / total       0.87      0.87      0.87      7496

Valid F2: 0.82973 (keep)

['yes', 'no']
[[2381  487]
 [ 495 4133]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.79      0.82      0.80      2127
Test  discard       0.89      0.86      0.88      3515

  avg / total       0.85      0.85      0.85      5642

Test  F2: 0.81329 (keep)

['yes', 'no']
[[1745  382]
 [ 475 3040]]

### Best Pipeline Parameters:
classifier__max_depth: 15
classifier__max_features: 10
classifier__min_samples_split: 75
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=15, max_features=10,
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=1, min_samples_split=75,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=52, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__max_depth:[15]
classifier__max_features:[10]
classifier__min_samples_split:[75]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 475
28147276
28052251
28423311
29020625
28700948

### False negatives for Test set: 382
28800889
28402849
28514652
29020624
29466735

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/14-12-34-41. Total    524.92 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/14-12-59-32  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=293   randForSplit=899   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.90      0.87      0.88     21507
Train discard       0.86      0.89      0.87     19296

  avg / total       0.88      0.88      0.88     40803

Train F2: 0.87587 (keep)

['yes', 'no']
[[18734  2773]
 [ 2183 17113]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      2868
Valid discard       0.92      0.90      0.91      4628

  avg / total       0.89      0.89      0.89      7496

Valid F2: 0.87072 (keep)

['yes', 'no']
[[2519  349]
 [ 474 4154]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.87      0.85      2127
Test  discard       0.92      0.89      0.90      3515

  avg / total       0.88      0.88      0.88      5642

Test  F2: 0.85724 (keep)

['yes', 'no']
[[1841  286]
 [ 389 3126]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=293, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 389
28147276
28052251
28297671
28423311
28700948

### False negatives for Test set: 286
28800889
28402849
28514652
29466735
29361613

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/14-13-08-41. Total    548.90 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/14-13-52-59  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=519   randForSplit=480   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.90      0.88      0.89     21507
Train discard       0.86      0.89      0.88     19296

  avg / total       0.88      0.88      0.88     40803

Train F2: 0.87938 (keep)

['yes', 'no']
[[18822  2685]
 [ 2168 17128]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      2868
Valid discard       0.93      0.90      0.91      4628

  avg / total       0.89      0.89      0.89      7496

Valid F2: 0.87585 (keep)

['yes', 'no']
[[2537  331]
 [ 474 4154]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.82      0.87      0.85      2127
Test  discard       0.92      0.89      0.90      3515

  avg / total       0.88      0.88      0.88      5642

Test  F2: 0.86031 (keep)

['yes', 'no']
[[1850  277]
 [ 394 3121]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 250
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=6,
            oob_score=False, random_state=519, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[250]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 394
28538172
28147276
28052251
28297671
28423311

### False negatives for Test set: 277
28800889
28402849
28514652
29466735
27579714

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/14-14-02-59. Total    599.73 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/14-14-07-40  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=568   randForSplit=913   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.89      0.86      0.87     21507
Train discard       0.85      0.88      0.86     19296

  avg / total       0.87      0.87      0.87     40803

Train F2: 0.86798 (keep)

['yes', 'no']
[[18570  2937]
 [ 2374 16922]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.83      0.87      0.85      2868
Valid discard       0.92      0.89      0.90      4628

  avg / total       0.88      0.88      0.88      7496

Valid F2: 0.86484 (keep)

['yes', 'no']
[[2507  361]
 [ 515 4113]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.82      0.87      0.85      2127
Test  discard       0.92      0.89      0.90      3515

  avg / total       0.88      0.88      0.88      5642

Test  F2: 0.86000 (keep)

['yes', 'no']
[[1849  278]
 [ 393 3122]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 50
classifier__n_estimators: 700
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=50, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=6,
            oob_score=False, random_state=568, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[50]
classifier__n_estimators:[700]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2878
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lead', u'lead increas', u'learn', u'led', u'left', u'left panel', u'left repres']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 393
28147276
28052251
28297671
28423311
28700948

### False negatives for Test set: 278
28800889
28402849
28514652
29466735
27579714

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7496         2868         4628          38%
Training Set        :        40803        21507        19296          53%
Test Set            :         5642         2127         3515          38%
TestSplit: 0.20
### End Time 2019/01/14-14-18-40. Total    659.55 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/01/28-17-22-41  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/trainSetFig.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/valSetFig.txt
Test data path:       /Users/jak/work/autolittriage/Data/jan2_noReviews/Proc1/testSetFig.txt
Random Seeds:	randForClassifier=979   randForSplit=260   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.90      0.86      0.88     21300
Train discard       0.84      0.88      0.86     17779

  avg / total       0.87      0.87      0.87     39079

Train F2: 0.86954 (keep)

['yes', 'no']
[[18389  2911]
 [ 2151 15628]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.87      0.86      2823
Valid discard       0.91      0.89      0.90      4277

  avg / total       0.89      0.88      0.88      7100

Valid F2: 0.86628 (keep)

['yes', 'no']
[[2463  360]
 [ 461 3816]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.86      0.84      2111
Test  discard       0.91      0.88      0.89      3233

  avg / total       0.88      0.87      0.87      5344

Test  F2: 0.85432 (keep)

['yes', 'no']
[[1818  293]
 [ 378 2855]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 50
classifier__n_estimators: 700
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=50, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=6,
            oob_score=False, random_state=979, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[50]
classifier__n_estimators:[700]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2940
First 10 features: [u'aa', u'aav', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish']

Middle 10 features: [u'left repres', u'left right', u'left untreat', u'legend', u'legend continu', u'legend figur', u'legend reader', u'length', u'lentivir', u'lentivirus']

Last 10 features: [u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone', u'zoom']

### False positives for Test set: 378
28122243
28591580
28683305
28813664
28751309

### False negatives for Test set: 293
29660410
28834748
29661797
27312243
27522067

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         7100         2823         4277          40%
Training Set        :        39079        21300        17779          55%
Test Set            :         5344         2111         3233          40%
TestSplit: 0.20
### End Time 2019/01/28-17-33-26. Total    645.73 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/19-07-27-08  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=791   randForSplit=101   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     25900
Train discard       0.85      0.89      0.87     20459

  avg / total       0.88      0.88      0.88     46359

Train F4: 0.87377 (keep)

['yes', 'no']
[[22573  3327]
 [ 2203 18256]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.89      0.87      3124
Valid discard       0.93      0.91      0.92      5005

  avg / total       0.90      0.90      0.90      8129

Valid F4: 0.88595 (keep)

['yes', 'no']
[[2774  350]
 [ 471 4534]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.88      0.85      2345
Test  discard       0.92      0.89      0.90      3761

  avg / total       0.89      0.89      0.89      6106

Test  F4: 0.87823 (keep)

['yes', 'no']
[[2067  278]
 [ 424 3337]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=791, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 6289
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abi', u'abil', u'abl']

Middle 10 features: [u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn', u'leav', u'lectin', u'led']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 424
28538172
28273465
28813664
28683308
29330350

### False negatives for Test set: 278
29122676
26663874
27338806
27125859
12115612

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3124         5005          38%
Training Set        :        46359        25900        20459          56%
Test Set            :         6106         2345         3761          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1909 predicted keep:  1739 recall: 0.911
gxd_status     selected papers:   197 predicted keep:   177 recall: 0.898
go_status      selected papers:  1990 predicted keep:  1782 recall: 0.895
tumor_status   selected papers:   168 predicted keep:   151 recall: 0.899
qtl_status     selected papers:     5 predicted keep:     2 recall: 0.400
Totals         selected papers:  2345 predicted keep:  2067 recall: 0.881
### End Time 2019/02/19-07-53-17. Total   1568.35 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/19-09-04-13  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/trainSet.txt	GridSearch Beta: 4
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/Legends/Proc1/testSet.txt
Random Seeds:	randForClassifier=128   randForSplit=41   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     25931
Train discard       0.84      0.89      0.86     20428

  avg / total       0.88      0.88      0.88     46359

Train F4: 0.87046 (keep)

['yes', 'no']
[[22517  3414]
 [ 2344 18084]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.87      0.86      3103
Valid discard       0.92      0.90      0.91      5026

  avg / total       0.89      0.89      0.89      8129

Valid F4: 0.86895 (keep)

['yes', 'no']
[[2701  402]
 [ 493 4533]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.86      0.85      2335
Test  discard       0.91      0.89      0.90      3771

  avg / total       0.88      0.88      0.88      6106

Test  F4: 0.86013 (keep)

['yes', 'no']
[[2013  322]
 [ 413 3358]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=128, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2909
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'lentivirus', u'lesion', u'lethal', u'letter', u'leukocyt', u'level', u'level cell', u'level cell_lin', u'level determin', u'level express']

Last 10 features: [u'wound', u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone']

### False positives for Test set: 413
28052251
28614716
28954219
28683305
29358166

### False negatives for Test set: 322
29122676
29510224
28854361
29241530
28834748

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3103         5026          38%
Training Set        :        46359        25931        20428          56%
Test Set            :         6106         2335         3771          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1899 predicted keep:  1708 recall: 0.899
gxd_status     selected papers:   197 predicted keep:   183 recall: 0.929
go_status      selected papers:  1954 predicted keep:  1708 recall: 0.874
tumor_status   selected papers:   152 predicted keep:   136 recall: 0.895
### End Time 2019/02/19-09-14-54. Total    641.03 seconds

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/02/20-13-36-52  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/feb18_nopmRevs/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=804   randForSplit=253   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.88      0.89     25898
Train discard       0.85      0.89      0.87     20461

  avg / total       0.88      0.88      0.88     46359

Train F2: 0.88228 (keep)

['yes', 'no']
[[22677  3221]
 [ 2245 18216]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.89      0.87      3164
Valid discard       0.93      0.91      0.92      4965

  avg / total       0.90      0.90      0.90      8129

Valid F2: 0.88267 (keep)

['yes', 'no']
[[2812  352]
 [ 461 4504]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.81      0.87      0.84      2307
Test  discard       0.92      0.88      0.90      3799

  avg / total       0.88      0.87      0.87      6106

Test  F2: 0.85526 (keep)

['yes', 'no']
[[2002  305]
 [ 474 3325]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=804, verbose=1, warm_start=False)

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 8561
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abc', u'abcam', u'abdomin', u'aberr', u'abi']

Middle 10 features: [u'jolla', u'journal', u'judg', u'juli', u'jun', u'junction', u'june', u'just', u'kaplan', u'kaplan meier']

Last 10 features: [u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zinc finger', u'zone', u'zoom']

### False positives for Test set: 474
28122243
28297671
28423311
29020625
29091758

### False negatives for Test set: 305
28800889
29510224
28683322
26711629
27185595

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8129         3164         4965          39%
Training Set        :        46359        25898        20461          56%
Test Set            :         6106         2307         3799          38%
TestSplit: 0.20

Recall for papers selected by each curation group
ap_status      selected papers:  1841 predicted keep:  1687 recall: 0.916
gxd_status     selected papers:   177 predicted keep:   168 recall: 0.949
go_status      selected papers:  1922 predicted keep:  1683 recall: 0.876
tumor_status   selected papers:   171 predicted keep:   152 recall: 0.889
qtl_status     selected papers:     3 predicted keep:     1 recall: 0.333
Totals         selected papers:  2307 predicted keep:  2002 recall: 0.868
### End Time 2019/02/20-14-08-47. Total   1914.75 seconds

----------------------------
Start April 22 data
----------------------------

Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/24-14-07-53  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=478   randForSplit=78   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     27648
Train discard       0.85      0.89      0.87     21819

  avg / total       0.88      0.88      0.88     49467

Train F2: 0.87981 (keep)

['yes', 'no']
[[24118  3530]
 [ 2353 19466]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.89      0.87      3402
Valid discard       0.93      0.90      0.91      5432

  avg / total       0.90      0.89      0.89      8834

Valid F2: 0.87884 (keep)

['yes', 'no']
[[3019  383]
 [ 549 4883]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.84      0.89      0.86      2607
Test  discard       0.93      0.89      0.91      4030

  avg / total       0.89      0.89      0.89      6637

Test  F2: 0.87930 (keep)

['yes', 'no']
[[2321  286]
 [ 449 3581]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=478, verbose=1, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 6288
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn', u'leav']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 449
29045831
29262323
29562173
29925008
29719241

### False negatives for Test set: 286
29122676
28903050
30184487
25704808
30463003

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3402         5432          39%
Training Set        :        49467        27648        21819          56%
Test Set            :         6637         2607         4030          39%
TestSplit: 0.20
### End Time 2019/04/24-14-34-50. Total   1617.23 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2142 predicted keep:  1980 recall: 0.924
gxd_status     selected papers:   207 predicted keep:   194 recall: 0.937
go_status      selected papers:  2179 predicted keep:  1974 recall: 0.906
tumor_status   selected papers:   187 predicted keep:   166 recall: 0.888
qtl_status     selected papers:     4 predicted keep:     2 recall: 0.500
Totals         selected papers:  2607 predicted keep:  2321 recall: 0.890
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/25-05-21-57  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/LegendsPara/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/LegendsPara/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/LegendsPara/Proc1/testSet.txt
Random Seeds:	randForClassifier=436   randForSplit=721   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     27577
Train discard       0.85      0.89      0.87     21890

  avg / total       0.88      0.88      0.88     49467

Train F2: 0.88150 (keep)

['yes', 'no']
[[24116  3461]
 [ 2366 19524]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.90      0.87      3488
Valid discard       0.93      0.90      0.91      5346

  avg / total       0.90      0.90      0.90      8834

Valid F2: 0.88651 (keep)

['yes', 'no']
[[3123  365]
 [ 539 4807]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.82      0.88      0.85      2592
Test  discard       0.92      0.88      0.90      4045

  avg / total       0.88      0.88      0.88      6637

Test  F2: 0.86702 (keep)

['yes', 'no']
[[2278  314]
 [ 491 3554]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=436, verbose=1, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 8579
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abc', u'abcam', u'abdomin', u'aberr', u'abi']

Middle 10 features: [u'issu', u'iter', u'iv', u'jackson', u'jackson immunoresearch', u'jackson laboratori', u'januari', u'japan', u'jnk', u'john']

Last 10 features: [u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zinc finger', u'zone', u'zoom']

### False positives for Test set: 491
28329687
28297671
28273465
29669283
30257220

### False negatives for Test set: 314
30179675
29166604
26549446
28768188
28793256

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3488         5346          39%
Training Set        :        49467        27577        21890          56%
Test Set            :         6637         2592         4045          39%
TestSplit: 0.20
### End Time 2019/04/25-05-58-01. Total   2163.98 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2151 predicted keep:  1975 recall: 0.918
gxd_status     selected papers:   207 predicted keep:   193 recall: 0.932
go_status      selected papers:  2178 predicted keep:  1950 recall: 0.895
tumor_status   selected papers:   160 predicted keep:   144 recall: 0.900
qtl_status     selected papers:     3 predicted keep:     3 recall: 1.000
Totals         selected papers:  2592 predicted keep:  2278 recall: 0.879
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/25-06-35-37  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/Legends/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/Legends/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/Legends/Proc1/testSet.txt
Random Seeds:	randForClassifier=896   randForSplit=100   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     27624
Train discard       0.84      0.89      0.87     21843

  avg / total       0.88      0.88      0.88     49467

Train F2: 0.87716 (keep)

['yes', 'no']
[[24031  3593]
 [ 2455 19388]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.84      0.88      0.86      3434
Valid discard       0.92      0.89      0.91      5400

  avg / total       0.89      0.89      0.89      8834

Valid F2: 0.87142 (keep)

['yes', 'no']
[[3024  410]
 [ 591 4809]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.87      0.85      2599
Test  discard       0.91      0.89      0.90      4038

  avg / total       0.88      0.88      0.88      6637

Test  F2: 0.86120 (keep)

['yes', 'no']
[[2256  343]
 [ 446 3592]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=896, verbose=1, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 2902
First 10 features: [u'aa', u'ab', u'abbrevi', u'aberr', u'abil', u'abl', u'ablat', u'abnorm', u'abolish', u'abov']

Middle 10 features: [u'length', u'lentivir', u'lentivirus', u'lesion', u'lethal', u'letter', u'leukocyt', u'level', u'level cell', u'level cell_lin']

Last 10 features: [u'xenograft', u'year', u'yellow', u'yellow arrow', u'yfp', u'yield', u'young', u'zero', u'zone', u'zoom']

### False positives for Test set: 446
29635032
29091761
29386117
29791852
30683673

### False negatives for Test set: 343
29660410
28854357
28793256
30134177
30463003

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3434         5400          39%
Training Set        :        49467        27624        21843          56%
Test Set            :         6637         2599         4038          39%
TestSplit: 0.20
### End Time 2019/04/25-06-46-06. Total    629.07 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2144 predicted keep:  1927 recall: 0.899
gxd_status     selected papers:   198 predicted keep:   183 recall: 0.924
go_status      selected papers:  2182 predicted keep:  1933 recall: 0.886
tumor_status   selected papers:   159 predicted keep:   131 recall: 0.824
qtl_status     selected papers:     3 predicted keep:     1 recall: 0.333
Totals         selected papers:  2599 predicted keep:  2256 recall: 0.868
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/25-10-02-50  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=711   randForSplit=340   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     27648
Train discard       0.85      0.89      0.87     21819

  avg / total       0.88      0.88      0.88     49467

Train F2: 0.88082 (keep)

['yes', 'no']
[[24146  3502]
 [ 2327 19492]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.89      0.87      3402
Valid discard       0.93      0.90      0.91      5432

  avg / total       0.90      0.90      0.90      8834

Valid F2: 0.88127 (keep)

['yes', 'no']
[[3027  375]
 [ 539 4893]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.89      0.86      2607
Test  discard       0.92      0.89      0.90      4030

  avg / total       0.89      0.89      0.89      6637

Test  F2: 0.87652 (keep)

['yes', 'no']
[[2314  293]
 [ 458 3572]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=711, verbose=1, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 6288
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'layer', u'lc', u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn', u'leav']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 458
28355573
29045831
29262323
29562173
29925008

### False negatives for Test set: 293
29122676
28903050
30184487
25704808
30463003

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3402         5432          39%
Training Set        :        49467        27648        21819          56%
Test Set            :         6637         2607         4030          39%
TestSplit: 0.20
### End Time 2019/04/25-10-31-09. Total   1698.56 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2142 predicted keep:  1976 recall: 0.923
gxd_status     selected papers:   207 predicted keep:   192 recall: 0.928
go_status      selected papers:  2179 predicted keep:  1965 recall: 0.902
tumor_status   selected papers:   187 predicted keep:   169 recall: 0.904
qtl_status     selected papers:     4 predicted keep:     2 recall: 0.500
Totals         selected papers:  2607 predicted keep:  2314 recall: 0.888
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/25-10-53-52  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=557   randForSplit=624   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.88      0.89     27523
Train discard       0.85      0.89      0.87     21944

  avg / total       0.88      0.88      0.88     49467

Train F2: 0.88304 (keep)

['yes', 'no']
[[24129  3394]
 [ 2404 19540]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.86      0.89      0.87      3547
Valid discard       0.92      0.90      0.91      5287

  avg / total       0.90      0.90      0.90      8834

Valid F2: 0.88130 (keep)

['yes', 'no']
[[3148  399]
 [ 524 4763]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.88      0.86      2587
Test  discard       0.92      0.89      0.90      4050

  avg / total       0.89      0.89      0.89      6637

Test  F2: 0.87267 (keep)

['yes', 'no']
[[2285  302]
 [ 459 3591]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=557, verbose=1, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 6293
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'later time', u'layer', u'lc', u'lc ms', u'lc3', u'lead', u'lead decreas', u'lead increas', u'lean', u'learn']

Last 10 features: [u'young', u'younger', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 459
28122243
28355573
28297677
29925008
30184508

### False negatives for Test set: 302
29122676
29155075
29155305
28903050
29320745

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3547         5287          40%
Training Set        :        49467        27523        21944          56%
Test Set            :         6637         2587         4050          39%
TestSplit: 0.20
### End Time 2019/04/25-11-21-34. Total   1662.07 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2125 predicted keep:  1952 recall: 0.919
gxd_status     selected papers:   204 predicted keep:   191 recall: 0.936
go_status      selected papers:  2195 predicted keep:  1971 recall: 0.898
tumor_status   selected papers:   179 predicted keep:   155 recall: 0.866
qtl_status     selected papers:     5 predicted keep:     3 recall: 0.600
Totals         selected papers:  2587 predicted keep:  2285 recall: 0.883
Fitting 1 folds for each of 1 candidates, totalling 1 fits
### Start Time 2019/04/25-11-49-50  RF.py	index file: index.out
Training data path:   /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/trainSet.txt	GridSearch Beta: 2
Validation data path: /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/valSet.txt
Test data path:       /Users/jak/work/autolittriage/Data/apr22/LegendsWords/Proc1/testSet.txt
Random Seeds:	randForClassifier=413   randForSplit=330   
### Metrics: Training Set
               precision    recall  f1-score   support

   Train keep       0.91      0.87      0.89     27608
Train discard       0.85      0.89      0.87     21859

  avg / total       0.88      0.88      0.88     49467

Train F2: 0.88159 (keep)

['yes', 'no']
[[24150  3458]
 [ 2386 19473]]

### Metrics: Validation Set
               precision    recall  f1-score   support

   Valid keep       0.85      0.89      0.87      3486
Valid discard       0.92      0.90      0.91      5348

  avg / total       0.89      0.89      0.89      8834

Valid F2: 0.88003 (keep)

['yes', 'no']
[[3097  389]
 [ 555 4793]]

### Metrics: Test Set
               precision    recall  f1-score   support

   Test  keep       0.83      0.87      0.85      2563
Test  discard       0.92      0.89      0.90      4074

  avg / total       0.88      0.88      0.88      6637

Test  F2: 0.86312 (keep)

['yes', 'no']
[[2236  327]
 [ 465 3609]]

### Best Pipeline Parameters:
classifier__min_samples_leaf: 25
classifier__n_estimators: 50
vectorizer__max_df: 0.75
vectorizer__min_df: 0.02
vectorizer__ngram_range: (1, 2)

### GridSearch Pipeline:
classifier:
RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=None, max_features='auto',
            max_leaf_nodes=None, min_impurity_split=1e-07,
            min_samples_leaf=25, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=6,
            oob_score=False, random_state=413, verbose=1, warm_start=False)

featureEvaluator:
FeatureDocCounter()

vectorizer:
CountVectorizer(analyzer=u'word', binary=True, decode_error='strict',
        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',
        lowercase=False, max_df=0.75, max_features=None, min_df=0.02,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern=u'(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)

### Parameter Options Tried:
classifier__min_samples_leaf:[25]
classifier__n_estimators:[50]
vectorizer__max_df:[0.75]
vectorizer__min_df:[0.02]
vectorizer__ngram_range:[(1, 2)]

### Top positive features - not available
### Top negative features - not available

### Vectorizer:   Number of Features: 6299
First 10 features: [u'aa', u'aaa', u'aav', u'ab', u'abbrevi', u'abcam', u'aberr', u'abil', u'abl', u'ablat']

Middle 10 features: [u'lead decreas', u'lead increas', u'lean', u'learn', u'leav', u'lectin', u'led', u'led decreas', u'led increas', u'led signific']

Last 10 features: [u'yield', u'young', u'zebrafish', u'zeiss', u'zero', u'zhang', u'zhang et', u'zinc', u'zone', u'zoom']

### False positives for Test set: 465
28122243
28538185
28954235
29241538
25127135

### False negatives for Test set: 327
29510224
26549446
30184487
30463000
29320745

### Sample set sizes
                    :      Samples     Positive     Negative   % Positive
Validation Set      :         8834         3486         5348          39%
Training Set        :        49467        27608        21859          56%
Test Set            :         6637         2563         4074          39%
TestSplit: 0.20
### End Time 2019/04/25-12-18-07. Total   1696.93 seconds

Recall for papers selected by each curation group
ap_status      selected papers:  2107 predicted keep:  1932 recall: 0.917
gxd_status     selected papers:   207 predicted keep:   194 recall: 0.937
go_status      selected papers:  2173 predicted keep:  1924 recall: 0.885
tumor_status   selected papers:   144 predicted keep:   131 recall: 0.910
qtl_status     selected papers:     3 predicted keep:     0 recall: 0.000
Totals         selected papers:  2563 predicted keep:  2236 recall: 0.872
