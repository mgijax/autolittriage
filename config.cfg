[DEFAULT]
HOMEDIR: /Users/jak/work/autolittriage3
PREDICTION_PROBLEM: primTriage
PROBLEM_DIR: %(HOMEDIR)s/Train/%(PREDICTION_PROBLEM)s
MLTEXTTOOLSDIR: /Users/jak/work/MLtextTools3

# Delimited text files from getTrainingData.py and input to predict
# probably don't need these anymore as they are gotten from ClassifiedSampleSet
FIELDSEP = '|'
RECORDEND = ';;'

TRAINING_DATA: %(HOMEDIR)s/Data/dec5/Proc1/trainingSetFig.txt
# data directory in format that sklearn.datasets.load_files() wants
# Directory where training data lives - split into class name subdirectories
#    as desired by sklearn.datasets.load_files()
# Currently unused since we are not using sklearn.datasets.load_files()

#DATA_TO_PREDICT: %(HOMEDIR)s/Data/predict/predict_data.txt
# tab delimited file of data to predict

#PREPROCESSORS = ['removeRefSection', 'rejectIfNoMice', 'removeURLsCleanStem']
# name of preprocessor functions to call to help prepare documents
# (not currently used since we bulk preprocess the data files before training)

FIG_CONVERSION: close words
FIG_CONVERSION_NWORDS: 50
# How should figure text be extracted
# Options are 'legend', 'paragraph', 'close words'. see figureText.py

[CLASS_NAMES]
# Class names and y_value mappings.
# ######## These values are for primary triage (discard/keep) #######

SAMPLE_OBJ_TYPE_NAME: PrimTriageClassifiedSample
# The name of the python Sample class

# The following config variables confusing & has taken a long time to
#   understand.
# See sklearn.metrics:   confusion_matrix,  classification_report
#   make_scorer, fbeta_score, precision_score, recall_score

# NOTE most of these have been encapsulated in Sample (sub)classes in 
#  sampleDataLib.py

#y_class_names: ['discard', 'keep']
# The labels matching y_values from the training set: y_class_names[y_val]= name
# These should be the classification labels in alpha order
# These match training set directory names used by sklearn.datasets.load_files()

#y_positive: 1
# The (numeric) value in y_ that we are treating as the "positive" class.

#y_class_to_score: %(y_positive)s
y_class_to_score: 1
# the index in ClassifiedSample.SampleClassNames of the class to score,
#   i.e., compute precision, recall, f-score, etc.
# This class is used in the grid search scoring to select the best model.
# AND in reporting scores in output

rpt_class_names: ['keep', 'discard']
# Order + labels we want to report in confusion matrix and other rpts.

rpt_class_mapping: [ 1, 0 ]
# List of y_values to rpt in confusion matrix and other reports.
# These y_values correspond to ClassifiedSample.yPositive and yNegative
# rpt_class_mapping[y_val] maps to rpt_class_names[]

rpt_classification_report_num: 2
# How many class_names to show in classification_report.
# These classes will be in rpt_class_mapping order


[MODEL_TUNING]
NUM_JOBS: 1
# number of parallel jobs to use when running GridSearch
# 10/9/2019: for anaconda-2019.07-py27_0.json
# when using >1 here on Mac, I get this warning:
# RuntimeWarning: semaphore are broken on OSX, release might increase its maximal value

TUNING_INDEX_FILE: index.out
# Where to write index file during tuning runs

GRIDSEARCH_BETA: 2
# default Fscore beta for comparing params in GridSearch

COMPARE_BETA: 2
# use when comparing different models (outside GS)

VALIDATION_SPLIT: 0.20
# fraction of sample set to use for validation set
NUM_CV: 5
# num of GridSearch cross validation fits (folds) to use
